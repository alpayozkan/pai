{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b6fbba-5b4f-4a34-bdc9-136aaba4c103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf `USE_PRETRAINED_INIT` is `True`, then MAP inference uses provided pretrained weights.\\nYou should not modify MAP training or the CNN architecture before passing the hard baseline.\\nIf you set the constant to `False` (to further experiment),\\nthis solution always performs MAP inference before running your SWAG implementation.\\nNote that MAP inference can take a long time.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import abc\n",
    "import collections\n",
    "import enum\n",
    "import math\n",
    "import pathlib\n",
    "import typing\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from util import draw_reliability_diagram, cost_function, setup_seeds, calc_calibration_curve\n",
    "\n",
    "EXTENDED_EVALUATION = False\n",
    "\"\"\"\n",
    "Set `EXTENDED_EVALUATION` to `True` in order to generate additional plots on validation data.\n",
    "\"\"\"\n",
    "\n",
    "USE_PRETRAINED_INIT = True\n",
    "\"\"\"\n",
    "If `USE_PRETRAINED_INIT` is `True`, then MAP inference uses provided pretrained weights.\n",
    "You should not modify MAP training or the CNN architecture before passing the hard baseline.\n",
    "If you set the constant to `False` (to further experiment),\n",
    "this solution always performs MAP inference before running your SWAG implementation.\n",
    "Note that MAP inference can take a long time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2f1c7-0241-4c30-a10c-b76cbf39feb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393f3113-7760-4d37-a4a0-f46082e7b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604e6e83-f604-4fb4-ae3a-356c75e8a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f5e8d5-7e1b-45fe-a85f-b498259694c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [torch.rand(4).unsqueeze(0) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1dd1da-b1f9-4162-b8f2-2ae3b2c226e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(L,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1701a9c6-1bcf-4bb8-8997-3a9b62d77320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3612, 0.6067, 0.5483, 0.5626])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.cat(L,0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275f3fb-9596-48d5-bb98-67734d02f3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e99430-337e-45ae-bd3a-edf02f5ac2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     raise RuntimeError(\n",
    "#         \"This main() method is for illustrative purposes only\"\n",
    "#         \" and will NEVER be called when running your solution to generate your submission file!\\n\"\n",
    "#         \"The checker always directly interacts with your SWAGInference class and evaluate method.\\n\"\n",
    "#         \"You can remove this exception for local testing, but be aware that any changes to the main() method\"\n",
    "#         \" are ignored when generating your submission file.\"\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b69f45-371a-40ee-9776-3a0ab0a04340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pathlib' from 'C:\\\\APPS\\\\Anaconda3\\\\envs\\\\pai\\\\lib\\\\pathlib.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c15b26-ffbb-483a-b7ac-53a0c7cb34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path.cwd()\n",
    "model_dir = pathlib.Path.cwd()\n",
    "output_dir = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158b9ef-049a-4f54-b45f-fd9f3d60bce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e7c782-a8d8-41c4-9d2e-c34ecea022e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Y:\\\\private\\\\desktop-dinfk-xp\\\\2023-f\\\\pai\\\\pai_proj\\\\task2_handout_e14a_works_for_new_mac\\\\train_xs.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_xs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_xs.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_xs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m raw_train_meta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_ys.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m train_ys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(raw_train_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_ys\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\APPS\\Anaconda3\\envs\\pai\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Y:\\\\private\\\\desktop-dinfk-xp\\\\2023-f\\\\pai\\\\pai_proj\\\\task2_handout_e14a_works_for_new_mac\\\\train_xs.npz'"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_xs = torch.from_numpy(np.load(data_dir / \"train_xs.npz\")[\"train_xs\"])\n",
    "raw_train_meta = np.load(data_dir / \"train_ys.npz\")\n",
    "train_ys = torch.from_numpy(raw_train_meta[\"train_ys\"])\n",
    "train_is_snow = torch.from_numpy(raw_train_meta[\"train_is_snow\"])\n",
    "train_is_cloud = torch.from_numpy(raw_train_meta[\"train_is_cloud\"])\n",
    "dataset_train = torch.utils.data.TensorDataset(train_xs, train_is_snow, train_is_cloud, train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12540b-a016-4218-8c7f-7856039c505c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4b578-97aa-4ed2-9743-d7f86752aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8ef8c-c923-4b01-97ad-4624105d8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3065bc-3e0d-43b8-970d-7780e9b94da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_xs[100].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfe4f9-6c9c-4470-ab68-f914eb5173ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(train_ys, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937826a0-8617-4638-ae10-a0f3db3bb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(train_is_snow, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485a497-c10d-496b-abac-60f51ae39613",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(train_is_cloud, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52a6bf-fb4a-475d-a51f-2fcebc232cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8581-a72c-493b-94bc-65777b5b5e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd70eb-b2a4-4df9-bd8d-72f6d102908e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42cb55-0378-46f6-92aa-97cdb1af9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "val_xs = torch.from_numpy(np.load(data_dir / \"val_xs.npz\")[\"val_xs\"])\n",
    "raw_val_meta = np.load(data_dir / \"val_ys.npz\")\n",
    "val_ys = torch.from_numpy(raw_val_meta[\"val_ys\"])\n",
    "val_is_snow = torch.from_numpy(raw_val_meta[\"val_is_snow\"])\n",
    "val_is_cloud = torch.from_numpy(raw_val_meta[\"val_is_cloud\"])\n",
    "dataset_val = torch.utils.data.TensorDataset(val_xs, val_is_snow, val_is_cloud, val_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e71185-e20e-48b3-930f-83812fdeae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd09c89-79ed-4529-94b5-559d0236ecea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mval_ys\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_ys' is not defined"
     ]
    }
   ],
   "source": [
    "val_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60f826e7-e0bf-47dc-9d12-5b778ed5fb18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_is_snow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mval_is_snow\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_is_snow' is not defined"
     ]
    }
   ],
   "source": [
    "val_is_snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baff3d9a-c6c0-4477-bab9-bb8cf3878e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m counts, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\u001b[43mval_ys\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(bins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bins, weights\u001b[38;5;241m=\u001b[39mcounts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_ys' is not defined"
     ]
    }
   ],
   "source": [
    "counts, bins = np.histogram(val_ys, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84c8792-0fef-47eb-a0cd-4cb13d352178",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m counts, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\u001b[43mval_ys\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(bins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bins, weights\u001b[38;5;241m=\u001b[39mcounts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_ys' is not defined"
     ]
    }
   ],
   "source": [
    "counts, bins = np.histogram(val_ys, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1512d4fe-d18b-4d20-95c6-4257bc6a1e2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_is_snow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m counts, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\u001b[43mval_is_snow\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(bins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bins, weights\u001b[38;5;241m=\u001b[39mcounts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_is_snow' is not defined"
     ]
    }
   ],
   "source": [
    "counts, bins = np.histogram(val_is_snow, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47a862b2-f559-4310-a63d-e5cdfb878439",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_is_cloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m counts, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\u001b[43mval_is_cloud\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(bins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bins, weights\u001b[38;5;241m=\u001b[39mcounts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_is_cloud' is not defined"
     ]
    }
   ],
   "source": [
    "counts, bins = np.histogram(val_is_cloud, bins=[-1,0,1,2,3,4,5])\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96031173-5299-4ba7-9120-2102e55cf10a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbins\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bins' is not defined"
     ]
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6daf9-4095-494a-8820-f6a1f852eba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6b3b3a-d7f3-45d5-b262-dd010e7d1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all randomness\n",
    "setup_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522cff-61a5-419e-bbcc-c53cb9c5f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a7b18a-a560-4a76-8150-4aa368c82136",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build and run the actual solution\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mdataset_train\u001b[49m,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      5\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Build and run the actual solution\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e10f9f-2abc-4b36-857d-976af6f58716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd1743d-fb57-449c-a333-a6006e060b5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SWAGInference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m swag \u001b[38;5;241m=\u001b[39m \u001b[43mSWAGInference\u001b[49m(\n\u001b[0;32m      2\u001b[0m     train_xs\u001b[38;5;241m=\u001b[39mdataset_train\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      3\u001b[0m     model_dir\u001b[38;5;241m=\u001b[39mmodel_dir,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m swag\u001b[38;5;241m.\u001b[39mfit(train_loader)\n\u001b[0;32m      6\u001b[0m swag\u001b[38;5;241m.\u001b[39mcalibrate(dataset_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SWAGInference' is not defined"
     ]
    }
   ],
   "source": [
    "swag = SWAGInference(\n",
    "    train_xs=dataset_train.tensors[0],\n",
    "    model_dir=model_dir,\n",
    ")\n",
    "swag.fit(train_loader)\n",
    "swag.calibrate(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441a9ab-c2ca-4f30-8f6b-65437ad63cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2446ed4-08b9-40fd-a093-129380bbb142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9577ae5b-a936-4ea9-8d49-912471d7b806",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fork_rng ensures that the evaluation does not change the rng state.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# That way, you should get exactly the same results even if you remove evaluation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# to save computational time when developing the task\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# (as long as you ONLY use torch randomness, and not e.g. random or numpy.random).\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfork_rng():\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mevaluate\u001b[49m(swag, dataset_val, EXTENDED_EVALUATION, output_dir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fork_rng ensures that the evaluation does not change the rng state.\n",
    "# That way, you should get exactly the same results even if you remove evaluation\n",
    "# to save computational time when developing the task\n",
    "# (as long as you ONLY use torch randomness, and not e.g. random or numpy.random).\n",
    "with torch.random.fork_rng():\n",
    "    evaluate(swag, dataset_val, EXTENDED_EVALUATION, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1388a1e-badc-4dde-bf6a-32176b201f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf25443-ca49-4494-b656-a898f54f717e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbf91d-6af4-4afe-8996-4c4f643de487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846569b1-6529-4438-91c7-66e07fdc5298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949218b-ea94-42b0-8efa-10caa19918c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad94abd-b35e-402b-aeb5-bee436154d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Small convolutional neural network used in this task.\n",
    "    You should not modify this class before passing the hard baseline.\n",
    "\n",
    "    Note that if you change the architecture of this network,\n",
    "    you need to re-run MAP inference and cannot use the provided pretrained weights anymore.\n",
    "    Hence, you need to set `USE_PRETRAINED_INIT = False` at the top of this file.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer0 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, 32, kernel_size=5),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 32, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 32, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.pool1 = torch.nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.pool2 = torch.nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3),\n",
    "        )\n",
    "\n",
    "        self.global_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.linear = torch.nn.Linear(64, out_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        # Average features over both spatial dimensions, and remove the now superfluous dimensions\n",
    "        x = self.global_pool(x).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        # Note: this network does NOT output the per-class probabilities y =[y_1, ..., y_C],\n",
    "        # but a feature vector z such that y = softmax(z).\n",
    "        # This avoids numerical instabilities during optimization.\n",
    "        # The PyTorch loss automatically handles this.\n",
    "        log_softmax = self.linear(x)\n",
    "\n",
    "        return log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b82485bc-d60b-431b-8a9f-10c46d0880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN(in_channels=3, out_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f1c7826-17c3-475a-8a15-0fa0cbe088e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x000001EFB8BCDDD0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d5648aa-6d8c-4e37-bac6-891a7b2944a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_params = {name: param.detach() for name, param in network.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f54242-bdac-4433-a3d3-4470224905fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c481b86-b42b-43fe-80d8-c2c102897289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer0.0.weight': tensor([[[[ 0.0595, -0.0510, -0.0224,  0.0542, -0.1087],\n",
       "           [ 0.0692, -0.0238,  0.0587,  0.0161, -0.0141],\n",
       "           [ 0.0320,  0.0057,  0.0422, -0.0450, -0.0084],\n",
       "           [-0.0104,  0.0167, -0.0005,  0.1009,  0.0359],\n",
       "           [-0.0430, -0.0697, -0.0194, -0.0498, -0.0370]],\n",
       " \n",
       "          [[ 0.0055,  0.0688,  0.0628, -0.1129,  0.0716],\n",
       "           [ 0.0323,  0.1095,  0.0762, -0.1052, -0.1098],\n",
       "           [-0.0557,  0.1014, -0.0192,  0.0494, -0.0537],\n",
       "           [ 0.1133, -0.0489,  0.0866,  0.0014, -0.0608],\n",
       "           [ 0.0594, -0.0613,  0.0340, -0.0333, -0.0127]],\n",
       " \n",
       "          [[-0.1110, -0.0551,  0.0627, -0.0281,  0.1150],\n",
       "           [ 0.0926, -0.0054, -0.0771,  0.0703,  0.0358],\n",
       "           [-0.0746,  0.0750,  0.0701,  0.1024, -0.0647],\n",
       "           [-0.0190, -0.0022,  0.0169, -0.0876, -0.0819],\n",
       "           [ 0.0628, -0.0271,  0.0564,  0.0066,  0.0379]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0254,  0.0420,  0.0572, -0.1069,  0.0581],\n",
       "           [-0.0812, -0.0871,  0.0070, -0.0197,  0.0678],\n",
       "           [-0.0669, -0.1027,  0.0840, -0.0171,  0.0649],\n",
       "           [ 0.0371, -0.0866,  0.0232,  0.0277, -0.0773],\n",
       "           [-0.0548,  0.0394,  0.0207, -0.0491, -0.0350]],\n",
       " \n",
       "          [[ 0.1058, -0.0214,  0.0651,  0.0500, -0.0746],\n",
       "           [-0.0982,  0.1108,  0.0060,  0.0791,  0.0239],\n",
       "           [ 0.0371,  0.0863,  0.1095, -0.0766,  0.0144],\n",
       "           [ 0.0862,  0.0837,  0.0717, -0.0836, -0.0832],\n",
       "           [-0.0698,  0.0145,  0.1151, -0.0729,  0.0615]],\n",
       " \n",
       "          [[-0.0639, -0.1086, -0.0245,  0.0665,  0.1072],\n",
       "           [-0.0717,  0.0251,  0.0996,  0.0765,  0.0720],\n",
       "           [ 0.0821,  0.0730,  0.0298, -0.0790, -0.0970],\n",
       "           [-0.0529, -0.0134, -0.0708,  0.0422,  0.0357],\n",
       "           [-0.0261,  0.0444,  0.0373,  0.0705,  0.0778]]],\n",
       " \n",
       " \n",
       "         [[[-0.0391,  0.1128, -0.0133, -0.0040, -0.1090],\n",
       "           [-0.0743, -0.0675, -0.0494,  0.0821, -0.0377],\n",
       "           [-0.0863,  0.0444,  0.0370,  0.0748, -0.0598],\n",
       "           [ 0.0250, -0.0420, -0.0259, -0.0920, -0.0526],\n",
       "           [-0.0354,  0.0494,  0.0211,  0.0285,  0.1153]],\n",
       " \n",
       "          [[ 0.1125,  0.0788,  0.0037, -0.0799,  0.0902],\n",
       "           [-0.0289, -0.0093, -0.0995, -0.0228, -0.0745],\n",
       "           [ 0.1061, -0.0998, -0.0900, -0.0039, -0.0624],\n",
       "           [ 0.0413, -0.0444, -0.0542,  0.0065,  0.0836],\n",
       "           [-0.0812,  0.0542,  0.0742,  0.1130, -0.0808]],\n",
       " \n",
       "          [[ 0.0280, -0.0854,  0.0986, -0.0448,  0.0696],\n",
       "           [ 0.0034, -0.0090, -0.0037,  0.0196,  0.0544],\n",
       "           [ 0.0185,  0.0352, -0.1039,  0.0841,  0.1007],\n",
       "           [ 0.0954,  0.0854, -0.0833, -0.0428,  0.1018],\n",
       "           [-0.0879,  0.1048, -0.0908, -0.0813,  0.0565]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0058, -0.0155,  0.0586, -0.0491,  0.0908],\n",
       "           [-0.0787, -0.0601,  0.0400,  0.0710, -0.0014],\n",
       "           [-0.0906, -0.0046, -0.0390, -0.0369, -0.0213],\n",
       "           [ 0.0278, -0.0269, -0.0810, -0.0577, -0.0967],\n",
       "           [-0.1153,  0.0558,  0.0645,  0.0873,  0.0091]],\n",
       " \n",
       "          [[-0.0475, -0.0694,  0.0575, -0.0698,  0.0863],\n",
       "           [-0.0626, -0.1077, -0.0832,  0.0940,  0.0872],\n",
       "           [ 0.0282,  0.0027,  0.0990,  0.0697,  0.0684],\n",
       "           [-0.0786,  0.0185,  0.1046, -0.0813,  0.1150],\n",
       "           [-0.0756, -0.0339, -0.0054,  0.0300,  0.0355]],\n",
       " \n",
       "          [[-0.0660,  0.0529,  0.0306, -0.0129, -0.1149],\n",
       "           [ 0.1143, -0.0427, -0.0615,  0.1143, -0.0585],\n",
       "           [ 0.0771,  0.0705, -0.0752, -0.0931, -0.0628],\n",
       "           [ 0.0361,  0.1089, -0.0064, -0.0345, -0.0332],\n",
       "           [-0.0804,  0.1154, -0.0013, -0.0914, -0.0789]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0718,  0.0559,  0.0745, -0.0122, -0.0228],\n",
       "           [ 0.0378, -0.0011, -0.0372,  0.0275, -0.0658],\n",
       "           [-0.0800, -0.0255, -0.0823,  0.0029,  0.0182],\n",
       "           [ 0.1131,  0.0333, -0.0007, -0.0839, -0.0464],\n",
       "           [-0.0188, -0.0831,  0.0225,  0.0831,  0.0661]],\n",
       " \n",
       "          [[-0.0479, -0.0282,  0.1151, -0.0185, -0.1037],\n",
       "           [-0.0010,  0.0059, -0.0429, -0.0125, -0.0942],\n",
       "           [ 0.0356, -0.0801,  0.0397,  0.0870, -0.0745],\n",
       "           [-0.0452,  0.0111,  0.0003,  0.0677, -0.0069],\n",
       "           [ 0.0187, -0.0319,  0.0381,  0.0349, -0.0930]],\n",
       " \n",
       "          [[ 0.0613, -0.0237,  0.1034, -0.1146, -0.0115],\n",
       "           [ 0.0522,  0.0796,  0.0015, -0.0624, -0.0893],\n",
       "           [-0.0874,  0.0930, -0.1006, -0.0457,  0.0605],\n",
       "           [ 0.0631, -0.1010,  0.0229,  0.0140,  0.1060],\n",
       "           [-0.0041,  0.0490, -0.0100,  0.1031, -0.0118]]],\n",
       " \n",
       " \n",
       "         [[[-0.0679,  0.0213, -0.0611,  0.0289,  0.0803],\n",
       "           [-0.0898, -0.0840,  0.0016, -0.0068, -0.0359],\n",
       "           [ 0.0967,  0.0518, -0.0383,  0.0167, -0.0174],\n",
       "           [-0.0739,  0.0472, -0.0762,  0.0140,  0.0784],\n",
       "           [-0.1061,  0.0051,  0.1066,  0.0521, -0.0455]],\n",
       " \n",
       "          [[ 0.0182, -0.1084,  0.0185,  0.1004,  0.1003],\n",
       "           [-0.0018,  0.0419, -0.0192, -0.0324,  0.0022],\n",
       "           [-0.0673,  0.0465,  0.0566, -0.0313, -0.0263],\n",
       "           [-0.0805,  0.0148,  0.0459,  0.1096, -0.1088],\n",
       "           [-0.0974,  0.0033,  0.1067,  0.0074,  0.0321]],\n",
       " \n",
       "          [[ 0.0164, -0.0138,  0.0824,  0.0848, -0.0666],\n",
       "           [-0.0692, -0.0898, -0.0281, -0.0026,  0.0966],\n",
       "           [-0.1118,  0.0820, -0.0645,  0.0094, -0.0054],\n",
       "           [ 0.0652, -0.0966, -0.0806,  0.0026,  0.0582],\n",
       "           [-0.0556,  0.0358, -0.0305, -0.1077,  0.0132]]]]),\n",
       " 'layer0.0.bias': tensor([-0.0246,  0.0683,  0.0761,  0.0755,  0.0723, -0.0893, -0.1108,  0.0129,\n",
       "          0.0335, -0.0888,  0.0944, -0.0122, -0.0677,  0.0792,  0.1011,  0.0177,\n",
       "         -0.0368,  0.0125, -0.0851,  0.0712,  0.0725, -0.0216, -0.0915,  0.0857,\n",
       "         -0.0945, -0.0606,  0.0689, -0.0574,  0.0220,  0.0949, -0.0146, -0.0261]),\n",
       " 'layer0.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer0.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.0.weight': tensor([[[[ 0.0546,  0.0101,  0.0206],\n",
       "           [-0.0194, -0.0508,  0.0092],\n",
       "           [-0.0348, -0.0305, -0.0483]],\n",
       " \n",
       "          [[ 0.0505, -0.0396,  0.0170],\n",
       "           [ 0.0121,  0.0407,  0.0322],\n",
       "           [-0.0413,  0.0261, -0.0299]],\n",
       " \n",
       "          [[ 0.0022, -0.0213, -0.0504],\n",
       "           [ 0.0176, -0.0393,  0.0577],\n",
       "           [ 0.0237, -0.0204, -0.0345]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0583,  0.0324,  0.0416],\n",
       "           [ 0.0469,  0.0359, -0.0188],\n",
       "           [ 0.0121,  0.0149, -0.0563]],\n",
       " \n",
       "          [[ 0.0318, -0.0475,  0.0212],\n",
       "           [ 0.0569, -0.0164,  0.0081],\n",
       "           [ 0.0546,  0.0486,  0.0492]],\n",
       " \n",
       "          [[-0.0408,  0.0116, -0.0493],\n",
       "           [ 0.0108, -0.0558,  0.0068],\n",
       "           [ 0.0298, -0.0525, -0.0090]]],\n",
       " \n",
       " \n",
       "         [[[-0.0244,  0.0484, -0.0058],\n",
       "           [ 0.0367, -0.0435,  0.0082],\n",
       "           [ 0.0427,  0.0033, -0.0206]],\n",
       " \n",
       "          [[-0.0241,  0.0402,  0.0232],\n",
       "           [ 0.0040,  0.0348, -0.0307],\n",
       "           [-0.0447, -0.0133,  0.0432]],\n",
       " \n",
       "          [[-0.0570, -0.0293,  0.0143],\n",
       "           [ 0.0222,  0.0295,  0.0178],\n",
       "           [-0.0520, -0.0192,  0.0362]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0269, -0.0078, -0.0461],\n",
       "           [-0.0380, -0.0191, -0.0069],\n",
       "           [-0.0127,  0.0033, -0.0540]],\n",
       " \n",
       "          [[-0.0095, -0.0517,  0.0310],\n",
       "           [ 0.0537, -0.0465, -0.0424],\n",
       "           [ 0.0571,  0.0458,  0.0271]],\n",
       " \n",
       "          [[-0.0372,  0.0185, -0.0019],\n",
       "           [ 0.0444,  0.0367, -0.0067],\n",
       "           [ 0.0230, -0.0515,  0.0101]]],\n",
       " \n",
       " \n",
       "         [[[-0.0359,  0.0468, -0.0428],\n",
       "           [-0.0512, -0.0502, -0.0168],\n",
       "           [ 0.0032, -0.0068,  0.0242]],\n",
       " \n",
       "          [[-0.0523, -0.0346, -0.0082],\n",
       "           [-0.0019, -0.0128,  0.0270],\n",
       "           [ 0.0305, -0.0106, -0.0029]],\n",
       " \n",
       "          [[-0.0092,  0.0058, -0.0247],\n",
       "           [-0.0092, -0.0432,  0.0493],\n",
       "           [ 0.0403, -0.0400,  0.0044]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0401, -0.0285, -0.0259],\n",
       "           [-0.0050, -0.0551,  0.0106],\n",
       "           [ 0.0445,  0.0369, -0.0460]],\n",
       " \n",
       "          [[-0.0178,  0.0308,  0.0211],\n",
       "           [ 0.0263,  0.0247, -0.0142],\n",
       "           [ 0.0390,  0.0552,  0.0218]],\n",
       " \n",
       "          [[-0.0097,  0.0256,  0.0409],\n",
       "           [-0.0466,  0.0163, -0.0281],\n",
       "           [ 0.0030, -0.0391, -0.0109]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0194, -0.0357,  0.0117],\n",
       "           [ 0.0072, -0.0325, -0.0014],\n",
       "           [ 0.0456, -0.0435,  0.0098]],\n",
       " \n",
       "          [[ 0.0320,  0.0543, -0.0537],\n",
       "           [ 0.0267,  0.0560,  0.0403],\n",
       "           [-0.0508, -0.0085, -0.0072]],\n",
       " \n",
       "          [[-0.0085,  0.0042,  0.0038],\n",
       "           [ 0.0312, -0.0462, -0.0416],\n",
       "           [-0.0018, -0.0555,  0.0578]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0169,  0.0042,  0.0447],\n",
       "           [-0.0125,  0.0027,  0.0512],\n",
       "           [-0.0242, -0.0469, -0.0531]],\n",
       " \n",
       "          [[-0.0371, -0.0043, -0.0548],\n",
       "           [-0.0245,  0.0057,  0.0537],\n",
       "           [-0.0011,  0.0426,  0.0344]],\n",
       " \n",
       "          [[-0.0172,  0.0337, -0.0225],\n",
       "           [ 0.0088, -0.0114,  0.0121],\n",
       "           [-0.0192,  0.0237,  0.0269]]],\n",
       " \n",
       " \n",
       "         [[[-0.0037, -0.0553, -0.0541],\n",
       "           [-0.0205, -0.0239,  0.0142],\n",
       "           [ 0.0084, -0.0058,  0.0161]],\n",
       " \n",
       "          [[ 0.0074,  0.0498,  0.0194],\n",
       "           [-0.0311, -0.0490, -0.0356],\n",
       "           [-0.0336,  0.0319, -0.0069]],\n",
       " \n",
       "          [[-0.0362, -0.0574, -0.0031],\n",
       "           [-0.0213, -0.0345,  0.0364],\n",
       "           [ 0.0138, -0.0144,  0.0195]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0320, -0.0554, -0.0148],\n",
       "           [-0.0214,  0.0331,  0.0398],\n",
       "           [ 0.0071,  0.0106, -0.0159]],\n",
       " \n",
       "          [[-0.0255,  0.0531,  0.0584],\n",
       "           [ 0.0261,  0.0347, -0.0573],\n",
       "           [ 0.0132,  0.0088, -0.0572]],\n",
       " \n",
       "          [[ 0.0217, -0.0435,  0.0497],\n",
       "           [ 0.0121,  0.0476, -0.0020],\n",
       "           [-0.0400,  0.0024, -0.0448]]],\n",
       " \n",
       " \n",
       "         [[[-0.0536, -0.0045,  0.0082],\n",
       "           [ 0.0016,  0.0405, -0.0227],\n",
       "           [-0.0341,  0.0054,  0.0062]],\n",
       " \n",
       "          [[-0.0014, -0.0461, -0.0520],\n",
       "           [-0.0377,  0.0143,  0.0103],\n",
       "           [ 0.0545, -0.0154, -0.0308]],\n",
       " \n",
       "          [[-0.0100,  0.0565, -0.0555],\n",
       "           [ 0.0302, -0.0189,  0.0516],\n",
       "           [ 0.0415,  0.0222,  0.0087]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0453, -0.0079,  0.0073],\n",
       "           [-0.0204,  0.0051, -0.0157],\n",
       "           [ 0.0565,  0.0389, -0.0149]],\n",
       " \n",
       "          [[ 0.0438, -0.0230,  0.0282],\n",
       "           [ 0.0552, -0.0253,  0.0328],\n",
       "           [-0.0390, -0.0553,  0.0518]],\n",
       " \n",
       "          [[ 0.0100, -0.0365,  0.0531],\n",
       "           [ 0.0285,  0.0130, -0.0063],\n",
       "           [ 0.0179, -0.0586, -0.0554]]]]),\n",
       " 'layer1.0.bias': tensor([-0.0543, -0.0043, -0.0017,  0.0498, -0.0517,  0.0165,  0.0087,  0.0565,\n",
       "          0.0444, -0.0543, -0.0388,  0.0033,  0.0551,  0.0235,  0.0446, -0.0100,\n",
       "         -0.0346,  0.0379,  0.0387,  0.0266, -0.0253,  0.0476,  0.0511, -0.0268,\n",
       "         -0.0131,  0.0463,  0.0268,  0.0487,  0.0120, -0.0506,  0.0130, -0.0039]),\n",
       " 'layer1.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer1.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.0.weight': tensor([[[[ 5.7134e-02,  2.2763e-03,  7.6729e-03],\n",
       "           [ 2.2283e-02, -5.0950e-02, -1.4664e-02],\n",
       "           [-4.8651e-02, -4.9914e-02,  2.2173e-02]],\n",
       " \n",
       "          [[-2.2566e-02, -3.4802e-02, -5.1511e-02],\n",
       "           [ 5.8050e-02, -4.7091e-02, -4.5683e-02],\n",
       "           [-4.2887e-02, -2.2843e-02,  9.9157e-03]],\n",
       " \n",
       "          [[-1.1733e-02, -4.2466e-02,  3.9983e-02],\n",
       "           [-3.8778e-02, -3.6147e-02,  6.0745e-03],\n",
       "           [-1.9005e-02, -3.8071e-02, -4.7358e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8251e-02, -2.0059e-02, -1.7664e-03],\n",
       "           [ 3.6452e-02, -5.8274e-02, -2.5591e-02],\n",
       "           [ 3.0273e-02,  2.4939e-02, -1.4607e-02]],\n",
       " \n",
       "          [[-5.6558e-02,  1.9704e-02, -1.7753e-02],\n",
       "           [ 2.6979e-02,  5.5089e-02,  1.3478e-02],\n",
       "           [ 2.6325e-02,  5.3409e-02, -1.9308e-02]],\n",
       " \n",
       "          [[ 1.3918e-02, -4.2279e-03,  3.3063e-02],\n",
       "           [ 1.9445e-02, -3.4774e-03,  1.6238e-02],\n",
       "           [ 6.9609e-04, -3.7400e-02,  2.5798e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.9733e-02,  5.1662e-02, -3.5295e-02],\n",
       "           [-4.7838e-03, -2.9584e-02,  1.9393e-02],\n",
       "           [-4.9178e-02,  1.5128e-02,  3.1844e-02]],\n",
       " \n",
       "          [[-4.8651e-02, -2.3051e-02,  4.6810e-02],\n",
       "           [ 2.2733e-02,  3.7091e-02,  7.8823e-03],\n",
       "           [ 4.6600e-05, -3.1117e-02, -2.0206e-02]],\n",
       " \n",
       "          [[-5.0931e-02,  5.2320e-02,  1.5128e-02],\n",
       "           [-1.2424e-02, -3.7507e-02,  2.9012e-04],\n",
       "           [ 1.3300e-02,  4.9583e-03,  2.4148e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8632e-02, -4.4404e-02,  1.1814e-02],\n",
       "           [-1.0807e-02,  4.8829e-02,  4.4790e-02],\n",
       "           [-2.0285e-02,  3.6822e-02,  2.8248e-02]],\n",
       " \n",
       "          [[ 1.7641e-02,  1.0618e-02, -3.1017e-02],\n",
       "           [-3.5140e-02, -1.0367e-02, -4.9357e-03],\n",
       "           [-2.6300e-03,  1.1192e-02, -4.5672e-02]],\n",
       " \n",
       "          [[-3.9225e-03, -3.7740e-02, -5.4893e-02],\n",
       "           [ 2.5574e-02,  5.4951e-02, -2.9725e-02],\n",
       "           [ 1.5240e-02, -3.6052e-02,  3.4700e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.5491e-02, -5.2750e-03, -1.8764e-02],\n",
       "           [-1.7387e-02, -5.2585e-02,  7.1799e-03],\n",
       "           [-2.7637e-02, -4.1692e-02,  3.6744e-02]],\n",
       " \n",
       "          [[ 2.0283e-02, -4.8516e-02, -2.9705e-02],\n",
       "           [ 3.5179e-02,  2.7032e-02,  5.6624e-02],\n",
       "           [-3.8420e-03,  1.8063e-02, -2.4304e-02]],\n",
       " \n",
       "          [[-3.5589e-02, -2.8323e-02, -3.3601e-03],\n",
       "           [-6.5405e-04, -5.8679e-02,  5.0192e-02],\n",
       "           [-3.0432e-02, -3.8527e-02, -4.3469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2697e-02, -1.4331e-02,  5.0963e-02],\n",
       "           [ 5.5813e-02,  1.8976e-02,  1.3342e-02],\n",
       "           [ 2.3138e-02,  3.1858e-02,  3.6571e-02]],\n",
       " \n",
       "          [[ 3.4722e-02, -2.1318e-02,  5.0169e-02],\n",
       "           [ 1.3877e-02,  1.4181e-02,  2.9957e-02],\n",
       "           [ 4.5517e-02,  2.8146e-02,  4.4315e-02]],\n",
       " \n",
       "          [[-2.2685e-02,  3.5278e-02, -7.6343e-03],\n",
       "           [ 3.1103e-02, -1.9444e-02, -2.7423e-02],\n",
       "           [ 5.1713e-02, -2.1571e-02, -4.5952e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-5.5247e-02,  3.1720e-02,  2.1539e-02],\n",
       "           [-3.8513e-02, -4.7985e-02, -3.3430e-02],\n",
       "           [-3.0489e-02, -1.7572e-02,  4.2375e-02]],\n",
       " \n",
       "          [[ 4.4120e-02,  5.4889e-02,  2.4734e-02],\n",
       "           [ 3.6550e-03, -4.3214e-02, -2.4624e-03],\n",
       "           [-4.2030e-02,  4.0658e-02, -5.2674e-02]],\n",
       " \n",
       "          [[-7.3320e-03, -7.3222e-03,  3.7609e-02],\n",
       "           [-3.0710e-02, -4.8105e-02, -1.4401e-02],\n",
       "           [-3.6586e-03,  1.9842e-02,  1.5428e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9497e-02, -3.2710e-02, -5.1007e-02],\n",
       "           [-1.2096e-02,  4.4725e-02,  4.9262e-02],\n",
       "           [-4.5488e-02,  5.7023e-02, -1.3938e-02]],\n",
       " \n",
       "          [[ 2.6453e-02, -5.3338e-02,  4.9874e-03],\n",
       "           [ 4.9443e-02,  4.6337e-02,  4.6237e-02],\n",
       "           [ 1.9181e-02, -2.0657e-02, -4.5685e-02]],\n",
       " \n",
       "          [[-2.5192e-03,  2.8761e-02, -4.2599e-02],\n",
       "           [-4.8064e-03,  2.7911e-02, -3.7541e-02],\n",
       "           [-5.1003e-02,  1.0393e-02,  5.6107e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0096e-02,  8.2636e-03,  3.3643e-02],\n",
       "           [-3.5483e-02,  3.9823e-02, -5.1088e-02],\n",
       "           [-5.2329e-02, -7.8036e-03, -2.6994e-02]],\n",
       " \n",
       "          [[ 5.0138e-02, -1.2705e-03,  5.5152e-02],\n",
       "           [ 4.8575e-02, -2.8620e-02,  4.0724e-02],\n",
       "           [ 4.4372e-02, -5.5048e-02,  8.2719e-03]],\n",
       " \n",
       "          [[-3.6917e-03, -4.8237e-02,  1.4326e-02],\n",
       "           [ 5.8474e-02,  9.2294e-04,  5.3283e-02],\n",
       "           [ 3.6018e-02,  1.5803e-02, -4.4104e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.2120e-02, -2.1614e-02,  1.7018e-02],\n",
       "           [-4.2496e-02, -5.5788e-02,  2.9173e-02],\n",
       "           [-4.1194e-02,  3.2194e-03,  2.2686e-02]],\n",
       " \n",
       "          [[ 5.4017e-02,  1.5278e-02, -3.9786e-02],\n",
       "           [ 3.6710e-03, -4.5804e-02, -3.8354e-02],\n",
       "           [-2.4702e-02,  3.4668e-02, -4.7339e-02]],\n",
       " \n",
       "          [[ 5.3430e-02,  1.8570e-02, -3.7024e-02],\n",
       "           [-5.7286e-02,  2.4916e-02, -2.3010e-02],\n",
       "           [ 3.4885e-02, -2.9613e-02,  1.6202e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.0582e-02, -2.6968e-02, -2.8093e-02],\n",
       "           [-8.5723e-04, -1.6351e-02, -1.8424e-02],\n",
       "           [ 3.6358e-02, -2.9207e-02,  4.2901e-02]],\n",
       " \n",
       "          [[ 5.2379e-02,  2.7298e-02, -3.8665e-02],\n",
       "           [ 4.7064e-02, -1.9328e-02,  5.7603e-02],\n",
       "           [ 3.4986e-02,  3.6665e-02, -9.3917e-03]],\n",
       " \n",
       "          [[ 3.7847e-02,  5.5604e-02,  1.2676e-02],\n",
       "           [ 5.7904e-02,  4.6458e-02, -1.0816e-02],\n",
       "           [ 1.4825e-02,  3.0120e-02, -2.4013e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.5582e-02,  7.9506e-03, -5.3923e-02],\n",
       "           [ 3.4684e-02,  3.2537e-03, -8.8748e-03],\n",
       "           [ 5.1414e-02,  2.1381e-02, -4.7578e-02]],\n",
       " \n",
       "          [[-1.9648e-02, -5.0517e-02, -1.2699e-02],\n",
       "           [ 2.0551e-02,  3.4886e-02, -1.7081e-02],\n",
       "           [ 4.5170e-02,  4.6150e-02,  2.6860e-02]],\n",
       " \n",
       "          [[-1.7783e-02,  3.7673e-02,  3.8889e-02],\n",
       "           [-4.2494e-02, -3.3087e-02,  4.2578e-02],\n",
       "           [-1.9450e-02, -4.6741e-02, -2.9636e-02]]]]),\n",
       " 'layer2.0.bias': tensor([-0.0029, -0.0226, -0.0220, -0.0451, -0.0162,  0.0195,  0.0535, -0.0280,\n",
       "         -0.0340,  0.0170,  0.0581,  0.0215, -0.0449,  0.0488,  0.0284,  0.0110,\n",
       "         -0.0304, -0.0164, -0.0357, -0.0168,  0.0295,  0.0206, -0.0200,  0.0095,\n",
       "         -0.0089,  0.0315,  0.0465,  0.0486, -0.0454,  0.0323,  0.0181, -0.0093]),\n",
       " 'layer2.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer2.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.0.weight': tensor([[[[ 0.0349,  0.0080,  0.0391],\n",
       "           [ 0.0168,  0.0509,  0.0433],\n",
       "           [ 0.0178,  0.0479, -0.0166]],\n",
       " \n",
       "          [[-0.0273, -0.0540, -0.0191],\n",
       "           [-0.0348, -0.0212, -0.0429],\n",
       "           [-0.0271, -0.0277,  0.0539]],\n",
       " \n",
       "          [[ 0.0317, -0.0411, -0.0299],\n",
       "           [ 0.0163, -0.0236,  0.0418],\n",
       "           [ 0.0094, -0.0482, -0.0238]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0558,  0.0193, -0.0203],\n",
       "           [-0.0455, -0.0138,  0.0564],\n",
       "           [ 0.0082, -0.0449, -0.0450]],\n",
       " \n",
       "          [[ 0.0185, -0.0095, -0.0317],\n",
       "           [ 0.0377,  0.0436, -0.0243],\n",
       "           [ 0.0119, -0.0278, -0.0025]],\n",
       " \n",
       "          [[-0.0028,  0.0118,  0.0340],\n",
       "           [-0.0475, -0.0382,  0.0570],\n",
       "           [ 0.0181,  0.0342, -0.0580]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0275, -0.0282,  0.0214],\n",
       "           [ 0.0168, -0.0525,  0.0339],\n",
       "           [ 0.0271, -0.0350,  0.0188]],\n",
       " \n",
       "          [[-0.0379,  0.0073,  0.0297],\n",
       "           [-0.0505,  0.0464, -0.0274],\n",
       "           [-0.0421,  0.0336,  0.0277]],\n",
       " \n",
       "          [[-0.0463,  0.0101, -0.0216],\n",
       "           [ 0.0380, -0.0448,  0.0118],\n",
       "           [-0.0039,  0.0029,  0.0205]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0137, -0.0485,  0.0479],\n",
       "           [ 0.0140,  0.0290,  0.0492],\n",
       "           [-0.0348,  0.0098, -0.0530]],\n",
       " \n",
       "          [[ 0.0022,  0.0261,  0.0222],\n",
       "           [-0.0144, -0.0012,  0.0539],\n",
       "           [-0.0323, -0.0358,  0.0455]],\n",
       " \n",
       "          [[-0.0019, -0.0225,  0.0147],\n",
       "           [-0.0320,  0.0233,  0.0163],\n",
       "           [ 0.0575,  0.0426, -0.0043]]],\n",
       " \n",
       " \n",
       "         [[[-0.0363, -0.0312,  0.0324],\n",
       "           [-0.0358,  0.0405, -0.0376],\n",
       "           [-0.0349,  0.0389, -0.0300]],\n",
       " \n",
       "          [[ 0.0290,  0.0511,  0.0255],\n",
       "           [ 0.0415,  0.0384, -0.0417],\n",
       "           [ 0.0170,  0.0173,  0.0497]],\n",
       " \n",
       "          [[-0.0512,  0.0508,  0.0123],\n",
       "           [ 0.0372, -0.0387, -0.0135],\n",
       "           [ 0.0373,  0.0515,  0.0059]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0423, -0.0471, -0.0543],\n",
       "           [-0.0494,  0.0340,  0.0193],\n",
       "           [ 0.0132, -0.0222, -0.0134]],\n",
       " \n",
       "          [[-0.0555,  0.0462, -0.0468],\n",
       "           [-0.0407,  0.0341, -0.0243],\n",
       "           [ 0.0366, -0.0470, -0.0287]],\n",
       " \n",
       "          [[ 0.0117,  0.0141, -0.0320],\n",
       "           [ 0.0347,  0.0127, -0.0439],\n",
       "           [-0.0045,  0.0420,  0.0280]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0276, -0.0193, -0.0327],\n",
       "           [ 0.0056, -0.0327, -0.0540],\n",
       "           [ 0.0408, -0.0589,  0.0439]],\n",
       " \n",
       "          [[ 0.0170,  0.0479,  0.0354],\n",
       "           [-0.0253,  0.0351,  0.0472],\n",
       "           [-0.0431,  0.0366,  0.0009]],\n",
       " \n",
       "          [[-0.0452,  0.0521, -0.0156],\n",
       "           [ 0.0237,  0.0153,  0.0115],\n",
       "           [ 0.0114,  0.0531, -0.0215]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0174, -0.0583, -0.0320],\n",
       "           [ 0.0349,  0.0220,  0.0481],\n",
       "           [-0.0178,  0.0080,  0.0153]],\n",
       " \n",
       "          [[ 0.0321,  0.0128,  0.0074],\n",
       "           [ 0.0360,  0.0581, -0.0427],\n",
       "           [ 0.0326,  0.0437, -0.0364]],\n",
       " \n",
       "          [[ 0.0378, -0.0583, -0.0260],\n",
       "           [-0.0287,  0.0527, -0.0389],\n",
       "           [ 0.0347, -0.0302, -0.0554]]],\n",
       " \n",
       " \n",
       "         [[[-0.0092, -0.0467, -0.0299],\n",
       "           [ 0.0316, -0.0589, -0.0055],\n",
       "           [ 0.0511, -0.0071, -0.0279]],\n",
       " \n",
       "          [[-0.0223,  0.0226, -0.0080],\n",
       "           [ 0.0587, -0.0140, -0.0529],\n",
       "           [-0.0343,  0.0180,  0.0249]],\n",
       " \n",
       "          [[-0.0064,  0.0322,  0.0150],\n",
       "           [-0.0121,  0.0542, -0.0135],\n",
       "           [-0.0501, -0.0066,  0.0361]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0131, -0.0132,  0.0006],\n",
       "           [-0.0170,  0.0108,  0.0513],\n",
       "           [-0.0477, -0.0503, -0.0247]],\n",
       " \n",
       "          [[ 0.0012,  0.0428,  0.0357],\n",
       "           [ 0.0526,  0.0207, -0.0433],\n",
       "           [ 0.0550,  0.0501,  0.0588]],\n",
       " \n",
       "          [[ 0.0333, -0.0109,  0.0188],\n",
       "           [-0.0043, -0.0551,  0.0034],\n",
       "           [ 0.0480,  0.0101, -0.0003]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0053,  0.0389,  0.0388],\n",
       "           [ 0.0026, -0.0537, -0.0568],\n",
       "           [-0.0342,  0.0285, -0.0239]],\n",
       " \n",
       "          [[ 0.0492,  0.0006,  0.0106],\n",
       "           [-0.0431, -0.0318,  0.0212],\n",
       "           [ 0.0052, -0.0454, -0.0238]],\n",
       " \n",
       "          [[ 0.0561,  0.0425, -0.0006],\n",
       "           [-0.0442,  0.0060, -0.0096],\n",
       "           [-0.0088, -0.0156,  0.0323]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0413, -0.0057, -0.0351],\n",
       "           [ 0.0050,  0.0508, -0.0194],\n",
       "           [-0.0276,  0.0149, -0.0189]],\n",
       " \n",
       "          [[-0.0123, -0.0535,  0.0464],\n",
       "           [-0.0081,  0.0378,  0.0531],\n",
       "           [-0.0053, -0.0570, -0.0249]],\n",
       " \n",
       "          [[ 0.0173, -0.0353,  0.0536],\n",
       "           [ 0.0449, -0.0072, -0.0557],\n",
       "           [-0.0291, -0.0258, -0.0001]]]]),\n",
       " 'layer3.0.bias': tensor([-0.0553,  0.0040,  0.0108, -0.0160,  0.0396,  0.0470,  0.0212,  0.0019,\n",
       "          0.0513, -0.0497,  0.0139, -0.0532,  0.0565, -0.0235,  0.0157,  0.0309,\n",
       "          0.0052,  0.0123, -0.0224, -0.0405,  0.0552,  0.0039,  0.0070, -0.0347,\n",
       "          0.0450,  0.0507, -0.0266,  0.0296,  0.0268,  0.0458,  0.0275, -0.0472,\n",
       "          0.0478, -0.0509,  0.0154, -0.0372,  0.0560, -0.0417, -0.0460,  0.0035,\n",
       "         -0.0077,  0.0466, -0.0062, -0.0025, -0.0086,  0.0558,  0.0206,  0.0366,\n",
       "          0.0067,  0.0200, -0.0214, -0.0477, -0.0559, -0.0190,  0.0371,  0.0582,\n",
       "          0.0312, -0.0585, -0.0531, -0.0584,  0.0278, -0.0551,  0.0183,  0.0443]),\n",
       " 'layer3.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer3.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.0.weight': tensor([[[[ 2.5620e-02,  1.1027e-02,  3.8344e-02],\n",
       "           [-5.6369e-04, -1.3636e-02, -1.1476e-02],\n",
       "           [ 2.4599e-02, -1.7833e-02,  1.0314e-02]],\n",
       " \n",
       "          [[-3.6600e-02,  1.6459e-02,  8.5596e-03],\n",
       "           [-2.3940e-02,  3.1190e-02,  1.1611e-03],\n",
       "           [-2.8263e-02, -2.6966e-02, -1.9842e-02]],\n",
       " \n",
       "          [[-2.2325e-02,  1.7213e-02,  1.4972e-02],\n",
       "           [ 1.2437e-03, -1.6358e-02,  2.6994e-02],\n",
       "           [ 6.8585e-03,  4.8376e-04,  2.7526e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0617e-02, -2.6364e-02,  3.6131e-02],\n",
       "           [ 2.8148e-02,  1.4054e-02, -2.4607e-02],\n",
       "           [-6.4064e-03,  3.6277e-02,  6.3002e-03]],\n",
       " \n",
       "          [[-2.6183e-02, -1.6960e-02, -3.2769e-02],\n",
       "           [ 3.3250e-02, -1.0777e-02,  3.2396e-02],\n",
       "           [-8.2837e-03,  3.9580e-02,  2.3819e-02]],\n",
       " \n",
       "          [[ 1.0965e-02, -3.6820e-02, -1.8887e-02],\n",
       "           [ 5.6978e-03, -3.5669e-02, -1.5734e-02],\n",
       "           [-1.7920e-02,  1.7379e-02, -3.0323e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7890e-02,  1.4734e-02,  1.2198e-02],\n",
       "           [-2.2439e-02,  4.1251e-02, -2.5036e-02],\n",
       "           [ 5.7460e-03, -1.1964e-02, -2.5474e-02]],\n",
       " \n",
       "          [[-2.0505e-02,  1.5931e-02,  1.7208e-02],\n",
       "           [-2.7738e-02, -3.5588e-02, -8.7796e-03],\n",
       "           [ 2.6947e-03,  2.5921e-03, -1.3987e-02]],\n",
       " \n",
       "          [[-7.3796e-03, -1.7497e-02,  3.8538e-03],\n",
       "           [ 2.2572e-02, -1.0772e-02,  5.4893e-03],\n",
       "           [ 4.1398e-02, -2.8769e-02, -1.4876e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5627e-02, -2.2806e-03,  1.0660e-02],\n",
       "           [ 3.1863e-03, -3.0281e-02,  3.9491e-02],\n",
       "           [-2.6706e-02, -4.1496e-02, -3.4536e-02]],\n",
       " \n",
       "          [[ 1.2076e-02, -2.2478e-03,  2.5527e-02],\n",
       "           [-5.1937e-03,  7.0800e-04,  2.4908e-02],\n",
       "           [ 3.5183e-02,  2.8290e-03, -1.1281e-02]],\n",
       " \n",
       "          [[ 3.3812e-02,  2.9348e-02,  2.4271e-02],\n",
       "           [ 4.3343e-03,  1.9623e-02,  2.9991e-02],\n",
       "           [ 3.7585e-02,  6.1731e-03, -1.6640e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5880e-02, -6.0504e-03,  2.0034e-03],\n",
       "           [-3.7352e-02, -7.3350e-03,  2.5647e-02],\n",
       "           [ 2.4312e-02, -8.3213e-03,  3.5337e-03]],\n",
       " \n",
       "          [[-3.0441e-02,  6.6977e-03, -1.9300e-02],\n",
       "           [ 3.0446e-02, -7.7699e-03, -5.5637e-03],\n",
       "           [ 1.3507e-02,  2.9579e-02,  3.1732e-02]],\n",
       " \n",
       "          [[-1.2611e-02,  2.5706e-02,  6.1131e-03],\n",
       "           [ 6.8956e-03, -1.2875e-02,  1.7288e-02],\n",
       "           [ 6.3988e-03,  1.7031e-02, -1.8602e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.2298e-03,  3.1480e-02, -2.4839e-02],\n",
       "           [-9.5341e-05, -3.4622e-02,  3.4004e-02],\n",
       "           [-1.9048e-02,  1.2274e-02, -3.6575e-02]],\n",
       " \n",
       "          [[ 2.3614e-02, -1.8650e-02, -2.2995e-02],\n",
       "           [ 1.8063e-02,  3.1919e-02, -3.8414e-02],\n",
       "           [ 3.2621e-02, -2.6842e-02,  2.1469e-02]],\n",
       " \n",
       "          [[ 2.2439e-02,  2.9607e-02, -3.4393e-03],\n",
       "           [ 1.2774e-02, -1.5567e-02,  2.1473e-02],\n",
       "           [-3.5595e-02, -1.9984e-02,  1.7679e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.8253e-03, -3.3776e-02,  4.0900e-02],\n",
       "           [ 2.1382e-02,  2.7088e-02,  4.6202e-04],\n",
       "           [-3.8172e-04,  1.4354e-02, -2.0458e-02]],\n",
       " \n",
       "          [[ 2.8361e-02, -3.9402e-02,  2.3592e-02],\n",
       "           [-1.6914e-02,  3.1797e-02,  1.0471e-02],\n",
       "           [-3.2137e-02,  2.4701e-03, -2.4310e-02]],\n",
       " \n",
       "          [[ 3.4360e-02,  9.9863e-03,  3.2582e-02],\n",
       "           [-3.5713e-02,  2.1561e-02,  2.0948e-02],\n",
       "           [ 2.8734e-02, -2.4535e-02, -1.9657e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8352e-02, -3.0637e-02, -4.1497e-02],\n",
       "           [-2.1351e-02,  1.9204e-02,  6.9097e-03],\n",
       "           [ 9.2071e-03, -2.6410e-02, -2.4193e-03]],\n",
       " \n",
       "          [[ 3.6037e-02,  3.7034e-02,  2.1712e-02],\n",
       "           [-1.5547e-02,  4.0763e-02, -2.4413e-02],\n",
       "           [-3.5063e-02, -6.3464e-03,  1.9633e-02]],\n",
       " \n",
       "          [[-1.1322e-02, -1.5831e-02, -2.7898e-02],\n",
       "           [-1.1176e-02, -4.0802e-02, -1.6075e-03],\n",
       "           [ 7.4114e-03, -1.5146e-02, -2.5475e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.6118e-02,  2.1552e-02, -3.4662e-02],\n",
       "           [-2.2085e-03,  1.5897e-02,  3.3573e-02],\n",
       "           [ 3.4382e-02,  2.0942e-02, -6.2279e-03]],\n",
       " \n",
       "          [[ 2.4146e-02, -3.4124e-02, -3.2239e-02],\n",
       "           [ 2.6915e-02,  1.0536e-02, -3.2622e-02],\n",
       "           [ 2.0656e-02, -1.9801e-02,  4.4186e-03]],\n",
       " \n",
       "          [[-1.3196e-02, -6.5854e-04,  3.5568e-02],\n",
       "           [-4.1158e-02,  1.5582e-02, -3.1423e-02],\n",
       "           [-9.3038e-04,  4.6161e-03, -1.9687e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6987e-03,  7.5396e-03, -7.5504e-03],\n",
       "           [ 9.4232e-03,  2.9016e-02,  2.9479e-02],\n",
       "           [-3.7800e-02,  7.1434e-03, -2.1037e-02]],\n",
       " \n",
       "          [[-1.7767e-02,  7.6964e-03,  6.1694e-03],\n",
       "           [ 2.9679e-02,  1.3413e-02, -7.4646e-04],\n",
       "           [-1.9178e-02, -9.6990e-03, -3.2808e-02]],\n",
       " \n",
       "          [[-3.6097e-02,  2.4256e-02,  3.8199e-02],\n",
       "           [-2.4204e-02, -3.6429e-02, -2.7111e-02],\n",
       "           [ 2.0422e-02,  3.4729e-03,  3.5056e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2510e-02, -1.9212e-02,  2.3803e-02],\n",
       "           [ 1.3745e-02, -2.2359e-02,  2.6260e-02],\n",
       "           [-4.0578e-02,  3.3985e-02,  2.1799e-02]],\n",
       " \n",
       "          [[-6.0673e-03,  3.1644e-02,  3.4686e-03],\n",
       "           [ 3.6875e-02, -4.1006e-02, -6.1496e-03],\n",
       "           [ 7.4729e-03,  1.8152e-03, -1.0912e-02]],\n",
       " \n",
       "          [[-2.6291e-02, -1.4366e-03,  2.9217e-03],\n",
       "           [ 1.3097e-02,  3.0829e-02, -3.4937e-02],\n",
       "           [-3.4530e-02, -3.6971e-02,  1.4080e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6622e-03,  2.5039e-02,  2.8354e-02],\n",
       "           [ 2.3704e-02,  8.1194e-03,  1.8403e-02],\n",
       "           [ 3.3893e-02, -2.9643e-02, -2.5597e-02]],\n",
       " \n",
       "          [[-5.5600e-03,  3.8782e-02,  1.3900e-03],\n",
       "           [-1.6761e-02,  9.2933e-03,  9.7108e-03],\n",
       "           [-2.1357e-03,  3.8266e-02,  3.8584e-02]],\n",
       " \n",
       "          [[ 1.8071e-02,  7.9090e-03,  1.1067e-02],\n",
       "           [ 1.0860e-02,  9.1985e-03,  9.1101e-03],\n",
       "           [ 5.3729e-03, -2.3801e-02, -3.0802e-02]]]]),\n",
       " 'layer4.0.bias': tensor([ 0.0177, -0.0163, -0.0093,  0.0162, -0.0377,  0.0078,  0.0001,  0.0027,\n",
       "         -0.0377,  0.0106, -0.0282,  0.0339, -0.0121, -0.0010, -0.0151, -0.0266,\n",
       "          0.0306,  0.0092, -0.0270,  0.0387,  0.0071,  0.0043,  0.0337, -0.0290,\n",
       "          0.0054, -0.0309, -0.0099,  0.0037,  0.0143,  0.0311, -0.0226, -0.0143,\n",
       "         -0.0285, -0.0150,  0.0323,  0.0416,  0.0100, -0.0162, -0.0373,  0.0130,\n",
       "         -0.0095,  0.0198,  0.0192, -0.0277,  0.0032,  0.0406,  0.0073, -0.0256,\n",
       "         -0.0246,  0.0203,  0.0312, -0.0264, -0.0383, -0.0415, -0.0085, -0.0052,\n",
       "         -0.0147,  0.0275,  0.0078,  0.0238,  0.0250,  0.0253, -0.0249,  0.0367]),\n",
       " 'layer4.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer4.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer5.0.weight': tensor([[[[ 4.0029e-02, -1.5555e-02, -1.9442e-02],\n",
       "           [ 2.7807e-02,  1.2606e-03,  2.2996e-02],\n",
       "           [ 1.6510e-02, -1.8767e-02,  1.4049e-02]],\n",
       " \n",
       "          [[-2.0909e-02,  3.2355e-03,  4.8950e-04],\n",
       "           [ 3.5541e-02, -2.6028e-02, -2.1366e-02],\n",
       "           [-1.8651e-02, -1.4314e-02, -1.5306e-04]],\n",
       " \n",
       "          [[-2.3171e-02,  1.9146e-02,  1.5210e-03],\n",
       "           [ 1.9624e-02, -1.5651e-02, -2.6014e-02],\n",
       "           [-3.2673e-02,  1.8227e-02,  3.6811e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4583e-02, -7.9460e-06, -1.4085e-02],\n",
       "           [ 2.8421e-02, -1.1669e-02,  1.9115e-02],\n",
       "           [ 3.0063e-02,  1.8295e-02, -2.4148e-02]],\n",
       " \n",
       "          [[-3.0112e-02,  3.7937e-02,  3.5968e-02],\n",
       "           [ 1.3086e-02, -1.0907e-02,  2.0002e-02],\n",
       "           [-5.9486e-03,  6.4267e-03, -1.3565e-02]],\n",
       " \n",
       "          [[ 3.3119e-02,  2.9293e-02,  4.7366e-03],\n",
       "           [ 1.3828e-02, -8.6379e-04, -3.8102e-02],\n",
       "           [ 2.7153e-02,  3.1091e-02,  1.0126e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.4183e-03, -1.7757e-03, -2.0380e-02],\n",
       "           [-1.5854e-02, -2.6645e-02,  7.1543e-03],\n",
       "           [ 6.6951e-03, -1.8744e-02, -1.2158e-02]],\n",
       " \n",
       "          [[ 1.2498e-02,  2.4377e-02,  2.7904e-02],\n",
       "           [ 3.8156e-02,  3.0734e-02,  8.7722e-03],\n",
       "           [ 2.6730e-02, -3.1139e-02,  3.4744e-02]],\n",
       " \n",
       "          [[ 2.6575e-02,  2.4073e-02, -3.0729e-02],\n",
       "           [ 2.7972e-02, -3.6623e-02,  2.2270e-02],\n",
       "           [-2.7218e-02,  3.9759e-02, -2.6646e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.4700e-03,  2.2825e-03,  3.6883e-02],\n",
       "           [ 2.7217e-02, -3.1232e-02,  3.1608e-02],\n",
       "           [-1.0017e-02,  3.1206e-02, -3.9591e-02]],\n",
       " \n",
       "          [[-2.9666e-02, -4.0470e-02, -6.2156e-03],\n",
       "           [ 3.0331e-02, -3.6313e-04, -1.9975e-02],\n",
       "           [-3.7550e-02,  2.9411e-02, -3.2907e-02]],\n",
       " \n",
       "          [[ 2.4071e-03,  2.2413e-02,  2.5404e-02],\n",
       "           [ 1.3434e-02, -3.0588e-02,  9.5532e-04],\n",
       "           [-3.2427e-02,  1.6529e-02, -1.6419e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.3955e-02,  7.1121e-03,  2.6891e-02],\n",
       "           [ 4.0416e-02, -3.3873e-02, -1.3531e-02],\n",
       "           [ 1.8637e-02,  5.2441e-05,  2.1841e-02]],\n",
       " \n",
       "          [[-1.7873e-02,  3.0563e-02,  1.1849e-02],\n",
       "           [ 9.3570e-03, -1.1101e-02,  8.0893e-03],\n",
       "           [-8.1875e-03, -1.7321e-02, -9.3326e-05]],\n",
       " \n",
       "          [[-2.1851e-02,  4.0022e-02,  8.1340e-03],\n",
       "           [ 1.9282e-02, -2.6939e-02,  1.7700e-02],\n",
       "           [ 7.5512e-03,  3.9676e-02, -3.6485e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.8432e-03,  1.4899e-02,  2.2023e-02],\n",
       "           [-5.1086e-03, -4.1410e-03, -1.7824e-02],\n",
       "           [ 3.6685e-02, -3.0121e-02, -2.4863e-02]],\n",
       " \n",
       "          [[ 7.5307e-03,  2.6082e-02,  2.2635e-02],\n",
       "           [-3.3264e-02, -1.2277e-02, -1.2866e-02],\n",
       "           [ 3.9813e-02, -1.0466e-02, -7.6253e-03]],\n",
       " \n",
       "          [[-3.7760e-02,  7.5000e-03, -5.7763e-03],\n",
       "           [-3.5322e-02,  3.6979e-02,  2.8847e-03],\n",
       "           [ 6.5473e-03,  3.5336e-02, -5.7323e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.4297e-02, -3.6211e-02,  2.7521e-02],\n",
       "           [-9.7694e-03,  1.5891e-02,  1.4592e-02],\n",
       "           [-3.0556e-02,  9.3818e-03,  4.0286e-02]],\n",
       " \n",
       "          [[-2.7050e-02, -1.7057e-02,  2.0408e-02],\n",
       "           [ 2.3277e-02,  3.4720e-02, -2.5510e-02],\n",
       "           [ 3.2969e-02, -3.7801e-02, -2.1019e-02]],\n",
       " \n",
       "          [[ 3.2294e-02, -5.6080e-03,  3.2732e-02],\n",
       "           [ 8.6077e-03,  2.3426e-02, -2.1425e-02],\n",
       "           [-2.0202e-03,  2.7345e-02,  3.4072e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1652e-02,  3.0896e-02, -2.1383e-02],\n",
       "           [ 3.9330e-02, -3.5811e-02,  1.0374e-02],\n",
       "           [ 1.3004e-02,  1.1354e-02, -3.0207e-02]],\n",
       " \n",
       "          [[-1.4926e-02, -2.4606e-02, -2.8183e-02],\n",
       "           [ 2.0890e-03,  3.1961e-02, -2.7149e-02],\n",
       "           [ 3.3376e-02, -4.2753e-03,  1.3732e-02]],\n",
       " \n",
       "          [[-3.1865e-02,  2.2441e-02, -2.7422e-02],\n",
       "           [ 3.6593e-02, -1.8769e-02, -1.5301e-02],\n",
       "           [ 1.6204e-02,  1.2891e-02, -2.4532e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5621e-02, -7.0786e-03, -1.0761e-02],\n",
       "           [-5.0155e-03, -3.1408e-02,  3.0269e-02],\n",
       "           [ 3.1515e-02, -2.1544e-02,  2.6874e-04]],\n",
       " \n",
       "          [[-4.1376e-02, -6.8147e-04, -2.9623e-02],\n",
       "           [-2.8259e-02,  3.9103e-03, -2.5514e-02],\n",
       "           [ 4.5687e-03, -1.8919e-02, -7.3692e-03]],\n",
       " \n",
       "          [[-2.4708e-02, -2.0455e-02, -1.3034e-02],\n",
       "           [ 2.2828e-02,  4.3709e-04,  3.2861e-02],\n",
       "           [ 1.2342e-02,  3.5667e-02, -2.3626e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7968e-02,  2.0814e-02, -1.4589e-02],\n",
       "           [ 3.5259e-02,  3.3609e-02,  1.2301e-02],\n",
       "           [ 7.3563e-03, -1.7608e-02,  2.7465e-02]],\n",
       " \n",
       "          [[ 6.1034e-03, -1.7165e-02, -6.9117e-03],\n",
       "           [ 2.9456e-02,  3.4874e-02,  1.7228e-02],\n",
       "           [ 3.4576e-02,  1.7019e-02, -2.9988e-02]],\n",
       " \n",
       "          [[-3.0170e-02, -2.8234e-02,  3.7775e-02],\n",
       "           [ 3.1383e-02,  3.2691e-02,  3.0495e-02],\n",
       "           [ 3.4685e-03, -1.7589e-02,  2.4322e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7058e-04, -2.9093e-02, -4.0108e-02],\n",
       "           [ 3.2973e-02,  1.0041e-02,  2.1036e-02],\n",
       "           [-2.9385e-02, -6.8148e-03,  3.9885e-02]],\n",
       " \n",
       "          [[ 2.3979e-03, -3.9971e-02, -1.7004e-02],\n",
       "           [-3.3634e-02,  1.1719e-02, -2.8307e-02],\n",
       "           [-3.2483e-02, -1.1167e-02,  1.5263e-02]],\n",
       " \n",
       "          [[ 6.7131e-03,  3.7708e-02,  3.4297e-02],\n",
       "           [ 2.8094e-02,  3.8445e-02,  3.6810e-05],\n",
       "           [ 8.6228e-03,  1.4023e-02,  2.4469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.1655e-02,  3.6069e-02, -1.6624e-02],\n",
       "           [ 2.2531e-02,  3.7367e-02, -2.7337e-02],\n",
       "           [-5.4987e-03, -3.2980e-03, -2.1241e-02]],\n",
       " \n",
       "          [[-2.5833e-03,  4.0529e-02, -2.8201e-02],\n",
       "           [ 7.9990e-03, -1.9770e-02, -9.0786e-03],\n",
       "           [ 1.9084e-02,  1.7834e-02,  1.1820e-02]],\n",
       " \n",
       "          [[-2.1395e-02, -1.0014e-02,  3.2037e-02],\n",
       "           [ 7.6473e-03,  2.1263e-02,  2.7528e-02],\n",
       "           [ 6.0682e-03,  1.0778e-02,  3.1273e-02]]]]),\n",
       " 'layer5.0.bias': tensor([-0.0339, -0.0223, -0.0282,  0.0156, -0.0012,  0.0039, -0.0381, -0.0168,\n",
       "         -0.0001,  0.0406, -0.0392, -0.0376,  0.0081, -0.0122,  0.0069, -0.0187,\n",
       "         -0.0228,  0.0056,  0.0213,  0.0152, -0.0076,  0.0395,  0.0266,  0.0247,\n",
       "         -0.0403, -0.0306,  0.0379, -0.0167, -0.0330, -0.0408, -0.0215,  0.0353,\n",
       "         -0.0026, -0.0162, -0.0388, -0.0065, -0.0216,  0.0155, -0.0153, -0.0108,\n",
       "         -0.0357, -0.0315, -0.0267, -0.0286, -0.0062, -0.0391,  0.0140, -0.0273,\n",
       "          0.0051,  0.0157, -0.0315, -0.0401,  0.0289, -0.0257, -0.0148,  0.0070,\n",
       "          0.0054,  0.0089, -0.0287, -0.0140, -0.0269,  0.0319, -0.0325, -0.0247]),\n",
       " 'linear.weight': tensor([[ 0.0916,  0.0274,  0.0482, -0.0863,  0.0164, -0.0115, -0.0446,  0.1144,\n",
       "           0.0822,  0.0646,  0.0713,  0.0645,  0.0248,  0.0175,  0.0264,  0.0958,\n",
       "           0.1223,  0.0784, -0.0136,  0.1037,  0.0573,  0.0770, -0.0095, -0.0206,\n",
       "           0.1065,  0.0468,  0.0714,  0.1024,  0.0972, -0.0708, -0.0112,  0.0418,\n",
       "          -0.0384, -0.1069, -0.0260, -0.1035,  0.0921, -0.0480, -0.0806, -0.0412,\n",
       "           0.1044, -0.1037,  0.0918,  0.1132, -0.0616,  0.0739,  0.0543,  0.0419,\n",
       "          -0.1071,  0.0925, -0.0029, -0.0504, -0.1013, -0.1048, -0.1139,  0.0840,\n",
       "           0.0123, -0.0573,  0.0097,  0.1013,  0.0002,  0.0757, -0.1092, -0.0977],\n",
       "         [-0.0976,  0.0218,  0.1236, -0.0156, -0.0988, -0.0866,  0.0803,  0.0230,\n",
       "          -0.0454, -0.0290,  0.1180, -0.1043, -0.1040, -0.0692, -0.0319,  0.0671,\n",
       "           0.0057,  0.0187,  0.1229,  0.0675,  0.0289, -0.0853,  0.0172,  0.0875,\n",
       "          -0.0131, -0.0520, -0.0023, -0.0837, -0.1215,  0.0070,  0.0172, -0.0861,\n",
       "           0.0510,  0.1128,  0.0698, -0.0959,  0.1047, -0.0330,  0.0005,  0.0720,\n",
       "           0.0032, -0.0150, -0.0510, -0.0521,  0.1005,  0.0592, -0.1216, -0.1142,\n",
       "           0.1248,  0.0489, -0.0867, -0.0501, -0.0520,  0.0541, -0.0905,  0.0906,\n",
       "           0.0294,  0.0876,  0.0433, -0.0863,  0.0969, -0.0604, -0.1024, -0.0643],\n",
       "         [ 0.1154, -0.1186, -0.0199, -0.0405, -0.1105,  0.0765,  0.0550, -0.0141,\n",
       "          -0.1237, -0.0296, -0.0304,  0.1103, -0.1205,  0.0008,  0.0556,  0.0408,\n",
       "           0.0326, -0.0969,  0.1037, -0.0864, -0.0293, -0.0055, -0.0150,  0.0192,\n",
       "          -0.0729, -0.0636,  0.0296, -0.0577, -0.0287, -0.0820, -0.0236,  0.0443,\n",
       "          -0.0256, -0.0003, -0.0927, -0.0993,  0.0258,  0.1160, -0.0434, -0.0916,\n",
       "          -0.0447, -0.0580,  0.0066,  0.0233,  0.1130, -0.1072, -0.0153, -0.0757,\n",
       "          -0.1002, -0.0961,  0.0014, -0.0149, -0.1029,  0.1006, -0.0517,  0.0877,\n",
       "          -0.0534, -0.0673,  0.0225,  0.0355,  0.1090, -0.1145,  0.1039, -0.0724],\n",
       "         [ 0.0105, -0.0863,  0.0174,  0.0673, -0.0783, -0.0996,  0.0594, -0.0393,\n",
       "          -0.0898,  0.0047, -0.1083,  0.0007,  0.0800, -0.1056,  0.0060, -0.1029,\n",
       "           0.0600,  0.0489, -0.0016,  0.0796,  0.0368, -0.0254, -0.1187, -0.0487,\n",
       "          -0.0344, -0.0922, -0.0645, -0.0865,  0.0391,  0.0313,  0.0412,  0.1113,\n",
       "          -0.1223, -0.0501, -0.0932, -0.1201,  0.0443,  0.0366, -0.0723,  0.0465,\n",
       "           0.0954,  0.0633,  0.0466, -0.0724, -0.0795, -0.0819, -0.1092,  0.0291,\n",
       "           0.0500,  0.0143, -0.0998, -0.0054,  0.1042,  0.0176, -0.0459,  0.0192,\n",
       "           0.0816, -0.0294, -0.0316, -0.0542,  0.0943, -0.0240,  0.0372, -0.0403],\n",
       "         [-0.0505, -0.0937, -0.1059,  0.0898,  0.1196, -0.1027,  0.0251,  0.0276,\n",
       "          -0.0344,  0.0518, -0.0177,  0.1089,  0.0241,  0.0386, -0.0508,  0.0748,\n",
       "          -0.0992,  0.0156,  0.0612, -0.1040, -0.0413,  0.0628,  0.0228, -0.1098,\n",
       "           0.1152,  0.0852, -0.0362,  0.0163,  0.0398,  0.0036,  0.1198,  0.0906,\n",
       "           0.0250,  0.1074,  0.0016, -0.1161, -0.1173, -0.0486, -0.0867,  0.1088,\n",
       "          -0.0890,  0.0498,  0.0614, -0.1214, -0.0523,  0.0367, -0.0253,  0.0643,\n",
       "          -0.0216,  0.0619,  0.0555,  0.1103, -0.0463, -0.1167, -0.0215, -0.0346,\n",
       "          -0.0006, -0.0089, -0.0418,  0.0205,  0.0769, -0.0936,  0.0747, -0.0514],\n",
       "         [-0.1041, -0.0652, -0.1099, -0.1172, -0.1183,  0.0261, -0.0061, -0.0181,\n",
       "           0.0306,  0.1034,  0.1023, -0.0415, -0.0590,  0.1013, -0.0350, -0.1135,\n",
       "           0.1211,  0.0423,  0.0534, -0.0943,  0.0192, -0.1066,  0.0101, -0.0907,\n",
       "          -0.0641, -0.0925,  0.0244,  0.0263,  0.0090, -0.0468,  0.0813,  0.0006,\n",
       "           0.0742,  0.0435,  0.0780, -0.0913,  0.0158, -0.1105, -0.0535, -0.0402,\n",
       "          -0.0937,  0.0195,  0.0634, -0.0159,  0.1228, -0.0416,  0.0739,  0.0429,\n",
       "           0.0029, -0.0882, -0.0594, -0.0101,  0.0290, -0.0891,  0.0971, -0.0061,\n",
       "          -0.0823, -0.0365,  0.0256, -0.1039,  0.1206,  0.1249,  0.1118, -0.0718]]),\n",
       " 'linear.bias': tensor([ 0.0939, -0.0072, -0.0662,  0.0920, -0.0422,  0.0693])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8efa1b90-371e-417b-a858-a69f483f1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in current_params.items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7647f06d-cf3e-4ea2-b2e1-2d090d75063c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layer0.0.weight'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3772ba6-d512-4a43-8284-37e1f6cf45f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  5.9497,  -5.0966,  -2.2385,   5.4198, -10.8708],\n",
       "          [  6.9249,  -2.3755,   5.8745,   1.6052,  -1.4139],\n",
       "          [  3.2027,   0.5696,   4.2173,  -4.4999,  -0.8419],\n",
       "          [ -1.0395,   1.6737,  -0.0461,  10.0940,   3.5933],\n",
       "          [ -4.3002,  -6.9739,  -1.9355,  -4.9807,  -3.7002]],\n",
       "\n",
       "         [[  0.5529,   6.8835,   6.2762, -11.2878,   7.1582],\n",
       "          [  3.2258,  10.9530,   7.6217, -10.5209, -10.9790],\n",
       "          [ -5.5695,  10.1396,  -1.9234,   4.9416,  -5.3660],\n",
       "          [ 11.3301,  -4.8855,   8.6594,   0.1367,  -6.0832],\n",
       "          [  5.9353,  -6.1294,   3.3960,  -3.3343,  -1.2659]],\n",
       "\n",
       "         [[-11.1012,  -5.5054,   6.2658,  -2.8068,  11.5014],\n",
       "          [  9.2559,  -0.5407,  -7.7074,   7.0317,   3.5837],\n",
       "          [ -7.4642,   7.5003,   7.0102,  10.2410,  -6.4728],\n",
       "          [ -1.9007,  -0.2237,   1.6865,  -8.7632,  -8.1940],\n",
       "          [  6.2816,  -2.7077,   5.6404,   0.6583,   3.7914]]],\n",
       "\n",
       "\n",
       "        [[[  2.5391,   4.1985,   5.7240, -10.6938,   5.8122],\n",
       "          [ -8.1190,  -8.7123,   0.7022,  -1.9677,   6.7818],\n",
       "          [ -6.6873, -10.2651,   8.4036,  -1.7122,   6.4947],\n",
       "          [  3.7122,  -8.6588,   2.3198,   2.7736,  -7.7314],\n",
       "          [ -5.4787,   3.9372,   2.0683,  -4.9118,  -3.4955]],\n",
       "\n",
       "         [[ 10.5757,  -2.1364,   6.5101,   4.9999,  -7.4641],\n",
       "          [ -9.8199,  11.0838,   0.6029,   7.9150,   2.3929],\n",
       "          [  3.7138,   8.6251,  10.9490,  -7.6624,   1.4437],\n",
       "          [  8.6170,   8.3651,   7.1734,  -8.3568,  -8.3150],\n",
       "          [ -6.9833,   1.4506,  11.5085,  -7.2940,   6.1532]],\n",
       "\n",
       "         [[ -6.3911, -10.8567,  -2.4542,   6.6530,  10.7199],\n",
       "          [ -7.1711,   2.5058,   9.9635,   7.6517,   7.1964],\n",
       "          [  8.2057,   7.3037,   2.9825,  -7.8961,  -9.6967],\n",
       "          [ -5.2911,  -1.3446,  -7.0778,   4.2245,   3.5737],\n",
       "          [ -2.6146,   4.4380,   3.7318,   7.0499,   7.7763]]],\n",
       "\n",
       "\n",
       "        [[[ -3.9104,  11.2817,  -1.3349,  -0.3967, -10.8990],\n",
       "          [ -7.4318,  -6.7458,  -4.9389,   8.2096,  -3.7733],\n",
       "          [ -8.6289,   4.4427,   3.6970,   7.4789,  -5.9753],\n",
       "          [  2.5036,  -4.2037,  -2.5943,  -9.2020,  -5.2627],\n",
       "          [ -3.5364,   4.9379,   2.1095,   2.8523,  11.5251]],\n",
       "\n",
       "         [[ 11.2540,   7.8756,   0.3677,  -7.9881,   9.0241],\n",
       "          [ -2.8875,  -0.9335,  -9.9477,  -2.2809,  -7.4477],\n",
       "          [ 10.6106,  -9.9826,  -9.0007,  -0.3921,  -6.2436],\n",
       "          [  4.1317,  -4.4447,  -5.4235,   0.6540,   8.3589],\n",
       "          [ -8.1224,   5.4225,   7.4183,  11.2952,  -8.0821]],\n",
       "\n",
       "         [[  2.7966,  -8.5382,   9.8583,  -4.4792,   6.9554],\n",
       "          [  0.3438,  -0.8993,  -0.3684,   1.9629,   5.4432],\n",
       "          [  1.8519,   3.5225, -10.3868,   8.4124,  10.0674],\n",
       "          [  9.5448,   8.5358,  -8.3327,  -4.2805,  10.1813],\n",
       "          [ -8.7949,  10.4757,  -9.0817,  -8.1338,   5.6451]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  0.5785,  -1.5470,   5.8621,  -4.9106,   9.0830],\n",
       "          [ -7.8747,  -6.0089,   3.9993,   7.0963,  -0.1414],\n",
       "          [ -9.0643,  -0.4613,  -3.8983,  -3.6896,  -2.1343],\n",
       "          [  2.7781,  -2.6878,  -8.0975,  -5.7654,  -9.6718],\n",
       "          [-11.5337,   5.5803,   6.4519,   8.7258,   0.9141]],\n",
       "\n",
       "         [[ -4.7495,  -6.9448,   5.7512,  -6.9783,   8.6292],\n",
       "          [ -6.2627, -10.7719,  -8.3157,   9.4045,   8.7158],\n",
       "          [  2.8183,   0.2671,   9.9007,   6.9682,   6.8369],\n",
       "          [ -7.8590,   1.8477,  10.4618,  -8.1341,  11.5038],\n",
       "          [ -7.5630,  -3.3931,  -0.5445,   3.0037,   3.5486]],\n",
       "\n",
       "         [[ -6.6042,   5.2851,   3.0560,  -1.2854, -11.4925],\n",
       "          [ 11.4281,  -4.2702,  -6.1548,  11.4341,  -5.8515],\n",
       "          [  7.7141,   7.0461,  -7.5158,  -9.3122,  -6.2774],\n",
       "          [  3.6140,  10.8924,  -0.6410,  -3.4488,  -3.3219],\n",
       "          [ -8.0417,  11.5395,  -0.1252,  -9.1377,  -7.8885]]],\n",
       "\n",
       "\n",
       "        [[[  7.1837,   5.5851,   7.4495,  -1.2173,  -2.2814],\n",
       "          [  3.7833,  -0.1131,  -3.7174,   2.7537,  -6.5808],\n",
       "          [ -7.9951,  -2.5525,  -8.2314,   0.2932,   1.8172],\n",
       "          [ 11.3064,   3.3278,  -0.0676,  -8.3921,  -4.6413],\n",
       "          [ -1.8824,  -8.3144,   2.2477,   8.3106,   6.6069]],\n",
       "\n",
       "         [[ -4.7889,  -2.8228,  11.5115,  -1.8488, -10.3705],\n",
       "          [ -0.1014,   0.5871,  -4.2897,  -1.2534,  -9.4160],\n",
       "          [  3.5559,  -8.0136,   3.9742,   8.7004,  -7.4547],\n",
       "          [ -4.5211,   1.1106,   0.0278,   6.7702,  -0.6923],\n",
       "          [  1.8667,  -3.1918,   3.8085,   3.4887,  -9.2971]],\n",
       "\n",
       "         [[  6.1298,  -2.3664,  10.3399, -11.4589,  -1.1463],\n",
       "          [  5.2175,   7.9625,   0.1501,  -6.2401,  -8.9258],\n",
       "          [ -8.7440,   9.2972, -10.0563,  -4.5691,   6.0528],\n",
       "          [  6.3145, -10.1006,   2.2893,   1.3960,  10.5979],\n",
       "          [ -0.4095,   4.9035,  -0.9980,  10.3067,  -1.1787]]],\n",
       "\n",
       "\n",
       "        [[[ -6.7853,   2.1298,  -6.1120,   2.8874,   8.0265],\n",
       "          [ -8.9812,  -8.4009,   0.1575,  -0.6754,  -3.5937],\n",
       "          [  9.6654,   5.1765,  -3.8285,   1.6735,  -1.7373],\n",
       "          [ -7.3930,   4.7244,  -7.6180,   1.3974,   7.8387],\n",
       "          [-10.6052,   0.5061,  10.6636,   5.2149,  -4.5538]],\n",
       "\n",
       "         [[  1.8172, -10.8420,   1.8541,  10.0396,  10.0343],\n",
       "          [ -0.1844,   4.1863,  -1.9164,  -3.2412,   0.2221],\n",
       "          [ -6.7261,   4.6491,   5.6610,  -3.1302,  -2.6272],\n",
       "          [ -8.0464,   1.4764,   4.5924,  10.9627, -10.8798],\n",
       "          [ -9.7351,   0.3265,  10.6712,   0.7431,   3.2052]],\n",
       "\n",
       "         [[  1.6394,  -1.3808,   8.2412,   8.4764,  -6.6573],\n",
       "          [ -6.9152,  -8.9787,  -2.8082,  -0.2601,   9.6647],\n",
       "          [-11.1754,   8.1955,  -6.4500,   0.9432,  -0.5396],\n",
       "          [  6.5220,  -9.6597,  -8.0637,   0.2648,   5.8231],\n",
       "          [ -5.5553,   3.5788,  -3.0515, -10.7678,   1.3180]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params[name]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c3c53d6-84e5-4c7a-8d0c-657a283553ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.5399e+01, 2.5975e+01, 5.0110e+00, 2.9374e+01, 1.1817e+02],\n",
       "          [4.7955e+01, 5.6431e+00, 3.4509e+01, 2.5768e+00, 1.9990e+00],\n",
       "          [1.0257e+01, 3.2448e-01, 1.7786e+01, 2.0249e+01, 7.0876e-01],\n",
       "          [1.0807e+00, 2.8012e+00, 2.1278e-03, 1.0189e+02, 1.2912e+01],\n",
       "          [1.8492e+01, 4.8636e+01, 3.7460e+00, 2.4807e+01, 1.3692e+01]],\n",
       "\n",
       "         [[3.0569e-01, 4.7382e+01, 3.9391e+01, 1.2741e+02, 5.1240e+01],\n",
       "          [1.0406e+01, 1.1997e+02, 5.8091e+01, 1.1069e+02, 1.2054e+02],\n",
       "          [3.1019e+01, 1.0281e+02, 3.6994e+00, 2.4420e+01, 2.8794e+01],\n",
       "          [1.2837e+02, 2.3868e+01, 7.4985e+01, 1.8697e-02, 3.7005e+01],\n",
       "          [3.5228e+01, 3.7569e+01, 1.1533e+01, 1.1117e+01, 1.6026e+00]],\n",
       "\n",
       "         [[1.2324e+02, 3.0309e+01, 3.9260e+01, 7.8782e+00, 1.3228e+02],\n",
       "          [8.5673e+01, 2.9233e-01, 5.9404e+01, 4.9445e+01, 1.2843e+01],\n",
       "          [5.5714e+01, 5.6254e+01, 4.9143e+01, 1.0488e+02, 4.1897e+01],\n",
       "          [3.6127e+00, 5.0036e-02, 2.8444e+00, 7.6794e+01, 6.7142e+01],\n",
       "          [3.9459e+01, 7.3315e+00, 3.1814e+01, 4.3335e-01, 1.4375e+01]]],\n",
       "\n",
       "\n",
       "        [[[6.4468e+00, 1.7627e+01, 3.2764e+01, 1.1436e+02, 3.3782e+01],\n",
       "          [6.5918e+01, 7.5905e+01, 4.9312e-01, 3.8718e+00, 4.5993e+01],\n",
       "          [4.4720e+01, 1.0537e+02, 7.0620e+01, 2.9317e+00, 4.2181e+01],\n",
       "          [1.3780e+01, 7.4975e+01, 5.3814e+00, 7.6926e+00, 5.9775e+01],\n",
       "          [3.0017e+01, 1.5502e+01, 4.2780e+00, 2.4126e+01, 1.2218e+01]],\n",
       "\n",
       "         [[1.1185e+02, 4.5644e+00, 4.2381e+01, 2.4999e+01, 5.5712e+01],\n",
       "          [9.6431e+01, 1.2285e+02, 3.6355e-01, 6.2647e+01, 5.7260e+00],\n",
       "          [1.3792e+01, 7.4393e+01, 1.1988e+02, 5.8712e+01, 2.0843e+00],\n",
       "          [7.4253e+01, 6.9974e+01, 5.1458e+01, 6.9836e+01, 6.9140e+01],\n",
       "          [4.8766e+01, 2.1043e+00, 1.3245e+02, 5.3202e+01, 3.7862e+01]],\n",
       "\n",
       "         [[4.0847e+01, 1.1787e+02, 6.0231e+00, 4.4263e+01, 1.1492e+02],\n",
       "          [5.1425e+01, 6.2792e+00, 9.9270e+01, 5.8548e+01, 5.1788e+01],\n",
       "          [6.7333e+01, 5.3344e+01, 8.8956e+00, 6.2348e+01, 9.4026e+01],\n",
       "          [2.7995e+01, 1.8080e+00, 5.0095e+01, 1.7847e+01, 1.2771e+01],\n",
       "          [6.8364e+00, 1.9696e+01, 1.3926e+01, 4.9701e+01, 6.0470e+01]]],\n",
       "\n",
       "\n",
       "        [[[1.5291e+01, 1.2728e+02, 1.7820e+00, 1.5738e-01, 1.1879e+02],\n",
       "          [5.5232e+01, 4.5506e+01, 2.4393e+01, 6.7397e+01, 1.4238e+01],\n",
       "          [7.4457e+01, 1.9738e+01, 1.3668e+01, 5.5934e+01, 3.5704e+01],\n",
       "          [6.2678e+00, 1.7671e+01, 6.7305e+00, 8.4677e+01, 2.7696e+01],\n",
       "          [1.2506e+01, 2.4383e+01, 4.4501e+00, 8.1356e+00, 1.3283e+02]],\n",
       "\n",
       "         [[1.2665e+02, 6.2025e+01, 1.3520e-01, 6.3810e+01, 8.1434e+01],\n",
       "          [8.3376e+00, 8.7146e-01, 9.8957e+01, 5.2023e+00, 5.5468e+01],\n",
       "          [1.1259e+02, 9.9653e+01, 8.1012e+01, 1.5374e-01, 3.8983e+01],\n",
       "          [1.7071e+01, 1.9756e+01, 2.9414e+01, 4.2771e-01, 6.9870e+01],\n",
       "          [6.5974e+01, 2.9404e+01, 5.5031e+01, 1.2758e+02, 6.5320e+01]],\n",
       "\n",
       "         [[7.8208e+00, 7.2900e+01, 9.7185e+01, 2.0063e+01, 4.8377e+01],\n",
       "          [1.1818e-01, 8.0876e-01, 1.3575e-01, 3.8531e+00, 2.9629e+01],\n",
       "          [3.4296e+00, 1.2408e+01, 1.0789e+02, 7.0769e+01, 1.0135e+02],\n",
       "          [9.1104e+01, 7.2860e+01, 6.9434e+01, 1.8322e+01, 1.0366e+02],\n",
       "          [7.7350e+01, 1.0974e+02, 8.2477e+01, 6.6159e+01, 3.1867e+01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[3.3463e-01, 2.3931e+00, 3.4364e+01, 2.4114e+01, 8.2501e+01],\n",
       "          [6.2011e+01, 3.6106e+01, 1.5994e+01, 5.0357e+01, 1.9989e-02],\n",
       "          [8.2162e+01, 2.1278e-01, 1.5197e+01, 1.3613e+01, 4.5553e+00],\n",
       "          [7.7180e+00, 7.2245e+00, 6.5570e+01, 3.3239e+01, 9.3544e+01],\n",
       "          [1.3303e+02, 3.1139e+01, 4.1626e+01, 7.6140e+01, 8.3556e-01]],\n",
       "\n",
       "         [[2.2558e+01, 4.8231e+01, 3.3076e+01, 4.8697e+01, 7.4464e+01],\n",
       "          [3.9221e+01, 1.1603e+02, 6.9150e+01, 8.8444e+01, 7.5964e+01],\n",
       "          [7.9429e+00, 7.1363e-02, 9.8023e+01, 4.8556e+01, 4.6743e+01],\n",
       "          [6.1765e+01, 3.4139e+00, 1.0945e+02, 6.6164e+01, 1.3234e+02],\n",
       "          [5.7199e+01, 1.1513e+01, 2.9648e-01, 9.0223e+00, 1.2592e+01]],\n",
       "\n",
       "         [[4.3616e+01, 2.7933e+01, 9.3389e+00, 1.6522e+00, 1.3208e+02],\n",
       "          [1.3060e+02, 1.8235e+01, 3.7882e+01, 1.3074e+02, 3.4241e+01],\n",
       "          [5.9508e+01, 4.9647e+01, 5.6487e+01, 8.6717e+01, 3.9406e+01],\n",
       "          [1.3061e+01, 1.1864e+02, 4.1086e-01, 1.1894e+01, 1.1035e+01],\n",
       "          [6.4669e+01, 1.3316e+02, 1.5684e-02, 8.3497e+01, 6.2229e+01]]],\n",
       "\n",
       "\n",
       "        [[[5.1605e+01, 3.1193e+01, 5.5495e+01, 1.4819e+00, 5.2050e+00],\n",
       "          [1.4314e+01, 1.2782e-02, 1.3819e+01, 7.5827e+00, 4.3307e+01],\n",
       "          [6.3921e+01, 6.5151e+00, 6.7755e+01, 8.5952e-02, 3.3023e+00],\n",
       "          [1.2783e+02, 1.1074e+01, 4.5666e-03, 7.0428e+01, 2.1542e+01],\n",
       "          [3.5435e+00, 6.9129e+01, 5.0523e+00, 6.9066e+01, 4.3651e+01]],\n",
       "\n",
       "         [[2.2933e+01, 7.9680e+00, 1.3251e+02, 3.4182e+00, 1.0755e+02],\n",
       "          [1.0280e-02, 3.4466e-01, 1.8402e+01, 1.5711e+00, 8.8660e+01],\n",
       "          [1.2644e+01, 6.4218e+01, 1.5794e+01, 7.5697e+01, 5.5572e+01],\n",
       "          [2.0440e+01, 1.2334e+00, 7.7560e-04, 4.5836e+01, 4.7924e-01],\n",
       "          [3.4847e+00, 1.0188e+01, 1.4505e+01, 1.2171e+01, 8.6437e+01]],\n",
       "\n",
       "         [[3.7575e+01, 5.5997e+00, 1.0691e+02, 1.3131e+02, 1.3140e+00],\n",
       "          [2.7223e+01, 6.3401e+01, 2.2532e-02, 3.8939e+01, 7.9670e+01],\n",
       "          [7.6457e+01, 8.6438e+01, 1.0113e+02, 2.0876e+01, 3.6636e+01],\n",
       "          [3.9873e+01, 1.0202e+02, 5.2410e+00, 1.9488e+00, 1.1231e+02],\n",
       "          [1.6772e-01, 2.4044e+01, 9.9602e-01, 1.0623e+02, 1.3892e+00]]],\n",
       "\n",
       "\n",
       "        [[[4.6040e+01, 4.5362e+00, 3.7357e+01, 8.3370e+00, 6.4425e+01],\n",
       "          [8.0661e+01, 7.0575e+01, 2.4796e-02, 4.5618e-01, 1.2915e+01],\n",
       "          [9.3420e+01, 2.6797e+01, 1.4657e+01, 2.8005e+00, 3.0183e+00],\n",
       "          [5.4656e+01, 2.2320e+01, 5.8033e+01, 1.9527e+00, 6.1445e+01],\n",
       "          [1.1247e+02, 2.5616e-01, 1.1371e+02, 2.7195e+01, 2.0737e+01]],\n",
       "\n",
       "         [[3.3023e+00, 1.1755e+02, 3.4378e+00, 1.0079e+02, 1.0069e+02],\n",
       "          [3.4019e-02, 1.7525e+01, 3.6726e+00, 1.0505e+01, 4.9324e-02],\n",
       "          [4.5241e+01, 2.1614e+01, 3.2047e+01, 9.7984e+00, 6.9024e+00],\n",
       "          [6.4745e+01, 2.1799e+00, 2.1091e+01, 1.2018e+02, 1.1837e+02],\n",
       "          [9.4772e+01, 1.0663e-01, 1.1387e+02, 5.5220e-01, 1.0273e+01]],\n",
       "\n",
       "         [[2.6877e+00, 1.9067e+00, 6.7918e+01, 7.1849e+01, 4.4319e+01],\n",
       "          [4.7820e+01, 8.0617e+01, 7.8859e+00, 6.7665e-02, 9.3406e+01],\n",
       "          [1.2489e+02, 6.7167e+01, 4.1603e+01, 8.8959e-01, 2.9121e-01],\n",
       "          [4.2536e+01, 9.3309e+01, 6.5023e+01, 7.0134e-02, 3.3908e+01],\n",
       "          [3.0861e+01, 1.2808e+01, 9.3119e+00, 1.1595e+02, 1.7371e+00]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params[name]*10000*current_params[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a57123-ce77-4ccc-8e0e-1c6f776659b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d3d12-dfc3-45f6-9164-3a3988b6b1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68f93971-a416-49be-b5a4-461c1872b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0595, -0.0510, -0.0224,  0.0542, -0.1087],\n",
       "          [ 0.0692, -0.0238,  0.0587,  0.0161, -0.0141],\n",
       "          [ 0.0320,  0.0057,  0.0422, -0.0450, -0.0084],\n",
       "          [-0.0104,  0.0167, -0.0005,  0.1009,  0.0359],\n",
       "          [-0.0430, -0.0697, -0.0194, -0.0498, -0.0370]],\n",
       "\n",
       "         [[ 0.0055,  0.0688,  0.0628, -0.1129,  0.0716],\n",
       "          [ 0.0323,  0.1095,  0.0762, -0.1052, -0.1098],\n",
       "          [-0.0557,  0.1014, -0.0192,  0.0494, -0.0537],\n",
       "          [ 0.1133, -0.0489,  0.0866,  0.0014, -0.0608],\n",
       "          [ 0.0594, -0.0613,  0.0340, -0.0333, -0.0127]],\n",
       "\n",
       "         [[-0.1110, -0.0551,  0.0627, -0.0281,  0.1150],\n",
       "          [ 0.0926, -0.0054, -0.0771,  0.0703,  0.0358],\n",
       "          [-0.0746,  0.0750,  0.0701,  0.1024, -0.0647],\n",
       "          [-0.0190, -0.0022,  0.0169, -0.0876, -0.0819],\n",
       "          [ 0.0628, -0.0271,  0.0564,  0.0066,  0.0379]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0254,  0.0420,  0.0572, -0.1069,  0.0581],\n",
       "          [-0.0812, -0.0871,  0.0070, -0.0197,  0.0678],\n",
       "          [-0.0669, -0.1027,  0.0840, -0.0171,  0.0649],\n",
       "          [ 0.0371, -0.0866,  0.0232,  0.0277, -0.0773],\n",
       "          [-0.0548,  0.0394,  0.0207, -0.0491, -0.0350]],\n",
       "\n",
       "         [[ 0.1058, -0.0214,  0.0651,  0.0500, -0.0746],\n",
       "          [-0.0982,  0.1108,  0.0060,  0.0791,  0.0239],\n",
       "          [ 0.0371,  0.0863,  0.1095, -0.0766,  0.0144],\n",
       "          [ 0.0862,  0.0837,  0.0717, -0.0836, -0.0832],\n",
       "          [-0.0698,  0.0145,  0.1151, -0.0729,  0.0615]],\n",
       "\n",
       "         [[-0.0639, -0.1086, -0.0245,  0.0665,  0.1072],\n",
       "          [-0.0717,  0.0251,  0.0996,  0.0765,  0.0720],\n",
       "          [ 0.0821,  0.0730,  0.0298, -0.0790, -0.0970],\n",
       "          [-0.0529, -0.0134, -0.0708,  0.0422,  0.0357],\n",
       "          [-0.0261,  0.0444,  0.0373,  0.0705,  0.0778]]],\n",
       "\n",
       "\n",
       "        [[[-0.0391,  0.1128, -0.0133, -0.0040, -0.1090],\n",
       "          [-0.0743, -0.0675, -0.0494,  0.0821, -0.0377],\n",
       "          [-0.0863,  0.0444,  0.0370,  0.0748, -0.0598],\n",
       "          [ 0.0250, -0.0420, -0.0259, -0.0920, -0.0526],\n",
       "          [-0.0354,  0.0494,  0.0211,  0.0285,  0.1153]],\n",
       "\n",
       "         [[ 0.1125,  0.0788,  0.0037, -0.0799,  0.0902],\n",
       "          [-0.0289, -0.0093, -0.0995, -0.0228, -0.0745],\n",
       "          [ 0.1061, -0.0998, -0.0900, -0.0039, -0.0624],\n",
       "          [ 0.0413, -0.0444, -0.0542,  0.0065,  0.0836],\n",
       "          [-0.0812,  0.0542,  0.0742,  0.1130, -0.0808]],\n",
       "\n",
       "         [[ 0.0280, -0.0854,  0.0986, -0.0448,  0.0696],\n",
       "          [ 0.0034, -0.0090, -0.0037,  0.0196,  0.0544],\n",
       "          [ 0.0185,  0.0352, -0.1039,  0.0841,  0.1007],\n",
       "          [ 0.0954,  0.0854, -0.0833, -0.0428,  0.1018],\n",
       "          [-0.0879,  0.1048, -0.0908, -0.0813,  0.0565]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0058, -0.0155,  0.0586, -0.0491,  0.0908],\n",
       "          [-0.0787, -0.0601,  0.0400,  0.0710, -0.0014],\n",
       "          [-0.0906, -0.0046, -0.0390, -0.0369, -0.0213],\n",
       "          [ 0.0278, -0.0269, -0.0810, -0.0577, -0.0967],\n",
       "          [-0.1153,  0.0558,  0.0645,  0.0873,  0.0091]],\n",
       "\n",
       "         [[-0.0475, -0.0694,  0.0575, -0.0698,  0.0863],\n",
       "          [-0.0626, -0.1077, -0.0832,  0.0940,  0.0872],\n",
       "          [ 0.0282,  0.0027,  0.0990,  0.0697,  0.0684],\n",
       "          [-0.0786,  0.0185,  0.1046, -0.0813,  0.1150],\n",
       "          [-0.0756, -0.0339, -0.0054,  0.0300,  0.0355]],\n",
       "\n",
       "         [[-0.0660,  0.0529,  0.0306, -0.0129, -0.1149],\n",
       "          [ 0.1143, -0.0427, -0.0615,  0.1143, -0.0585],\n",
       "          [ 0.0771,  0.0705, -0.0752, -0.0931, -0.0628],\n",
       "          [ 0.0361,  0.1089, -0.0064, -0.0345, -0.0332],\n",
       "          [-0.0804,  0.1154, -0.0013, -0.0914, -0.0789]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0718,  0.0559,  0.0745, -0.0122, -0.0228],\n",
       "          [ 0.0378, -0.0011, -0.0372,  0.0275, -0.0658],\n",
       "          [-0.0800, -0.0255, -0.0823,  0.0029,  0.0182],\n",
       "          [ 0.1131,  0.0333, -0.0007, -0.0839, -0.0464],\n",
       "          [-0.0188, -0.0831,  0.0225,  0.0831,  0.0661]],\n",
       "\n",
       "         [[-0.0479, -0.0282,  0.1151, -0.0185, -0.1037],\n",
       "          [-0.0010,  0.0059, -0.0429, -0.0125, -0.0942],\n",
       "          [ 0.0356, -0.0801,  0.0397,  0.0870, -0.0745],\n",
       "          [-0.0452,  0.0111,  0.0003,  0.0677, -0.0069],\n",
       "          [ 0.0187, -0.0319,  0.0381,  0.0349, -0.0930]],\n",
       "\n",
       "         [[ 0.0613, -0.0237,  0.1034, -0.1146, -0.0115],\n",
       "          [ 0.0522,  0.0796,  0.0015, -0.0624, -0.0893],\n",
       "          [-0.0874,  0.0930, -0.1006, -0.0457,  0.0605],\n",
       "          [ 0.0631, -0.1010,  0.0229,  0.0140,  0.1060],\n",
       "          [-0.0041,  0.0490, -0.0100,  0.1031, -0.0118]]],\n",
       "\n",
       "\n",
       "        [[[-0.0679,  0.0213, -0.0611,  0.0289,  0.0803],\n",
       "          [-0.0898, -0.0840,  0.0016, -0.0068, -0.0359],\n",
       "          [ 0.0967,  0.0518, -0.0383,  0.0167, -0.0174],\n",
       "          [-0.0739,  0.0472, -0.0762,  0.0140,  0.0784],\n",
       "          [-0.1061,  0.0051,  0.1066,  0.0521, -0.0455]],\n",
       "\n",
       "         [[ 0.0182, -0.1084,  0.0185,  0.1004,  0.1003],\n",
       "          [-0.0018,  0.0419, -0.0192, -0.0324,  0.0022],\n",
       "          [-0.0673,  0.0465,  0.0566, -0.0313, -0.0263],\n",
       "          [-0.0805,  0.0148,  0.0459,  0.1096, -0.1088],\n",
       "          [-0.0974,  0.0033,  0.1067,  0.0074,  0.0321]],\n",
       "\n",
       "         [[ 0.0164, -0.0138,  0.0824,  0.0848, -0.0666],\n",
       "          [-0.0692, -0.0898, -0.0281, -0.0026,  0.0966],\n",
       "          [-0.1118,  0.0820, -0.0645,  0.0094, -0.0054],\n",
       "          [ 0.0652, -0.0966, -0.0806,  0.0026,  0.0582],\n",
       "          [-0.0556,  0.0358, -0.0305, -0.1077,  0.0132]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef1de5-afdf-4b22-b102-d79a80060b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88b291-b6bd-4857-bc7e-6bfacacada72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cfc8261-b898-44a3-8205-6cafcf04bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layer0.0.weight', 'layer0.0.bias', 'layer0.1.weight', 'layer0.1.bias', 'layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer2.0.weight', 'layer2.0.bias', 'layer2.1.weight', 'layer2.1.bias', 'layer3.0.weight', 'layer3.0.bias', 'layer3.1.weight', 'layer3.1.bias', 'layer4.0.weight', 'layer4.0.bias', 'layer4.1.weight', 'layer4.1.bias', 'layer5.0.weight', 'layer5.0.bias', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc411263-a138-44bb-8cf0-0c78bfdb4c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cd15e74-58ae-4b29-bb78-700ff1ddab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_weight_copy(net):\n",
    "    \"\"\"Create an all-zero copy of the network weights as a dictionary that maps name -> weight\"\"\"\n",
    "    return {\n",
    "        name: torch.zeros_like(param, requires_grad=False)\n",
    "        for name, param in net.named_parameters()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e48f7-51a0-4d47-9c1b-65afe548f747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec89d2-29d9-4ea4-a998-34f8440abe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f1ece0f-7d76-4cb7-84cd-3dbe303b3b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer0.0.weight': tensor([[[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]]]),\n",
       " 'layer0.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer0.1.weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer0.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.0.weight': tensor([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]]),\n",
       " 'layer1.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.1.weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.0.weight': tensor([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]]),\n",
       " 'layer2.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.1.weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.0.weight': tensor([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]]),\n",
       " 'layer3.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.1.weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.0.weight': tensor([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]]),\n",
       " 'layer4.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.1.weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer5.0.weight': tensor([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]]),\n",
       " 'layer5.0.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'linear.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'linear.bias': tensor([0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_weight_copy(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bb174dc-9912-413d-9fff-61e47e35e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480295c-9e3e-42da-ad34-e2d15f4a8046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c5c4d0a-1fde-44b4-8090-81320bd7641c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PRETRAINED_WEIGHTS_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m network\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mPRETRAINED_WEIGHTS_FILE\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PRETRAINED_WEIGHTS_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "network.load_state_dict(torch.load(PRETRAINED_WEIGHTS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd2b616-9e67-411a-bead-2665c23f584b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PRETRAINED_WEIGHTS_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mPRETRAINED_WEIGHTS_FILE\u001b[49m)\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PRETRAINED_WEIGHTS_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "torch.load(PRETRAINED_WEIGHTS_FILE).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a248b-bead-46c1-bf95-a2e5fff8fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c58c9db4-18be-493e-8763-3a0c45ad01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_WEIGHTS_FILE = model_dir / \"map_weights.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a8b0bd2-a981-4453-9217-ca3e8381c7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer0.0.weight': tensor([[[[ 0.0595, -0.0510, -0.0224,  0.0542, -0.1087],\n",
       "           [ 0.0692, -0.0238,  0.0587,  0.0161, -0.0141],\n",
       "           [ 0.0320,  0.0057,  0.0422, -0.0450, -0.0084],\n",
       "           [-0.0104,  0.0167, -0.0005,  0.1009,  0.0359],\n",
       "           [-0.0430, -0.0697, -0.0194, -0.0498, -0.0370]],\n",
       " \n",
       "          [[ 0.0055,  0.0688,  0.0628, -0.1129,  0.0716],\n",
       "           [ 0.0323,  0.1095,  0.0762, -0.1052, -0.1098],\n",
       "           [-0.0557,  0.1014, -0.0192,  0.0494, -0.0537],\n",
       "           [ 0.1133, -0.0489,  0.0866,  0.0014, -0.0608],\n",
       "           [ 0.0594, -0.0613,  0.0340, -0.0333, -0.0127]],\n",
       " \n",
       "          [[-0.1110, -0.0551,  0.0627, -0.0281,  0.1150],\n",
       "           [ 0.0926, -0.0054, -0.0771,  0.0703,  0.0358],\n",
       "           [-0.0746,  0.0750,  0.0701,  0.1024, -0.0647],\n",
       "           [-0.0190, -0.0022,  0.0169, -0.0876, -0.0819],\n",
       "           [ 0.0628, -0.0271,  0.0564,  0.0066,  0.0379]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0254,  0.0420,  0.0572, -0.1069,  0.0581],\n",
       "           [-0.0812, -0.0871,  0.0070, -0.0197,  0.0678],\n",
       "           [-0.0669, -0.1027,  0.0840, -0.0171,  0.0649],\n",
       "           [ 0.0371, -0.0866,  0.0232,  0.0277, -0.0773],\n",
       "           [-0.0548,  0.0394,  0.0207, -0.0491, -0.0350]],\n",
       " \n",
       "          [[ 0.1058, -0.0214,  0.0651,  0.0500, -0.0746],\n",
       "           [-0.0982,  0.1108,  0.0060,  0.0791,  0.0239],\n",
       "           [ 0.0371,  0.0863,  0.1095, -0.0766,  0.0144],\n",
       "           [ 0.0862,  0.0837,  0.0717, -0.0836, -0.0832],\n",
       "           [-0.0698,  0.0145,  0.1151, -0.0729,  0.0615]],\n",
       " \n",
       "          [[-0.0639, -0.1086, -0.0245,  0.0665,  0.1072],\n",
       "           [-0.0717,  0.0251,  0.0996,  0.0765,  0.0720],\n",
       "           [ 0.0821,  0.0730,  0.0298, -0.0790, -0.0970],\n",
       "           [-0.0529, -0.0134, -0.0708,  0.0422,  0.0357],\n",
       "           [-0.0261,  0.0444,  0.0373,  0.0705,  0.0778]]],\n",
       " \n",
       " \n",
       "         [[[-0.0391,  0.1128, -0.0133, -0.0040, -0.1090],\n",
       "           [-0.0743, -0.0675, -0.0494,  0.0821, -0.0377],\n",
       "           [-0.0863,  0.0444,  0.0370,  0.0748, -0.0598],\n",
       "           [ 0.0250, -0.0420, -0.0259, -0.0920, -0.0526],\n",
       "           [-0.0354,  0.0494,  0.0211,  0.0285,  0.1153]],\n",
       " \n",
       "          [[ 0.1125,  0.0788,  0.0037, -0.0799,  0.0902],\n",
       "           [-0.0289, -0.0093, -0.0995, -0.0228, -0.0745],\n",
       "           [ 0.1061, -0.0998, -0.0900, -0.0039, -0.0624],\n",
       "           [ 0.0413, -0.0444, -0.0542,  0.0065,  0.0836],\n",
       "           [-0.0812,  0.0542,  0.0742,  0.1130, -0.0808]],\n",
       " \n",
       "          [[ 0.0280, -0.0854,  0.0986, -0.0448,  0.0696],\n",
       "           [ 0.0034, -0.0090, -0.0037,  0.0196,  0.0544],\n",
       "           [ 0.0185,  0.0352, -0.1039,  0.0841,  0.1007],\n",
       "           [ 0.0954,  0.0854, -0.0833, -0.0428,  0.1018],\n",
       "           [-0.0879,  0.1048, -0.0908, -0.0813,  0.0565]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0058, -0.0155,  0.0586, -0.0491,  0.0908],\n",
       "           [-0.0787, -0.0601,  0.0400,  0.0710, -0.0014],\n",
       "           [-0.0906, -0.0046, -0.0390, -0.0369, -0.0213],\n",
       "           [ 0.0278, -0.0269, -0.0810, -0.0577, -0.0967],\n",
       "           [-0.1153,  0.0558,  0.0645,  0.0873,  0.0091]],\n",
       " \n",
       "          [[-0.0475, -0.0694,  0.0575, -0.0698,  0.0863],\n",
       "           [-0.0626, -0.1077, -0.0832,  0.0940,  0.0872],\n",
       "           [ 0.0282,  0.0027,  0.0990,  0.0697,  0.0684],\n",
       "           [-0.0786,  0.0185,  0.1046, -0.0813,  0.1150],\n",
       "           [-0.0756, -0.0339, -0.0054,  0.0300,  0.0355]],\n",
       " \n",
       "          [[-0.0660,  0.0529,  0.0306, -0.0129, -0.1149],\n",
       "           [ 0.1143, -0.0427, -0.0615,  0.1143, -0.0585],\n",
       "           [ 0.0771,  0.0705, -0.0752, -0.0931, -0.0628],\n",
       "           [ 0.0361,  0.1089, -0.0064, -0.0345, -0.0332],\n",
       "           [-0.0804,  0.1154, -0.0013, -0.0914, -0.0789]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0718,  0.0559,  0.0745, -0.0122, -0.0228],\n",
       "           [ 0.0378, -0.0011, -0.0372,  0.0275, -0.0658],\n",
       "           [-0.0800, -0.0255, -0.0823,  0.0029,  0.0182],\n",
       "           [ 0.1131,  0.0333, -0.0007, -0.0839, -0.0464],\n",
       "           [-0.0188, -0.0831,  0.0225,  0.0831,  0.0661]],\n",
       " \n",
       "          [[-0.0479, -0.0282,  0.1151, -0.0185, -0.1037],\n",
       "           [-0.0010,  0.0059, -0.0429, -0.0125, -0.0942],\n",
       "           [ 0.0356, -0.0801,  0.0397,  0.0870, -0.0745],\n",
       "           [-0.0452,  0.0111,  0.0003,  0.0677, -0.0069],\n",
       "           [ 0.0187, -0.0319,  0.0381,  0.0349, -0.0930]],\n",
       " \n",
       "          [[ 0.0613, -0.0237,  0.1034, -0.1146, -0.0115],\n",
       "           [ 0.0522,  0.0796,  0.0015, -0.0624, -0.0893],\n",
       "           [-0.0874,  0.0930, -0.1006, -0.0457,  0.0605],\n",
       "           [ 0.0631, -0.1010,  0.0229,  0.0140,  0.1060],\n",
       "           [-0.0041,  0.0490, -0.0100,  0.1031, -0.0118]]],\n",
       " \n",
       " \n",
       "         [[[-0.0679,  0.0213, -0.0611,  0.0289,  0.0803],\n",
       "           [-0.0898, -0.0840,  0.0016, -0.0068, -0.0359],\n",
       "           [ 0.0967,  0.0518, -0.0383,  0.0167, -0.0174],\n",
       "           [-0.0739,  0.0472, -0.0762,  0.0140,  0.0784],\n",
       "           [-0.1061,  0.0051,  0.1066,  0.0521, -0.0455]],\n",
       " \n",
       "          [[ 0.0182, -0.1084,  0.0185,  0.1004,  0.1003],\n",
       "           [-0.0018,  0.0419, -0.0192, -0.0324,  0.0022],\n",
       "           [-0.0673,  0.0465,  0.0566, -0.0313, -0.0263],\n",
       "           [-0.0805,  0.0148,  0.0459,  0.1096, -0.1088],\n",
       "           [-0.0974,  0.0033,  0.1067,  0.0074,  0.0321]],\n",
       " \n",
       "          [[ 0.0164, -0.0138,  0.0824,  0.0848, -0.0666],\n",
       "           [-0.0692, -0.0898, -0.0281, -0.0026,  0.0966],\n",
       "           [-0.1118,  0.0820, -0.0645,  0.0094, -0.0054],\n",
       "           [ 0.0652, -0.0966, -0.0806,  0.0026,  0.0582],\n",
       "           [-0.0556,  0.0358, -0.0305, -0.1077,  0.0132]]]]),\n",
       " 'layer0.0.bias': tensor([-0.0246,  0.0683,  0.0761,  0.0755,  0.0723, -0.0893, -0.1108,  0.0129,\n",
       "          0.0335, -0.0888,  0.0944, -0.0122, -0.0677,  0.0792,  0.1011,  0.0177,\n",
       "         -0.0368,  0.0125, -0.0851,  0.0712,  0.0725, -0.0216, -0.0915,  0.0857,\n",
       "         -0.0945, -0.0606,  0.0689, -0.0574,  0.0220,  0.0949, -0.0146, -0.0261]),\n",
       " 'layer0.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer0.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.0.weight': tensor([[[[ 0.0546,  0.0101,  0.0206],\n",
       "           [-0.0194, -0.0508,  0.0092],\n",
       "           [-0.0348, -0.0305, -0.0483]],\n",
       " \n",
       "          [[ 0.0505, -0.0396,  0.0170],\n",
       "           [ 0.0121,  0.0407,  0.0322],\n",
       "           [-0.0413,  0.0261, -0.0299]],\n",
       " \n",
       "          [[ 0.0022, -0.0213, -0.0504],\n",
       "           [ 0.0176, -0.0393,  0.0577],\n",
       "           [ 0.0237, -0.0204, -0.0345]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0583,  0.0324,  0.0416],\n",
       "           [ 0.0469,  0.0359, -0.0188],\n",
       "           [ 0.0121,  0.0149, -0.0563]],\n",
       " \n",
       "          [[ 0.0318, -0.0475,  0.0212],\n",
       "           [ 0.0569, -0.0164,  0.0081],\n",
       "           [ 0.0546,  0.0486,  0.0492]],\n",
       " \n",
       "          [[-0.0408,  0.0116, -0.0493],\n",
       "           [ 0.0108, -0.0558,  0.0068],\n",
       "           [ 0.0298, -0.0525, -0.0090]]],\n",
       " \n",
       " \n",
       "         [[[-0.0244,  0.0484, -0.0058],\n",
       "           [ 0.0367, -0.0435,  0.0082],\n",
       "           [ 0.0427,  0.0033, -0.0206]],\n",
       " \n",
       "          [[-0.0241,  0.0402,  0.0232],\n",
       "           [ 0.0040,  0.0348, -0.0307],\n",
       "           [-0.0447, -0.0133,  0.0432]],\n",
       " \n",
       "          [[-0.0570, -0.0293,  0.0143],\n",
       "           [ 0.0222,  0.0295,  0.0178],\n",
       "           [-0.0520, -0.0192,  0.0362]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0269, -0.0078, -0.0461],\n",
       "           [-0.0380, -0.0191, -0.0069],\n",
       "           [-0.0127,  0.0033, -0.0540]],\n",
       " \n",
       "          [[-0.0095, -0.0517,  0.0310],\n",
       "           [ 0.0537, -0.0465, -0.0424],\n",
       "           [ 0.0571,  0.0458,  0.0271]],\n",
       " \n",
       "          [[-0.0372,  0.0185, -0.0019],\n",
       "           [ 0.0444,  0.0367, -0.0067],\n",
       "           [ 0.0230, -0.0515,  0.0101]]],\n",
       " \n",
       " \n",
       "         [[[-0.0359,  0.0468, -0.0428],\n",
       "           [-0.0512, -0.0502, -0.0168],\n",
       "           [ 0.0032, -0.0068,  0.0242]],\n",
       " \n",
       "          [[-0.0523, -0.0346, -0.0082],\n",
       "           [-0.0019, -0.0128,  0.0270],\n",
       "           [ 0.0305, -0.0106, -0.0029]],\n",
       " \n",
       "          [[-0.0092,  0.0058, -0.0247],\n",
       "           [-0.0092, -0.0432,  0.0493],\n",
       "           [ 0.0403, -0.0400,  0.0044]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0401, -0.0285, -0.0259],\n",
       "           [-0.0050, -0.0551,  0.0106],\n",
       "           [ 0.0445,  0.0369, -0.0460]],\n",
       " \n",
       "          [[-0.0178,  0.0308,  0.0211],\n",
       "           [ 0.0263,  0.0247, -0.0142],\n",
       "           [ 0.0390,  0.0552,  0.0218]],\n",
       " \n",
       "          [[-0.0097,  0.0256,  0.0409],\n",
       "           [-0.0466,  0.0163, -0.0281],\n",
       "           [ 0.0030, -0.0391, -0.0109]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0194, -0.0357,  0.0117],\n",
       "           [ 0.0072, -0.0325, -0.0014],\n",
       "           [ 0.0456, -0.0435,  0.0098]],\n",
       " \n",
       "          [[ 0.0320,  0.0543, -0.0537],\n",
       "           [ 0.0267,  0.0560,  0.0403],\n",
       "           [-0.0508, -0.0085, -0.0072]],\n",
       " \n",
       "          [[-0.0085,  0.0042,  0.0038],\n",
       "           [ 0.0312, -0.0462, -0.0416],\n",
       "           [-0.0018, -0.0555,  0.0578]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0169,  0.0042,  0.0447],\n",
       "           [-0.0125,  0.0027,  0.0512],\n",
       "           [-0.0242, -0.0469, -0.0531]],\n",
       " \n",
       "          [[-0.0371, -0.0043, -0.0548],\n",
       "           [-0.0245,  0.0057,  0.0537],\n",
       "           [-0.0011,  0.0426,  0.0344]],\n",
       " \n",
       "          [[-0.0172,  0.0337, -0.0225],\n",
       "           [ 0.0088, -0.0114,  0.0121],\n",
       "           [-0.0192,  0.0237,  0.0269]]],\n",
       " \n",
       " \n",
       "         [[[-0.0037, -0.0553, -0.0541],\n",
       "           [-0.0205, -0.0239,  0.0142],\n",
       "           [ 0.0084, -0.0058,  0.0161]],\n",
       " \n",
       "          [[ 0.0074,  0.0498,  0.0194],\n",
       "           [-0.0311, -0.0490, -0.0356],\n",
       "           [-0.0336,  0.0319, -0.0069]],\n",
       " \n",
       "          [[-0.0362, -0.0574, -0.0031],\n",
       "           [-0.0213, -0.0345,  0.0364],\n",
       "           [ 0.0138, -0.0144,  0.0195]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0320, -0.0554, -0.0148],\n",
       "           [-0.0214,  0.0331,  0.0398],\n",
       "           [ 0.0071,  0.0106, -0.0159]],\n",
       " \n",
       "          [[-0.0255,  0.0531,  0.0584],\n",
       "           [ 0.0261,  0.0347, -0.0573],\n",
       "           [ 0.0132,  0.0088, -0.0572]],\n",
       " \n",
       "          [[ 0.0217, -0.0435,  0.0497],\n",
       "           [ 0.0121,  0.0476, -0.0020],\n",
       "           [-0.0400,  0.0024, -0.0448]]],\n",
       " \n",
       " \n",
       "         [[[-0.0536, -0.0045,  0.0082],\n",
       "           [ 0.0016,  0.0405, -0.0227],\n",
       "           [-0.0341,  0.0054,  0.0062]],\n",
       " \n",
       "          [[-0.0014, -0.0461, -0.0520],\n",
       "           [-0.0377,  0.0143,  0.0103],\n",
       "           [ 0.0545, -0.0154, -0.0308]],\n",
       " \n",
       "          [[-0.0100,  0.0565, -0.0555],\n",
       "           [ 0.0302, -0.0189,  0.0516],\n",
       "           [ 0.0415,  0.0222,  0.0087]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0453, -0.0079,  0.0073],\n",
       "           [-0.0204,  0.0051, -0.0157],\n",
       "           [ 0.0565,  0.0389, -0.0149]],\n",
       " \n",
       "          [[ 0.0438, -0.0230,  0.0282],\n",
       "           [ 0.0552, -0.0253,  0.0328],\n",
       "           [-0.0390, -0.0553,  0.0518]],\n",
       " \n",
       "          [[ 0.0100, -0.0365,  0.0531],\n",
       "           [ 0.0285,  0.0130, -0.0063],\n",
       "           [ 0.0179, -0.0586, -0.0554]]]]),\n",
       " 'layer1.0.bias': tensor([-0.0543, -0.0043, -0.0017,  0.0498, -0.0517,  0.0165,  0.0087,  0.0565,\n",
       "          0.0444, -0.0543, -0.0388,  0.0033,  0.0551,  0.0235,  0.0446, -0.0100,\n",
       "         -0.0346,  0.0379,  0.0387,  0.0266, -0.0253,  0.0476,  0.0511, -0.0268,\n",
       "         -0.0131,  0.0463,  0.0268,  0.0487,  0.0120, -0.0506,  0.0130, -0.0039]),\n",
       " 'layer1.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer1.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.0.weight': tensor([[[[ 5.7134e-02,  2.2763e-03,  7.6729e-03],\n",
       "           [ 2.2283e-02, -5.0950e-02, -1.4664e-02],\n",
       "           [-4.8651e-02, -4.9914e-02,  2.2173e-02]],\n",
       " \n",
       "          [[-2.2566e-02, -3.4802e-02, -5.1511e-02],\n",
       "           [ 5.8050e-02, -4.7091e-02, -4.5683e-02],\n",
       "           [-4.2887e-02, -2.2843e-02,  9.9157e-03]],\n",
       " \n",
       "          [[-1.1733e-02, -4.2466e-02,  3.9983e-02],\n",
       "           [-3.8778e-02, -3.6147e-02,  6.0745e-03],\n",
       "           [-1.9005e-02, -3.8071e-02, -4.7358e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8251e-02, -2.0059e-02, -1.7664e-03],\n",
       "           [ 3.6452e-02, -5.8274e-02, -2.5591e-02],\n",
       "           [ 3.0273e-02,  2.4939e-02, -1.4607e-02]],\n",
       " \n",
       "          [[-5.6558e-02,  1.9704e-02, -1.7753e-02],\n",
       "           [ 2.6979e-02,  5.5089e-02,  1.3478e-02],\n",
       "           [ 2.6325e-02,  5.3409e-02, -1.9308e-02]],\n",
       " \n",
       "          [[ 1.3918e-02, -4.2279e-03,  3.3063e-02],\n",
       "           [ 1.9445e-02, -3.4774e-03,  1.6238e-02],\n",
       "           [ 6.9609e-04, -3.7400e-02,  2.5798e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.9733e-02,  5.1662e-02, -3.5295e-02],\n",
       "           [-4.7838e-03, -2.9584e-02,  1.9393e-02],\n",
       "           [-4.9178e-02,  1.5128e-02,  3.1844e-02]],\n",
       " \n",
       "          [[-4.8651e-02, -2.3051e-02,  4.6810e-02],\n",
       "           [ 2.2733e-02,  3.7091e-02,  7.8823e-03],\n",
       "           [ 4.6600e-05, -3.1117e-02, -2.0206e-02]],\n",
       " \n",
       "          [[-5.0931e-02,  5.2320e-02,  1.5128e-02],\n",
       "           [-1.2424e-02, -3.7507e-02,  2.9012e-04],\n",
       "           [ 1.3300e-02,  4.9583e-03,  2.4148e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8632e-02, -4.4404e-02,  1.1814e-02],\n",
       "           [-1.0807e-02,  4.8829e-02,  4.4790e-02],\n",
       "           [-2.0285e-02,  3.6822e-02,  2.8248e-02]],\n",
       " \n",
       "          [[ 1.7641e-02,  1.0618e-02, -3.1017e-02],\n",
       "           [-3.5140e-02, -1.0367e-02, -4.9357e-03],\n",
       "           [-2.6300e-03,  1.1192e-02, -4.5672e-02]],\n",
       " \n",
       "          [[-3.9225e-03, -3.7740e-02, -5.4893e-02],\n",
       "           [ 2.5574e-02,  5.4951e-02, -2.9725e-02],\n",
       "           [ 1.5240e-02, -3.6052e-02,  3.4700e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.5491e-02, -5.2750e-03, -1.8764e-02],\n",
       "           [-1.7387e-02, -5.2585e-02,  7.1799e-03],\n",
       "           [-2.7637e-02, -4.1692e-02,  3.6744e-02]],\n",
       " \n",
       "          [[ 2.0283e-02, -4.8516e-02, -2.9705e-02],\n",
       "           [ 3.5179e-02,  2.7032e-02,  5.6624e-02],\n",
       "           [-3.8420e-03,  1.8063e-02, -2.4304e-02]],\n",
       " \n",
       "          [[-3.5589e-02, -2.8323e-02, -3.3601e-03],\n",
       "           [-6.5405e-04, -5.8679e-02,  5.0192e-02],\n",
       "           [-3.0432e-02, -3.8527e-02, -4.3469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2697e-02, -1.4331e-02,  5.0963e-02],\n",
       "           [ 5.5813e-02,  1.8976e-02,  1.3342e-02],\n",
       "           [ 2.3138e-02,  3.1858e-02,  3.6571e-02]],\n",
       " \n",
       "          [[ 3.4722e-02, -2.1318e-02,  5.0169e-02],\n",
       "           [ 1.3877e-02,  1.4181e-02,  2.9957e-02],\n",
       "           [ 4.5517e-02,  2.8146e-02,  4.4315e-02]],\n",
       " \n",
       "          [[-2.2685e-02,  3.5278e-02, -7.6343e-03],\n",
       "           [ 3.1103e-02, -1.9444e-02, -2.7423e-02],\n",
       "           [ 5.1713e-02, -2.1571e-02, -4.5952e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-5.5247e-02,  3.1720e-02,  2.1539e-02],\n",
       "           [-3.8513e-02, -4.7985e-02, -3.3430e-02],\n",
       "           [-3.0489e-02, -1.7572e-02,  4.2375e-02]],\n",
       " \n",
       "          [[ 4.4120e-02,  5.4889e-02,  2.4734e-02],\n",
       "           [ 3.6550e-03, -4.3214e-02, -2.4624e-03],\n",
       "           [-4.2030e-02,  4.0658e-02, -5.2674e-02]],\n",
       " \n",
       "          [[-7.3320e-03, -7.3222e-03,  3.7609e-02],\n",
       "           [-3.0710e-02, -4.8105e-02, -1.4401e-02],\n",
       "           [-3.6586e-03,  1.9842e-02,  1.5428e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9497e-02, -3.2710e-02, -5.1007e-02],\n",
       "           [-1.2096e-02,  4.4725e-02,  4.9262e-02],\n",
       "           [-4.5488e-02,  5.7023e-02, -1.3938e-02]],\n",
       " \n",
       "          [[ 2.6453e-02, -5.3338e-02,  4.9874e-03],\n",
       "           [ 4.9443e-02,  4.6337e-02,  4.6237e-02],\n",
       "           [ 1.9181e-02, -2.0657e-02, -4.5685e-02]],\n",
       " \n",
       "          [[-2.5192e-03,  2.8761e-02, -4.2599e-02],\n",
       "           [-4.8064e-03,  2.7911e-02, -3.7541e-02],\n",
       "           [-5.1003e-02,  1.0393e-02,  5.6107e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0096e-02,  8.2636e-03,  3.3643e-02],\n",
       "           [-3.5483e-02,  3.9823e-02, -5.1088e-02],\n",
       "           [-5.2329e-02, -7.8036e-03, -2.6994e-02]],\n",
       " \n",
       "          [[ 5.0138e-02, -1.2705e-03,  5.5152e-02],\n",
       "           [ 4.8575e-02, -2.8620e-02,  4.0724e-02],\n",
       "           [ 4.4372e-02, -5.5048e-02,  8.2719e-03]],\n",
       " \n",
       "          [[-3.6917e-03, -4.8237e-02,  1.4326e-02],\n",
       "           [ 5.8474e-02,  9.2294e-04,  5.3283e-02],\n",
       "           [ 3.6018e-02,  1.5803e-02, -4.4104e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.2120e-02, -2.1614e-02,  1.7018e-02],\n",
       "           [-4.2496e-02, -5.5788e-02,  2.9173e-02],\n",
       "           [-4.1194e-02,  3.2194e-03,  2.2686e-02]],\n",
       " \n",
       "          [[ 5.4017e-02,  1.5278e-02, -3.9786e-02],\n",
       "           [ 3.6710e-03, -4.5804e-02, -3.8354e-02],\n",
       "           [-2.4702e-02,  3.4668e-02, -4.7339e-02]],\n",
       " \n",
       "          [[ 5.3430e-02,  1.8570e-02, -3.7024e-02],\n",
       "           [-5.7286e-02,  2.4916e-02, -2.3010e-02],\n",
       "           [ 3.4885e-02, -2.9613e-02,  1.6202e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.0582e-02, -2.6968e-02, -2.8093e-02],\n",
       "           [-8.5723e-04, -1.6351e-02, -1.8424e-02],\n",
       "           [ 3.6358e-02, -2.9207e-02,  4.2901e-02]],\n",
       " \n",
       "          [[ 5.2379e-02,  2.7298e-02, -3.8665e-02],\n",
       "           [ 4.7064e-02, -1.9328e-02,  5.7603e-02],\n",
       "           [ 3.4986e-02,  3.6665e-02, -9.3917e-03]],\n",
       " \n",
       "          [[ 3.7847e-02,  5.5604e-02,  1.2676e-02],\n",
       "           [ 5.7904e-02,  4.6458e-02, -1.0816e-02],\n",
       "           [ 1.4825e-02,  3.0120e-02, -2.4013e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.5582e-02,  7.9506e-03, -5.3923e-02],\n",
       "           [ 3.4684e-02,  3.2537e-03, -8.8748e-03],\n",
       "           [ 5.1414e-02,  2.1381e-02, -4.7578e-02]],\n",
       " \n",
       "          [[-1.9648e-02, -5.0517e-02, -1.2699e-02],\n",
       "           [ 2.0551e-02,  3.4886e-02, -1.7081e-02],\n",
       "           [ 4.5170e-02,  4.6150e-02,  2.6860e-02]],\n",
       " \n",
       "          [[-1.7783e-02,  3.7673e-02,  3.8889e-02],\n",
       "           [-4.2494e-02, -3.3087e-02,  4.2578e-02],\n",
       "           [-1.9450e-02, -4.6741e-02, -2.9636e-02]]]]),\n",
       " 'layer2.0.bias': tensor([-0.0029, -0.0226, -0.0220, -0.0451, -0.0162,  0.0195,  0.0535, -0.0280,\n",
       "         -0.0340,  0.0170,  0.0581,  0.0215, -0.0449,  0.0488,  0.0284,  0.0110,\n",
       "         -0.0304, -0.0164, -0.0357, -0.0168,  0.0295,  0.0206, -0.0200,  0.0095,\n",
       "         -0.0089,  0.0315,  0.0465,  0.0486, -0.0454,  0.0323,  0.0181, -0.0093]),\n",
       " 'layer2.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer2.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.0.weight': tensor([[[[ 0.0349,  0.0080,  0.0391],\n",
       "           [ 0.0168,  0.0509,  0.0433],\n",
       "           [ 0.0178,  0.0479, -0.0166]],\n",
       " \n",
       "          [[-0.0273, -0.0540, -0.0191],\n",
       "           [-0.0348, -0.0212, -0.0429],\n",
       "           [-0.0271, -0.0277,  0.0539]],\n",
       " \n",
       "          [[ 0.0317, -0.0411, -0.0299],\n",
       "           [ 0.0163, -0.0236,  0.0418],\n",
       "           [ 0.0094, -0.0482, -0.0238]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0558,  0.0193, -0.0203],\n",
       "           [-0.0455, -0.0138,  0.0564],\n",
       "           [ 0.0082, -0.0449, -0.0450]],\n",
       " \n",
       "          [[ 0.0185, -0.0095, -0.0317],\n",
       "           [ 0.0377,  0.0436, -0.0243],\n",
       "           [ 0.0119, -0.0278, -0.0025]],\n",
       " \n",
       "          [[-0.0028,  0.0118,  0.0340],\n",
       "           [-0.0475, -0.0382,  0.0570],\n",
       "           [ 0.0181,  0.0342, -0.0580]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0275, -0.0282,  0.0214],\n",
       "           [ 0.0168, -0.0525,  0.0339],\n",
       "           [ 0.0271, -0.0350,  0.0188]],\n",
       " \n",
       "          [[-0.0379,  0.0073,  0.0297],\n",
       "           [-0.0505,  0.0464, -0.0274],\n",
       "           [-0.0421,  0.0336,  0.0277]],\n",
       " \n",
       "          [[-0.0463,  0.0101, -0.0216],\n",
       "           [ 0.0380, -0.0448,  0.0118],\n",
       "           [-0.0039,  0.0029,  0.0205]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0137, -0.0485,  0.0479],\n",
       "           [ 0.0140,  0.0290,  0.0492],\n",
       "           [-0.0348,  0.0098, -0.0530]],\n",
       " \n",
       "          [[ 0.0022,  0.0261,  0.0222],\n",
       "           [-0.0144, -0.0012,  0.0539],\n",
       "           [-0.0323, -0.0358,  0.0455]],\n",
       " \n",
       "          [[-0.0019, -0.0225,  0.0147],\n",
       "           [-0.0320,  0.0233,  0.0163],\n",
       "           [ 0.0575,  0.0426, -0.0043]]],\n",
       " \n",
       " \n",
       "         [[[-0.0363, -0.0312,  0.0324],\n",
       "           [-0.0358,  0.0405, -0.0376],\n",
       "           [-0.0349,  0.0389, -0.0300]],\n",
       " \n",
       "          [[ 0.0290,  0.0511,  0.0255],\n",
       "           [ 0.0415,  0.0384, -0.0417],\n",
       "           [ 0.0170,  0.0173,  0.0497]],\n",
       " \n",
       "          [[-0.0512,  0.0508,  0.0123],\n",
       "           [ 0.0372, -0.0387, -0.0135],\n",
       "           [ 0.0373,  0.0515,  0.0059]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0423, -0.0471, -0.0543],\n",
       "           [-0.0494,  0.0340,  0.0193],\n",
       "           [ 0.0132, -0.0222, -0.0134]],\n",
       " \n",
       "          [[-0.0555,  0.0462, -0.0468],\n",
       "           [-0.0407,  0.0341, -0.0243],\n",
       "           [ 0.0366, -0.0470, -0.0287]],\n",
       " \n",
       "          [[ 0.0117,  0.0141, -0.0320],\n",
       "           [ 0.0347,  0.0127, -0.0439],\n",
       "           [-0.0045,  0.0420,  0.0280]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0276, -0.0193, -0.0327],\n",
       "           [ 0.0056, -0.0327, -0.0540],\n",
       "           [ 0.0408, -0.0589,  0.0439]],\n",
       " \n",
       "          [[ 0.0170,  0.0479,  0.0354],\n",
       "           [-0.0253,  0.0351,  0.0472],\n",
       "           [-0.0431,  0.0366,  0.0009]],\n",
       " \n",
       "          [[-0.0452,  0.0521, -0.0156],\n",
       "           [ 0.0237,  0.0153,  0.0115],\n",
       "           [ 0.0114,  0.0531, -0.0215]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0174, -0.0583, -0.0320],\n",
       "           [ 0.0349,  0.0220,  0.0481],\n",
       "           [-0.0178,  0.0080,  0.0153]],\n",
       " \n",
       "          [[ 0.0321,  0.0128,  0.0074],\n",
       "           [ 0.0360,  0.0581, -0.0427],\n",
       "           [ 0.0326,  0.0437, -0.0364]],\n",
       " \n",
       "          [[ 0.0378, -0.0583, -0.0260],\n",
       "           [-0.0287,  0.0527, -0.0389],\n",
       "           [ 0.0347, -0.0302, -0.0554]]],\n",
       " \n",
       " \n",
       "         [[[-0.0092, -0.0467, -0.0299],\n",
       "           [ 0.0316, -0.0589, -0.0055],\n",
       "           [ 0.0511, -0.0071, -0.0279]],\n",
       " \n",
       "          [[-0.0223,  0.0226, -0.0080],\n",
       "           [ 0.0587, -0.0140, -0.0529],\n",
       "           [-0.0343,  0.0180,  0.0249]],\n",
       " \n",
       "          [[-0.0064,  0.0322,  0.0150],\n",
       "           [-0.0121,  0.0542, -0.0135],\n",
       "           [-0.0501, -0.0066,  0.0361]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0131, -0.0132,  0.0006],\n",
       "           [-0.0170,  0.0108,  0.0513],\n",
       "           [-0.0477, -0.0503, -0.0247]],\n",
       " \n",
       "          [[ 0.0012,  0.0428,  0.0357],\n",
       "           [ 0.0526,  0.0207, -0.0433],\n",
       "           [ 0.0550,  0.0501,  0.0588]],\n",
       " \n",
       "          [[ 0.0333, -0.0109,  0.0188],\n",
       "           [-0.0043, -0.0551,  0.0034],\n",
       "           [ 0.0480,  0.0101, -0.0003]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0053,  0.0389,  0.0388],\n",
       "           [ 0.0026, -0.0537, -0.0568],\n",
       "           [-0.0342,  0.0285, -0.0239]],\n",
       " \n",
       "          [[ 0.0492,  0.0006,  0.0106],\n",
       "           [-0.0431, -0.0318,  0.0212],\n",
       "           [ 0.0052, -0.0454, -0.0238]],\n",
       " \n",
       "          [[ 0.0561,  0.0425, -0.0006],\n",
       "           [-0.0442,  0.0060, -0.0096],\n",
       "           [-0.0088, -0.0156,  0.0323]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0413, -0.0057, -0.0351],\n",
       "           [ 0.0050,  0.0508, -0.0194],\n",
       "           [-0.0276,  0.0149, -0.0189]],\n",
       " \n",
       "          [[-0.0123, -0.0535,  0.0464],\n",
       "           [-0.0081,  0.0378,  0.0531],\n",
       "           [-0.0053, -0.0570, -0.0249]],\n",
       " \n",
       "          [[ 0.0173, -0.0353,  0.0536],\n",
       "           [ 0.0449, -0.0072, -0.0557],\n",
       "           [-0.0291, -0.0258, -0.0001]]]]),\n",
       " 'layer3.0.bias': tensor([-0.0553,  0.0040,  0.0108, -0.0160,  0.0396,  0.0470,  0.0212,  0.0019,\n",
       "          0.0513, -0.0497,  0.0139, -0.0532,  0.0565, -0.0235,  0.0157,  0.0309,\n",
       "          0.0052,  0.0123, -0.0224, -0.0405,  0.0552,  0.0039,  0.0070, -0.0347,\n",
       "          0.0450,  0.0507, -0.0266,  0.0296,  0.0268,  0.0458,  0.0275, -0.0472,\n",
       "          0.0478, -0.0509,  0.0154, -0.0372,  0.0560, -0.0417, -0.0460,  0.0035,\n",
       "         -0.0077,  0.0466, -0.0062, -0.0025, -0.0086,  0.0558,  0.0206,  0.0366,\n",
       "          0.0067,  0.0200, -0.0214, -0.0477, -0.0559, -0.0190,  0.0371,  0.0582,\n",
       "          0.0312, -0.0585, -0.0531, -0.0584,  0.0278, -0.0551,  0.0183,  0.0443]),\n",
       " 'layer3.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer3.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.0.weight': tensor([[[[ 2.5620e-02,  1.1027e-02,  3.8344e-02],\n",
       "           [-5.6369e-04, -1.3636e-02, -1.1476e-02],\n",
       "           [ 2.4599e-02, -1.7833e-02,  1.0314e-02]],\n",
       " \n",
       "          [[-3.6600e-02,  1.6459e-02,  8.5596e-03],\n",
       "           [-2.3940e-02,  3.1190e-02,  1.1611e-03],\n",
       "           [-2.8263e-02, -2.6966e-02, -1.9842e-02]],\n",
       " \n",
       "          [[-2.2325e-02,  1.7213e-02,  1.4972e-02],\n",
       "           [ 1.2437e-03, -1.6358e-02,  2.6994e-02],\n",
       "           [ 6.8585e-03,  4.8376e-04,  2.7526e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0617e-02, -2.6364e-02,  3.6131e-02],\n",
       "           [ 2.8148e-02,  1.4054e-02, -2.4607e-02],\n",
       "           [-6.4064e-03,  3.6277e-02,  6.3002e-03]],\n",
       " \n",
       "          [[-2.6183e-02, -1.6960e-02, -3.2769e-02],\n",
       "           [ 3.3250e-02, -1.0777e-02,  3.2396e-02],\n",
       "           [-8.2837e-03,  3.9580e-02,  2.3819e-02]],\n",
       " \n",
       "          [[ 1.0965e-02, -3.6820e-02, -1.8887e-02],\n",
       "           [ 5.6978e-03, -3.5669e-02, -1.5734e-02],\n",
       "           [-1.7920e-02,  1.7379e-02, -3.0323e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7890e-02,  1.4734e-02,  1.2198e-02],\n",
       "           [-2.2439e-02,  4.1251e-02, -2.5036e-02],\n",
       "           [ 5.7460e-03, -1.1964e-02, -2.5474e-02]],\n",
       " \n",
       "          [[-2.0505e-02,  1.5931e-02,  1.7208e-02],\n",
       "           [-2.7738e-02, -3.5588e-02, -8.7796e-03],\n",
       "           [ 2.6947e-03,  2.5921e-03, -1.3987e-02]],\n",
       " \n",
       "          [[-7.3796e-03, -1.7497e-02,  3.8538e-03],\n",
       "           [ 2.2572e-02, -1.0772e-02,  5.4893e-03],\n",
       "           [ 4.1398e-02, -2.8769e-02, -1.4876e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5627e-02, -2.2806e-03,  1.0660e-02],\n",
       "           [ 3.1863e-03, -3.0281e-02,  3.9491e-02],\n",
       "           [-2.6706e-02, -4.1496e-02, -3.4536e-02]],\n",
       " \n",
       "          [[ 1.2076e-02, -2.2478e-03,  2.5527e-02],\n",
       "           [-5.1937e-03,  7.0800e-04,  2.4908e-02],\n",
       "           [ 3.5183e-02,  2.8290e-03, -1.1281e-02]],\n",
       " \n",
       "          [[ 3.3812e-02,  2.9348e-02,  2.4271e-02],\n",
       "           [ 4.3343e-03,  1.9623e-02,  2.9991e-02],\n",
       "           [ 3.7585e-02,  6.1731e-03, -1.6640e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5880e-02, -6.0504e-03,  2.0034e-03],\n",
       "           [-3.7352e-02, -7.3350e-03,  2.5647e-02],\n",
       "           [ 2.4312e-02, -8.3213e-03,  3.5337e-03]],\n",
       " \n",
       "          [[-3.0441e-02,  6.6977e-03, -1.9300e-02],\n",
       "           [ 3.0446e-02, -7.7699e-03, -5.5637e-03],\n",
       "           [ 1.3507e-02,  2.9579e-02,  3.1732e-02]],\n",
       " \n",
       "          [[-1.2611e-02,  2.5706e-02,  6.1131e-03],\n",
       "           [ 6.8956e-03, -1.2875e-02,  1.7288e-02],\n",
       "           [ 6.3988e-03,  1.7031e-02, -1.8602e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.2298e-03,  3.1480e-02, -2.4839e-02],\n",
       "           [-9.5341e-05, -3.4622e-02,  3.4004e-02],\n",
       "           [-1.9048e-02,  1.2274e-02, -3.6575e-02]],\n",
       " \n",
       "          [[ 2.3614e-02, -1.8650e-02, -2.2995e-02],\n",
       "           [ 1.8063e-02,  3.1919e-02, -3.8414e-02],\n",
       "           [ 3.2621e-02, -2.6842e-02,  2.1469e-02]],\n",
       " \n",
       "          [[ 2.2439e-02,  2.9607e-02, -3.4393e-03],\n",
       "           [ 1.2774e-02, -1.5567e-02,  2.1473e-02],\n",
       "           [-3.5595e-02, -1.9984e-02,  1.7679e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.8253e-03, -3.3776e-02,  4.0900e-02],\n",
       "           [ 2.1382e-02,  2.7088e-02,  4.6202e-04],\n",
       "           [-3.8172e-04,  1.4354e-02, -2.0458e-02]],\n",
       " \n",
       "          [[ 2.8361e-02, -3.9402e-02,  2.3592e-02],\n",
       "           [-1.6914e-02,  3.1797e-02,  1.0471e-02],\n",
       "           [-3.2137e-02,  2.4701e-03, -2.4310e-02]],\n",
       " \n",
       "          [[ 3.4360e-02,  9.9863e-03,  3.2582e-02],\n",
       "           [-3.5713e-02,  2.1561e-02,  2.0948e-02],\n",
       "           [ 2.8734e-02, -2.4535e-02, -1.9657e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8352e-02, -3.0637e-02, -4.1497e-02],\n",
       "           [-2.1351e-02,  1.9204e-02,  6.9097e-03],\n",
       "           [ 9.2071e-03, -2.6410e-02, -2.4193e-03]],\n",
       " \n",
       "          [[ 3.6037e-02,  3.7034e-02,  2.1712e-02],\n",
       "           [-1.5547e-02,  4.0763e-02, -2.4413e-02],\n",
       "           [-3.5063e-02, -6.3464e-03,  1.9633e-02]],\n",
       " \n",
       "          [[-1.1322e-02, -1.5831e-02, -2.7898e-02],\n",
       "           [-1.1176e-02, -4.0802e-02, -1.6075e-03],\n",
       "           [ 7.4114e-03, -1.5146e-02, -2.5475e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.6118e-02,  2.1552e-02, -3.4662e-02],\n",
       "           [-2.2085e-03,  1.5897e-02,  3.3573e-02],\n",
       "           [ 3.4382e-02,  2.0942e-02, -6.2279e-03]],\n",
       " \n",
       "          [[ 2.4146e-02, -3.4124e-02, -3.2239e-02],\n",
       "           [ 2.6915e-02,  1.0536e-02, -3.2622e-02],\n",
       "           [ 2.0656e-02, -1.9801e-02,  4.4186e-03]],\n",
       " \n",
       "          [[-1.3196e-02, -6.5854e-04,  3.5568e-02],\n",
       "           [-4.1158e-02,  1.5582e-02, -3.1423e-02],\n",
       "           [-9.3038e-04,  4.6161e-03, -1.9687e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6987e-03,  7.5396e-03, -7.5504e-03],\n",
       "           [ 9.4232e-03,  2.9016e-02,  2.9479e-02],\n",
       "           [-3.7800e-02,  7.1434e-03, -2.1037e-02]],\n",
       " \n",
       "          [[-1.7767e-02,  7.6964e-03,  6.1694e-03],\n",
       "           [ 2.9679e-02,  1.3413e-02, -7.4646e-04],\n",
       "           [-1.9178e-02, -9.6990e-03, -3.2808e-02]],\n",
       " \n",
       "          [[-3.6097e-02,  2.4256e-02,  3.8199e-02],\n",
       "           [-2.4204e-02, -3.6429e-02, -2.7111e-02],\n",
       "           [ 2.0422e-02,  3.4729e-03,  3.5056e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2510e-02, -1.9212e-02,  2.3803e-02],\n",
       "           [ 1.3745e-02, -2.2359e-02,  2.6260e-02],\n",
       "           [-4.0578e-02,  3.3985e-02,  2.1799e-02]],\n",
       " \n",
       "          [[-6.0673e-03,  3.1644e-02,  3.4686e-03],\n",
       "           [ 3.6875e-02, -4.1006e-02, -6.1496e-03],\n",
       "           [ 7.4729e-03,  1.8152e-03, -1.0912e-02]],\n",
       " \n",
       "          [[-2.6291e-02, -1.4366e-03,  2.9217e-03],\n",
       "           [ 1.3097e-02,  3.0829e-02, -3.4937e-02],\n",
       "           [-3.4530e-02, -3.6971e-02,  1.4080e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6622e-03,  2.5039e-02,  2.8354e-02],\n",
       "           [ 2.3704e-02,  8.1194e-03,  1.8403e-02],\n",
       "           [ 3.3893e-02, -2.9643e-02, -2.5597e-02]],\n",
       " \n",
       "          [[-5.5600e-03,  3.8782e-02,  1.3900e-03],\n",
       "           [-1.6761e-02,  9.2933e-03,  9.7108e-03],\n",
       "           [-2.1357e-03,  3.8266e-02,  3.8584e-02]],\n",
       " \n",
       "          [[ 1.8071e-02,  7.9090e-03,  1.1067e-02],\n",
       "           [ 1.0860e-02,  9.1985e-03,  9.1101e-03],\n",
       "           [ 5.3729e-03, -2.3801e-02, -3.0802e-02]]]]),\n",
       " 'layer4.0.bias': tensor([ 0.0177, -0.0163, -0.0093,  0.0162, -0.0377,  0.0078,  0.0001,  0.0027,\n",
       "         -0.0377,  0.0106, -0.0282,  0.0339, -0.0121, -0.0010, -0.0151, -0.0266,\n",
       "          0.0306,  0.0092, -0.0270,  0.0387,  0.0071,  0.0043,  0.0337, -0.0290,\n",
       "          0.0054, -0.0309, -0.0099,  0.0037,  0.0143,  0.0311, -0.0226, -0.0143,\n",
       "         -0.0285, -0.0150,  0.0323,  0.0416,  0.0100, -0.0162, -0.0373,  0.0130,\n",
       "         -0.0095,  0.0198,  0.0192, -0.0277,  0.0032,  0.0406,  0.0073, -0.0256,\n",
       "         -0.0246,  0.0203,  0.0312, -0.0264, -0.0383, -0.0415, -0.0085, -0.0052,\n",
       "         -0.0147,  0.0275,  0.0078,  0.0238,  0.0250,  0.0253, -0.0249,  0.0367]),\n",
       " 'layer4.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer4.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer5.0.weight': tensor([[[[ 4.0029e-02, -1.5555e-02, -1.9442e-02],\n",
       "           [ 2.7807e-02,  1.2606e-03,  2.2996e-02],\n",
       "           [ 1.6510e-02, -1.8767e-02,  1.4049e-02]],\n",
       " \n",
       "          [[-2.0909e-02,  3.2355e-03,  4.8950e-04],\n",
       "           [ 3.5541e-02, -2.6028e-02, -2.1366e-02],\n",
       "           [-1.8651e-02, -1.4314e-02, -1.5306e-04]],\n",
       " \n",
       "          [[-2.3171e-02,  1.9146e-02,  1.5210e-03],\n",
       "           [ 1.9624e-02, -1.5651e-02, -2.6014e-02],\n",
       "           [-3.2673e-02,  1.8227e-02,  3.6811e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4583e-02, -7.9460e-06, -1.4085e-02],\n",
       "           [ 2.8421e-02, -1.1669e-02,  1.9115e-02],\n",
       "           [ 3.0063e-02,  1.8295e-02, -2.4148e-02]],\n",
       " \n",
       "          [[-3.0112e-02,  3.7937e-02,  3.5968e-02],\n",
       "           [ 1.3086e-02, -1.0907e-02,  2.0002e-02],\n",
       "           [-5.9486e-03,  6.4267e-03, -1.3565e-02]],\n",
       " \n",
       "          [[ 3.3119e-02,  2.9293e-02,  4.7366e-03],\n",
       "           [ 1.3828e-02, -8.6379e-04, -3.8102e-02],\n",
       "           [ 2.7153e-02,  3.1091e-02,  1.0126e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.4183e-03, -1.7757e-03, -2.0380e-02],\n",
       "           [-1.5854e-02, -2.6645e-02,  7.1543e-03],\n",
       "           [ 6.6951e-03, -1.8744e-02, -1.2158e-02]],\n",
       " \n",
       "          [[ 1.2498e-02,  2.4377e-02,  2.7904e-02],\n",
       "           [ 3.8156e-02,  3.0734e-02,  8.7722e-03],\n",
       "           [ 2.6730e-02, -3.1139e-02,  3.4744e-02]],\n",
       " \n",
       "          [[ 2.6575e-02,  2.4073e-02, -3.0729e-02],\n",
       "           [ 2.7972e-02, -3.6623e-02,  2.2270e-02],\n",
       "           [-2.7218e-02,  3.9759e-02, -2.6646e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.4700e-03,  2.2825e-03,  3.6883e-02],\n",
       "           [ 2.7217e-02, -3.1232e-02,  3.1608e-02],\n",
       "           [-1.0017e-02,  3.1206e-02, -3.9591e-02]],\n",
       " \n",
       "          [[-2.9666e-02, -4.0470e-02, -6.2156e-03],\n",
       "           [ 3.0331e-02, -3.6313e-04, -1.9975e-02],\n",
       "           [-3.7550e-02,  2.9411e-02, -3.2907e-02]],\n",
       " \n",
       "          [[ 2.4071e-03,  2.2413e-02,  2.5404e-02],\n",
       "           [ 1.3434e-02, -3.0588e-02,  9.5532e-04],\n",
       "           [-3.2427e-02,  1.6529e-02, -1.6419e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.3955e-02,  7.1121e-03,  2.6891e-02],\n",
       "           [ 4.0416e-02, -3.3873e-02, -1.3531e-02],\n",
       "           [ 1.8637e-02,  5.2441e-05,  2.1841e-02]],\n",
       " \n",
       "          [[-1.7873e-02,  3.0563e-02,  1.1849e-02],\n",
       "           [ 9.3570e-03, -1.1101e-02,  8.0893e-03],\n",
       "           [-8.1875e-03, -1.7321e-02, -9.3326e-05]],\n",
       " \n",
       "          [[-2.1851e-02,  4.0022e-02,  8.1340e-03],\n",
       "           [ 1.9282e-02, -2.6939e-02,  1.7700e-02],\n",
       "           [ 7.5512e-03,  3.9676e-02, -3.6485e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.8432e-03,  1.4899e-02,  2.2023e-02],\n",
       "           [-5.1086e-03, -4.1410e-03, -1.7824e-02],\n",
       "           [ 3.6685e-02, -3.0121e-02, -2.4863e-02]],\n",
       " \n",
       "          [[ 7.5307e-03,  2.6082e-02,  2.2635e-02],\n",
       "           [-3.3264e-02, -1.2277e-02, -1.2866e-02],\n",
       "           [ 3.9813e-02, -1.0466e-02, -7.6253e-03]],\n",
       " \n",
       "          [[-3.7760e-02,  7.5000e-03, -5.7763e-03],\n",
       "           [-3.5322e-02,  3.6979e-02,  2.8847e-03],\n",
       "           [ 6.5473e-03,  3.5336e-02, -5.7323e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.4297e-02, -3.6211e-02,  2.7521e-02],\n",
       "           [-9.7694e-03,  1.5891e-02,  1.4592e-02],\n",
       "           [-3.0556e-02,  9.3818e-03,  4.0286e-02]],\n",
       " \n",
       "          [[-2.7050e-02, -1.7057e-02,  2.0408e-02],\n",
       "           [ 2.3277e-02,  3.4720e-02, -2.5510e-02],\n",
       "           [ 3.2969e-02, -3.7801e-02, -2.1019e-02]],\n",
       " \n",
       "          [[ 3.2294e-02, -5.6080e-03,  3.2732e-02],\n",
       "           [ 8.6077e-03,  2.3426e-02, -2.1425e-02],\n",
       "           [-2.0202e-03,  2.7345e-02,  3.4072e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1652e-02,  3.0896e-02, -2.1383e-02],\n",
       "           [ 3.9330e-02, -3.5811e-02,  1.0374e-02],\n",
       "           [ 1.3004e-02,  1.1354e-02, -3.0207e-02]],\n",
       " \n",
       "          [[-1.4926e-02, -2.4606e-02, -2.8183e-02],\n",
       "           [ 2.0890e-03,  3.1961e-02, -2.7149e-02],\n",
       "           [ 3.3376e-02, -4.2753e-03,  1.3732e-02]],\n",
       " \n",
       "          [[-3.1865e-02,  2.2441e-02, -2.7422e-02],\n",
       "           [ 3.6593e-02, -1.8769e-02, -1.5301e-02],\n",
       "           [ 1.6204e-02,  1.2891e-02, -2.4532e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5621e-02, -7.0786e-03, -1.0761e-02],\n",
       "           [-5.0155e-03, -3.1408e-02,  3.0269e-02],\n",
       "           [ 3.1515e-02, -2.1544e-02,  2.6874e-04]],\n",
       " \n",
       "          [[-4.1376e-02, -6.8147e-04, -2.9623e-02],\n",
       "           [-2.8259e-02,  3.9103e-03, -2.5514e-02],\n",
       "           [ 4.5687e-03, -1.8919e-02, -7.3692e-03]],\n",
       " \n",
       "          [[-2.4708e-02, -2.0455e-02, -1.3034e-02],\n",
       "           [ 2.2828e-02,  4.3709e-04,  3.2861e-02],\n",
       "           [ 1.2342e-02,  3.5667e-02, -2.3626e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7968e-02,  2.0814e-02, -1.4589e-02],\n",
       "           [ 3.5259e-02,  3.3609e-02,  1.2301e-02],\n",
       "           [ 7.3563e-03, -1.7608e-02,  2.7465e-02]],\n",
       " \n",
       "          [[ 6.1034e-03, -1.7165e-02, -6.9117e-03],\n",
       "           [ 2.9456e-02,  3.4874e-02,  1.7228e-02],\n",
       "           [ 3.4576e-02,  1.7019e-02, -2.9988e-02]],\n",
       " \n",
       "          [[-3.0170e-02, -2.8234e-02,  3.7775e-02],\n",
       "           [ 3.1383e-02,  3.2691e-02,  3.0495e-02],\n",
       "           [ 3.4685e-03, -1.7589e-02,  2.4322e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7058e-04, -2.9093e-02, -4.0108e-02],\n",
       "           [ 3.2973e-02,  1.0041e-02,  2.1036e-02],\n",
       "           [-2.9385e-02, -6.8148e-03,  3.9885e-02]],\n",
       " \n",
       "          [[ 2.3979e-03, -3.9971e-02, -1.7004e-02],\n",
       "           [-3.3634e-02,  1.1719e-02, -2.8307e-02],\n",
       "           [-3.2483e-02, -1.1167e-02,  1.5263e-02]],\n",
       " \n",
       "          [[ 6.7131e-03,  3.7708e-02,  3.4297e-02],\n",
       "           [ 2.8094e-02,  3.8445e-02,  3.6810e-05],\n",
       "           [ 8.6228e-03,  1.4023e-02,  2.4469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.1655e-02,  3.6069e-02, -1.6624e-02],\n",
       "           [ 2.2531e-02,  3.7367e-02, -2.7337e-02],\n",
       "           [-5.4987e-03, -3.2980e-03, -2.1241e-02]],\n",
       " \n",
       "          [[-2.5833e-03,  4.0529e-02, -2.8201e-02],\n",
       "           [ 7.9990e-03, -1.9770e-02, -9.0786e-03],\n",
       "           [ 1.9084e-02,  1.7834e-02,  1.1820e-02]],\n",
       " \n",
       "          [[-2.1395e-02, -1.0014e-02,  3.2037e-02],\n",
       "           [ 7.6473e-03,  2.1263e-02,  2.7528e-02],\n",
       "           [ 6.0682e-03,  1.0778e-02,  3.1273e-02]]]]),\n",
       " 'layer5.0.bias': tensor([-0.0339, -0.0223, -0.0282,  0.0156, -0.0012,  0.0039, -0.0381, -0.0168,\n",
       "         -0.0001,  0.0406, -0.0392, -0.0376,  0.0081, -0.0122,  0.0069, -0.0187,\n",
       "         -0.0228,  0.0056,  0.0213,  0.0152, -0.0076,  0.0395,  0.0266,  0.0247,\n",
       "         -0.0403, -0.0306,  0.0379, -0.0167, -0.0330, -0.0408, -0.0215,  0.0353,\n",
       "         -0.0026, -0.0162, -0.0388, -0.0065, -0.0216,  0.0155, -0.0153, -0.0108,\n",
       "         -0.0357, -0.0315, -0.0267, -0.0286, -0.0062, -0.0391,  0.0140, -0.0273,\n",
       "          0.0051,  0.0157, -0.0315, -0.0401,  0.0289, -0.0257, -0.0148,  0.0070,\n",
       "          0.0054,  0.0089, -0.0287, -0.0140, -0.0269,  0.0319, -0.0325, -0.0247]),\n",
       " 'linear.weight': tensor([[ 0.0916,  0.0274,  0.0482, -0.0863,  0.0164, -0.0115, -0.0446,  0.1144,\n",
       "           0.0822,  0.0646,  0.0713,  0.0645,  0.0248,  0.0175,  0.0264,  0.0958,\n",
       "           0.1223,  0.0784, -0.0136,  0.1037,  0.0573,  0.0770, -0.0095, -0.0206,\n",
       "           0.1065,  0.0468,  0.0714,  0.1024,  0.0972, -0.0708, -0.0112,  0.0418,\n",
       "          -0.0384, -0.1069, -0.0260, -0.1035,  0.0921, -0.0480, -0.0806, -0.0412,\n",
       "           0.1044, -0.1037,  0.0918,  0.1132, -0.0616,  0.0739,  0.0543,  0.0419,\n",
       "          -0.1071,  0.0925, -0.0029, -0.0504, -0.1013, -0.1048, -0.1139,  0.0840,\n",
       "           0.0123, -0.0573,  0.0097,  0.1013,  0.0002,  0.0757, -0.1092, -0.0977],\n",
       "         [-0.0976,  0.0218,  0.1236, -0.0156, -0.0988, -0.0866,  0.0803,  0.0230,\n",
       "          -0.0454, -0.0290,  0.1180, -0.1043, -0.1040, -0.0692, -0.0319,  0.0671,\n",
       "           0.0057,  0.0187,  0.1229,  0.0675,  0.0289, -0.0853,  0.0172,  0.0875,\n",
       "          -0.0131, -0.0520, -0.0023, -0.0837, -0.1215,  0.0070,  0.0172, -0.0861,\n",
       "           0.0510,  0.1128,  0.0698, -0.0959,  0.1047, -0.0330,  0.0005,  0.0720,\n",
       "           0.0032, -0.0150, -0.0510, -0.0521,  0.1005,  0.0592, -0.1216, -0.1142,\n",
       "           0.1248,  0.0489, -0.0867, -0.0501, -0.0520,  0.0541, -0.0905,  0.0906,\n",
       "           0.0294,  0.0876,  0.0433, -0.0863,  0.0969, -0.0604, -0.1024, -0.0643],\n",
       "         [ 0.1154, -0.1186, -0.0199, -0.0405, -0.1105,  0.0765,  0.0550, -0.0141,\n",
       "          -0.1237, -0.0296, -0.0304,  0.1103, -0.1205,  0.0008,  0.0556,  0.0408,\n",
       "           0.0326, -0.0969,  0.1037, -0.0864, -0.0293, -0.0055, -0.0150,  0.0192,\n",
       "          -0.0729, -0.0636,  0.0296, -0.0577, -0.0287, -0.0820, -0.0236,  0.0443,\n",
       "          -0.0256, -0.0003, -0.0927, -0.0993,  0.0258,  0.1160, -0.0434, -0.0916,\n",
       "          -0.0447, -0.0580,  0.0066,  0.0233,  0.1130, -0.1072, -0.0153, -0.0757,\n",
       "          -0.1002, -0.0961,  0.0014, -0.0149, -0.1029,  0.1006, -0.0517,  0.0877,\n",
       "          -0.0534, -0.0673,  0.0225,  0.0355,  0.1090, -0.1145,  0.1039, -0.0724],\n",
       "         [ 0.0105, -0.0863,  0.0174,  0.0673, -0.0783, -0.0996,  0.0594, -0.0393,\n",
       "          -0.0898,  0.0047, -0.1083,  0.0007,  0.0800, -0.1056,  0.0060, -0.1029,\n",
       "           0.0600,  0.0489, -0.0016,  0.0796,  0.0368, -0.0254, -0.1187, -0.0487,\n",
       "          -0.0344, -0.0922, -0.0645, -0.0865,  0.0391,  0.0313,  0.0412,  0.1113,\n",
       "          -0.1223, -0.0501, -0.0932, -0.1201,  0.0443,  0.0366, -0.0723,  0.0465,\n",
       "           0.0954,  0.0633,  0.0466, -0.0724, -0.0795, -0.0819, -0.1092,  0.0291,\n",
       "           0.0500,  0.0143, -0.0998, -0.0054,  0.1042,  0.0176, -0.0459,  0.0192,\n",
       "           0.0816, -0.0294, -0.0316, -0.0542,  0.0943, -0.0240,  0.0372, -0.0403],\n",
       "         [-0.0505, -0.0937, -0.1059,  0.0898,  0.1196, -0.1027,  0.0251,  0.0276,\n",
       "          -0.0344,  0.0518, -0.0177,  0.1089,  0.0241,  0.0386, -0.0508,  0.0748,\n",
       "          -0.0992,  0.0156,  0.0612, -0.1040, -0.0413,  0.0628,  0.0228, -0.1098,\n",
       "           0.1152,  0.0852, -0.0362,  0.0163,  0.0398,  0.0036,  0.1198,  0.0906,\n",
       "           0.0250,  0.1074,  0.0016, -0.1161, -0.1173, -0.0486, -0.0867,  0.1088,\n",
       "          -0.0890,  0.0498,  0.0614, -0.1214, -0.0523,  0.0367, -0.0253,  0.0643,\n",
       "          -0.0216,  0.0619,  0.0555,  0.1103, -0.0463, -0.1167, -0.0215, -0.0346,\n",
       "          -0.0006, -0.0089, -0.0418,  0.0205,  0.0769, -0.0936,  0.0747, -0.0514],\n",
       "         [-0.1041, -0.0652, -0.1099, -0.1172, -0.1183,  0.0261, -0.0061, -0.0181,\n",
       "           0.0306,  0.1034,  0.1023, -0.0415, -0.0590,  0.1013, -0.0350, -0.1135,\n",
       "           0.1211,  0.0423,  0.0534, -0.0943,  0.0192, -0.1066,  0.0101, -0.0907,\n",
       "          -0.0641, -0.0925,  0.0244,  0.0263,  0.0090, -0.0468,  0.0813,  0.0006,\n",
       "           0.0742,  0.0435,  0.0780, -0.0913,  0.0158, -0.1105, -0.0535, -0.0402,\n",
       "          -0.0937,  0.0195,  0.0634, -0.0159,  0.1228, -0.0416,  0.0739,  0.0429,\n",
       "           0.0029, -0.0882, -0.0594, -0.0101,  0.0290, -0.0891,  0.0971, -0.0061,\n",
       "          -0.0823, -0.0365,  0.0256, -0.1039,  0.1206,  0.1249,  0.1118, -0.0718]]),\n",
       " 'linear.bias': tensor([ 0.0939, -0.0072, -0.0662,  0.0920, -0.0422,  0.0693])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5253980a-4b74-47e1-8cba-bfcd9ae23134",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN:\n\tMissing key(s) in state_dict: \"layer0.1.running_mean\", \"layer0.1.running_var\", \"layer1.1.running_mean\", \"layer1.1.running_var\", \"layer2.1.running_mean\", \"layer2.1.running_var\", \"layer3.1.running_mean\", \"layer3.1.running_var\", \"layer4.1.running_mean\", \"layer4.1.running_var\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\APPS\\Anaconda3\\envs\\pai\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tMissing key(s) in state_dict: \"layer0.1.running_mean\", \"layer0.1.running_var\", \"layer1.1.running_mean\", \"layer1.1.running_var\", \"layer2.1.running_mean\", \"layer2.1.running_var\", \"layer3.1.running_mean\", \"layer3.1.running_var\", \"layer4.1.running_mean\", \"layer4.1.running_var\". "
     ]
    }
   ],
   "source": [
    "network.load_state_dict(current_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152e191-0a51-4a38-a284-bbdc97b83e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "183ff56e-cff2-477a-9e92-8051a938026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer0.0.weight': tensor([[[[ 0.0595, -0.0510, -0.0224,  0.0542, -0.1087],\n",
       "           [ 0.0692, -0.0238,  0.0587,  0.0161, -0.0141],\n",
       "           [ 0.0320,  0.0057,  0.0422, -0.0450, -0.0084],\n",
       "           [-0.0104,  0.0167, -0.0005,  0.1009,  0.0359],\n",
       "           [-0.0430, -0.0697, -0.0194, -0.0498, -0.0370]],\n",
       " \n",
       "          [[ 0.0055,  0.0688,  0.0628, -0.1129,  0.0716],\n",
       "           [ 0.0323,  0.1095,  0.0762, -0.1052, -0.1098],\n",
       "           [-0.0557,  0.1014, -0.0192,  0.0494, -0.0537],\n",
       "           [ 0.1133, -0.0489,  0.0866,  0.0014, -0.0608],\n",
       "           [ 0.0594, -0.0613,  0.0340, -0.0333, -0.0127]],\n",
       " \n",
       "          [[-0.1110, -0.0551,  0.0627, -0.0281,  0.1150],\n",
       "           [ 0.0926, -0.0054, -0.0771,  0.0703,  0.0358],\n",
       "           [-0.0746,  0.0750,  0.0701,  0.1024, -0.0647],\n",
       "           [-0.0190, -0.0022,  0.0169, -0.0876, -0.0819],\n",
       "           [ 0.0628, -0.0271,  0.0564,  0.0066,  0.0379]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0254,  0.0420,  0.0572, -0.1069,  0.0581],\n",
       "           [-0.0812, -0.0871,  0.0070, -0.0197,  0.0678],\n",
       "           [-0.0669, -0.1027,  0.0840, -0.0171,  0.0649],\n",
       "           [ 0.0371, -0.0866,  0.0232,  0.0277, -0.0773],\n",
       "           [-0.0548,  0.0394,  0.0207, -0.0491, -0.0350]],\n",
       " \n",
       "          [[ 0.1058, -0.0214,  0.0651,  0.0500, -0.0746],\n",
       "           [-0.0982,  0.1108,  0.0060,  0.0791,  0.0239],\n",
       "           [ 0.0371,  0.0863,  0.1095, -0.0766,  0.0144],\n",
       "           [ 0.0862,  0.0837,  0.0717, -0.0836, -0.0832],\n",
       "           [-0.0698,  0.0145,  0.1151, -0.0729,  0.0615]],\n",
       " \n",
       "          [[-0.0639, -0.1086, -0.0245,  0.0665,  0.1072],\n",
       "           [-0.0717,  0.0251,  0.0996,  0.0765,  0.0720],\n",
       "           [ 0.0821,  0.0730,  0.0298, -0.0790, -0.0970],\n",
       "           [-0.0529, -0.0134, -0.0708,  0.0422,  0.0357],\n",
       "           [-0.0261,  0.0444,  0.0373,  0.0705,  0.0778]]],\n",
       " \n",
       " \n",
       "         [[[-0.0391,  0.1128, -0.0133, -0.0040, -0.1090],\n",
       "           [-0.0743, -0.0675, -0.0494,  0.0821, -0.0377],\n",
       "           [-0.0863,  0.0444,  0.0370,  0.0748, -0.0598],\n",
       "           [ 0.0250, -0.0420, -0.0259, -0.0920, -0.0526],\n",
       "           [-0.0354,  0.0494,  0.0211,  0.0285,  0.1153]],\n",
       " \n",
       "          [[ 0.1125,  0.0788,  0.0037, -0.0799,  0.0902],\n",
       "           [-0.0289, -0.0093, -0.0995, -0.0228, -0.0745],\n",
       "           [ 0.1061, -0.0998, -0.0900, -0.0039, -0.0624],\n",
       "           [ 0.0413, -0.0444, -0.0542,  0.0065,  0.0836],\n",
       "           [-0.0812,  0.0542,  0.0742,  0.1130, -0.0808]],\n",
       " \n",
       "          [[ 0.0280, -0.0854,  0.0986, -0.0448,  0.0696],\n",
       "           [ 0.0034, -0.0090, -0.0037,  0.0196,  0.0544],\n",
       "           [ 0.0185,  0.0352, -0.1039,  0.0841,  0.1007],\n",
       "           [ 0.0954,  0.0854, -0.0833, -0.0428,  0.1018],\n",
       "           [-0.0879,  0.1048, -0.0908, -0.0813,  0.0565]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0058, -0.0155,  0.0586, -0.0491,  0.0908],\n",
       "           [-0.0787, -0.0601,  0.0400,  0.0710, -0.0014],\n",
       "           [-0.0906, -0.0046, -0.0390, -0.0369, -0.0213],\n",
       "           [ 0.0278, -0.0269, -0.0810, -0.0577, -0.0967],\n",
       "           [-0.1153,  0.0558,  0.0645,  0.0873,  0.0091]],\n",
       " \n",
       "          [[-0.0475, -0.0694,  0.0575, -0.0698,  0.0863],\n",
       "           [-0.0626, -0.1077, -0.0832,  0.0940,  0.0872],\n",
       "           [ 0.0282,  0.0027,  0.0990,  0.0697,  0.0684],\n",
       "           [-0.0786,  0.0185,  0.1046, -0.0813,  0.1150],\n",
       "           [-0.0756, -0.0339, -0.0054,  0.0300,  0.0355]],\n",
       " \n",
       "          [[-0.0660,  0.0529,  0.0306, -0.0129, -0.1149],\n",
       "           [ 0.1143, -0.0427, -0.0615,  0.1143, -0.0585],\n",
       "           [ 0.0771,  0.0705, -0.0752, -0.0931, -0.0628],\n",
       "           [ 0.0361,  0.1089, -0.0064, -0.0345, -0.0332],\n",
       "           [-0.0804,  0.1154, -0.0013, -0.0914, -0.0789]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0718,  0.0559,  0.0745, -0.0122, -0.0228],\n",
       "           [ 0.0378, -0.0011, -0.0372,  0.0275, -0.0658],\n",
       "           [-0.0800, -0.0255, -0.0823,  0.0029,  0.0182],\n",
       "           [ 0.1131,  0.0333, -0.0007, -0.0839, -0.0464],\n",
       "           [-0.0188, -0.0831,  0.0225,  0.0831,  0.0661]],\n",
       " \n",
       "          [[-0.0479, -0.0282,  0.1151, -0.0185, -0.1037],\n",
       "           [-0.0010,  0.0059, -0.0429, -0.0125, -0.0942],\n",
       "           [ 0.0356, -0.0801,  0.0397,  0.0870, -0.0745],\n",
       "           [-0.0452,  0.0111,  0.0003,  0.0677, -0.0069],\n",
       "           [ 0.0187, -0.0319,  0.0381,  0.0349, -0.0930]],\n",
       " \n",
       "          [[ 0.0613, -0.0237,  0.1034, -0.1146, -0.0115],\n",
       "           [ 0.0522,  0.0796,  0.0015, -0.0624, -0.0893],\n",
       "           [-0.0874,  0.0930, -0.1006, -0.0457,  0.0605],\n",
       "           [ 0.0631, -0.1010,  0.0229,  0.0140,  0.1060],\n",
       "           [-0.0041,  0.0490, -0.0100,  0.1031, -0.0118]]],\n",
       " \n",
       " \n",
       "         [[[-0.0679,  0.0213, -0.0611,  0.0289,  0.0803],\n",
       "           [-0.0898, -0.0840,  0.0016, -0.0068, -0.0359],\n",
       "           [ 0.0967,  0.0518, -0.0383,  0.0167, -0.0174],\n",
       "           [-0.0739,  0.0472, -0.0762,  0.0140,  0.0784],\n",
       "           [-0.1061,  0.0051,  0.1066,  0.0521, -0.0455]],\n",
       " \n",
       "          [[ 0.0182, -0.1084,  0.0185,  0.1004,  0.1003],\n",
       "           [-0.0018,  0.0419, -0.0192, -0.0324,  0.0022],\n",
       "           [-0.0673,  0.0465,  0.0566, -0.0313, -0.0263],\n",
       "           [-0.0805,  0.0148,  0.0459,  0.1096, -0.1088],\n",
       "           [-0.0974,  0.0033,  0.1067,  0.0074,  0.0321]],\n",
       " \n",
       "          [[ 0.0164, -0.0138,  0.0824,  0.0848, -0.0666],\n",
       "           [-0.0692, -0.0898, -0.0281, -0.0026,  0.0966],\n",
       "           [-0.1118,  0.0820, -0.0645,  0.0094, -0.0054],\n",
       "           [ 0.0652, -0.0966, -0.0806,  0.0026,  0.0582],\n",
       "           [-0.0556,  0.0358, -0.0305, -0.1077,  0.0132]]]]),\n",
       " 'layer0.0.bias': tensor([-0.0246,  0.0683,  0.0761,  0.0755,  0.0723, -0.0893, -0.1108,  0.0129,\n",
       "          0.0335, -0.0888,  0.0944, -0.0122, -0.0677,  0.0792,  0.1011,  0.0177,\n",
       "         -0.0368,  0.0125, -0.0851,  0.0712,  0.0725, -0.0216, -0.0915,  0.0857,\n",
       "         -0.0945, -0.0606,  0.0689, -0.0574,  0.0220,  0.0949, -0.0146, -0.0261]),\n",
       " 'layer0.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer0.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer1.0.weight': tensor([[[[ 0.0546,  0.0101,  0.0206],\n",
       "           [-0.0194, -0.0508,  0.0092],\n",
       "           [-0.0348, -0.0305, -0.0483]],\n",
       " \n",
       "          [[ 0.0505, -0.0396,  0.0170],\n",
       "           [ 0.0121,  0.0407,  0.0322],\n",
       "           [-0.0413,  0.0261, -0.0299]],\n",
       " \n",
       "          [[ 0.0022, -0.0213, -0.0504],\n",
       "           [ 0.0176, -0.0393,  0.0577],\n",
       "           [ 0.0237, -0.0204, -0.0345]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0583,  0.0324,  0.0416],\n",
       "           [ 0.0469,  0.0359, -0.0188],\n",
       "           [ 0.0121,  0.0149, -0.0563]],\n",
       " \n",
       "          [[ 0.0318, -0.0475,  0.0212],\n",
       "           [ 0.0569, -0.0164,  0.0081],\n",
       "           [ 0.0546,  0.0486,  0.0492]],\n",
       " \n",
       "          [[-0.0408,  0.0116, -0.0493],\n",
       "           [ 0.0108, -0.0558,  0.0068],\n",
       "           [ 0.0298, -0.0525, -0.0090]]],\n",
       " \n",
       " \n",
       "         [[[-0.0244,  0.0484, -0.0058],\n",
       "           [ 0.0367, -0.0435,  0.0082],\n",
       "           [ 0.0427,  0.0033, -0.0206]],\n",
       " \n",
       "          [[-0.0241,  0.0402,  0.0232],\n",
       "           [ 0.0040,  0.0348, -0.0307],\n",
       "           [-0.0447, -0.0133,  0.0432]],\n",
       " \n",
       "          [[-0.0570, -0.0293,  0.0143],\n",
       "           [ 0.0222,  0.0295,  0.0178],\n",
       "           [-0.0520, -0.0192,  0.0362]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0269, -0.0078, -0.0461],\n",
       "           [-0.0380, -0.0191, -0.0069],\n",
       "           [-0.0127,  0.0033, -0.0540]],\n",
       " \n",
       "          [[-0.0095, -0.0517,  0.0310],\n",
       "           [ 0.0537, -0.0465, -0.0424],\n",
       "           [ 0.0571,  0.0458,  0.0271]],\n",
       " \n",
       "          [[-0.0372,  0.0185, -0.0019],\n",
       "           [ 0.0444,  0.0367, -0.0067],\n",
       "           [ 0.0230, -0.0515,  0.0101]]],\n",
       " \n",
       " \n",
       "         [[[-0.0359,  0.0468, -0.0428],\n",
       "           [-0.0512, -0.0502, -0.0168],\n",
       "           [ 0.0032, -0.0068,  0.0242]],\n",
       " \n",
       "          [[-0.0523, -0.0346, -0.0082],\n",
       "           [-0.0019, -0.0128,  0.0270],\n",
       "           [ 0.0305, -0.0106, -0.0029]],\n",
       " \n",
       "          [[-0.0092,  0.0058, -0.0247],\n",
       "           [-0.0092, -0.0432,  0.0493],\n",
       "           [ 0.0403, -0.0400,  0.0044]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0401, -0.0285, -0.0259],\n",
       "           [-0.0050, -0.0551,  0.0106],\n",
       "           [ 0.0445,  0.0369, -0.0460]],\n",
       " \n",
       "          [[-0.0178,  0.0308,  0.0211],\n",
       "           [ 0.0263,  0.0247, -0.0142],\n",
       "           [ 0.0390,  0.0552,  0.0218]],\n",
       " \n",
       "          [[-0.0097,  0.0256,  0.0409],\n",
       "           [-0.0466,  0.0163, -0.0281],\n",
       "           [ 0.0030, -0.0391, -0.0109]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0194, -0.0357,  0.0117],\n",
       "           [ 0.0072, -0.0325, -0.0014],\n",
       "           [ 0.0456, -0.0435,  0.0098]],\n",
       " \n",
       "          [[ 0.0320,  0.0543, -0.0537],\n",
       "           [ 0.0267,  0.0560,  0.0403],\n",
       "           [-0.0508, -0.0085, -0.0072]],\n",
       " \n",
       "          [[-0.0085,  0.0042,  0.0038],\n",
       "           [ 0.0312, -0.0462, -0.0416],\n",
       "           [-0.0018, -0.0555,  0.0578]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0169,  0.0042,  0.0447],\n",
       "           [-0.0125,  0.0027,  0.0512],\n",
       "           [-0.0242, -0.0469, -0.0531]],\n",
       " \n",
       "          [[-0.0371, -0.0043, -0.0548],\n",
       "           [-0.0245,  0.0057,  0.0537],\n",
       "           [-0.0011,  0.0426,  0.0344]],\n",
       " \n",
       "          [[-0.0172,  0.0337, -0.0225],\n",
       "           [ 0.0088, -0.0114,  0.0121],\n",
       "           [-0.0192,  0.0237,  0.0269]]],\n",
       " \n",
       " \n",
       "         [[[-0.0037, -0.0553, -0.0541],\n",
       "           [-0.0205, -0.0239,  0.0142],\n",
       "           [ 0.0084, -0.0058,  0.0161]],\n",
       " \n",
       "          [[ 0.0074,  0.0498,  0.0194],\n",
       "           [-0.0311, -0.0490, -0.0356],\n",
       "           [-0.0336,  0.0319, -0.0069]],\n",
       " \n",
       "          [[-0.0362, -0.0574, -0.0031],\n",
       "           [-0.0213, -0.0345,  0.0364],\n",
       "           [ 0.0138, -0.0144,  0.0195]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0320, -0.0554, -0.0148],\n",
       "           [-0.0214,  0.0331,  0.0398],\n",
       "           [ 0.0071,  0.0106, -0.0159]],\n",
       " \n",
       "          [[-0.0255,  0.0531,  0.0584],\n",
       "           [ 0.0261,  0.0347, -0.0573],\n",
       "           [ 0.0132,  0.0088, -0.0572]],\n",
       " \n",
       "          [[ 0.0217, -0.0435,  0.0497],\n",
       "           [ 0.0121,  0.0476, -0.0020],\n",
       "           [-0.0400,  0.0024, -0.0448]]],\n",
       " \n",
       " \n",
       "         [[[-0.0536, -0.0045,  0.0082],\n",
       "           [ 0.0016,  0.0405, -0.0227],\n",
       "           [-0.0341,  0.0054,  0.0062]],\n",
       " \n",
       "          [[-0.0014, -0.0461, -0.0520],\n",
       "           [-0.0377,  0.0143,  0.0103],\n",
       "           [ 0.0545, -0.0154, -0.0308]],\n",
       " \n",
       "          [[-0.0100,  0.0565, -0.0555],\n",
       "           [ 0.0302, -0.0189,  0.0516],\n",
       "           [ 0.0415,  0.0222,  0.0087]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0453, -0.0079,  0.0073],\n",
       "           [-0.0204,  0.0051, -0.0157],\n",
       "           [ 0.0565,  0.0389, -0.0149]],\n",
       " \n",
       "          [[ 0.0438, -0.0230,  0.0282],\n",
       "           [ 0.0552, -0.0253,  0.0328],\n",
       "           [-0.0390, -0.0553,  0.0518]],\n",
       " \n",
       "          [[ 0.0100, -0.0365,  0.0531],\n",
       "           [ 0.0285,  0.0130, -0.0063],\n",
       "           [ 0.0179, -0.0586, -0.0554]]]]),\n",
       " 'layer1.0.bias': tensor([-0.0543, -0.0043, -0.0017,  0.0498, -0.0517,  0.0165,  0.0087,  0.0565,\n",
       "          0.0444, -0.0543, -0.0388,  0.0033,  0.0551,  0.0235,  0.0446, -0.0100,\n",
       "         -0.0346,  0.0379,  0.0387,  0.0266, -0.0253,  0.0476,  0.0511, -0.0268,\n",
       "         -0.0131,  0.0463,  0.0268,  0.0487,  0.0120, -0.0506,  0.0130, -0.0039]),\n",
       " 'layer1.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer1.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer2.0.weight': tensor([[[[ 5.7134e-02,  2.2763e-03,  7.6729e-03],\n",
       "           [ 2.2283e-02, -5.0950e-02, -1.4664e-02],\n",
       "           [-4.8651e-02, -4.9914e-02,  2.2173e-02]],\n",
       " \n",
       "          [[-2.2566e-02, -3.4802e-02, -5.1511e-02],\n",
       "           [ 5.8050e-02, -4.7091e-02, -4.5683e-02],\n",
       "           [-4.2887e-02, -2.2843e-02,  9.9157e-03]],\n",
       " \n",
       "          [[-1.1733e-02, -4.2466e-02,  3.9983e-02],\n",
       "           [-3.8778e-02, -3.6147e-02,  6.0745e-03],\n",
       "           [-1.9005e-02, -3.8071e-02, -4.7358e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8251e-02, -2.0059e-02, -1.7664e-03],\n",
       "           [ 3.6452e-02, -5.8274e-02, -2.5591e-02],\n",
       "           [ 3.0273e-02,  2.4939e-02, -1.4607e-02]],\n",
       " \n",
       "          [[-5.6558e-02,  1.9704e-02, -1.7753e-02],\n",
       "           [ 2.6979e-02,  5.5089e-02,  1.3478e-02],\n",
       "           [ 2.6325e-02,  5.3409e-02, -1.9308e-02]],\n",
       " \n",
       "          [[ 1.3918e-02, -4.2279e-03,  3.3063e-02],\n",
       "           [ 1.9445e-02, -3.4774e-03,  1.6238e-02],\n",
       "           [ 6.9609e-04, -3.7400e-02,  2.5798e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.9733e-02,  5.1662e-02, -3.5295e-02],\n",
       "           [-4.7838e-03, -2.9584e-02,  1.9393e-02],\n",
       "           [-4.9178e-02,  1.5128e-02,  3.1844e-02]],\n",
       " \n",
       "          [[-4.8651e-02, -2.3051e-02,  4.6810e-02],\n",
       "           [ 2.2733e-02,  3.7091e-02,  7.8823e-03],\n",
       "           [ 4.6600e-05, -3.1117e-02, -2.0206e-02]],\n",
       " \n",
       "          [[-5.0931e-02,  5.2320e-02,  1.5128e-02],\n",
       "           [-1.2424e-02, -3.7507e-02,  2.9012e-04],\n",
       "           [ 1.3300e-02,  4.9583e-03,  2.4148e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8632e-02, -4.4404e-02,  1.1814e-02],\n",
       "           [-1.0807e-02,  4.8829e-02,  4.4790e-02],\n",
       "           [-2.0285e-02,  3.6822e-02,  2.8248e-02]],\n",
       " \n",
       "          [[ 1.7641e-02,  1.0618e-02, -3.1017e-02],\n",
       "           [-3.5140e-02, -1.0367e-02, -4.9357e-03],\n",
       "           [-2.6300e-03,  1.1192e-02, -4.5672e-02]],\n",
       " \n",
       "          [[-3.9225e-03, -3.7740e-02, -5.4893e-02],\n",
       "           [ 2.5574e-02,  5.4951e-02, -2.9725e-02],\n",
       "           [ 1.5240e-02, -3.6052e-02,  3.4700e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.5491e-02, -5.2750e-03, -1.8764e-02],\n",
       "           [-1.7387e-02, -5.2585e-02,  7.1799e-03],\n",
       "           [-2.7637e-02, -4.1692e-02,  3.6744e-02]],\n",
       " \n",
       "          [[ 2.0283e-02, -4.8516e-02, -2.9705e-02],\n",
       "           [ 3.5179e-02,  2.7032e-02,  5.6624e-02],\n",
       "           [-3.8420e-03,  1.8063e-02, -2.4304e-02]],\n",
       " \n",
       "          [[-3.5589e-02, -2.8323e-02, -3.3601e-03],\n",
       "           [-6.5405e-04, -5.8679e-02,  5.0192e-02],\n",
       "           [-3.0432e-02, -3.8527e-02, -4.3469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2697e-02, -1.4331e-02,  5.0963e-02],\n",
       "           [ 5.5813e-02,  1.8976e-02,  1.3342e-02],\n",
       "           [ 2.3138e-02,  3.1858e-02,  3.6571e-02]],\n",
       " \n",
       "          [[ 3.4722e-02, -2.1318e-02,  5.0169e-02],\n",
       "           [ 1.3877e-02,  1.4181e-02,  2.9957e-02],\n",
       "           [ 4.5517e-02,  2.8146e-02,  4.4315e-02]],\n",
       " \n",
       "          [[-2.2685e-02,  3.5278e-02, -7.6343e-03],\n",
       "           [ 3.1103e-02, -1.9444e-02, -2.7423e-02],\n",
       "           [ 5.1713e-02, -2.1571e-02, -4.5952e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-5.5247e-02,  3.1720e-02,  2.1539e-02],\n",
       "           [-3.8513e-02, -4.7985e-02, -3.3430e-02],\n",
       "           [-3.0489e-02, -1.7572e-02,  4.2375e-02]],\n",
       " \n",
       "          [[ 4.4120e-02,  5.4889e-02,  2.4734e-02],\n",
       "           [ 3.6550e-03, -4.3214e-02, -2.4624e-03],\n",
       "           [-4.2030e-02,  4.0658e-02, -5.2674e-02]],\n",
       " \n",
       "          [[-7.3320e-03, -7.3222e-03,  3.7609e-02],\n",
       "           [-3.0710e-02, -4.8105e-02, -1.4401e-02],\n",
       "           [-3.6586e-03,  1.9842e-02,  1.5428e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9497e-02, -3.2710e-02, -5.1007e-02],\n",
       "           [-1.2096e-02,  4.4725e-02,  4.9262e-02],\n",
       "           [-4.5488e-02,  5.7023e-02, -1.3938e-02]],\n",
       " \n",
       "          [[ 2.6453e-02, -5.3338e-02,  4.9874e-03],\n",
       "           [ 4.9443e-02,  4.6337e-02,  4.6237e-02],\n",
       "           [ 1.9181e-02, -2.0657e-02, -4.5685e-02]],\n",
       " \n",
       "          [[-2.5192e-03,  2.8761e-02, -4.2599e-02],\n",
       "           [-4.8064e-03,  2.7911e-02, -3.7541e-02],\n",
       "           [-5.1003e-02,  1.0393e-02,  5.6107e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0096e-02,  8.2636e-03,  3.3643e-02],\n",
       "           [-3.5483e-02,  3.9823e-02, -5.1088e-02],\n",
       "           [-5.2329e-02, -7.8036e-03, -2.6994e-02]],\n",
       " \n",
       "          [[ 5.0138e-02, -1.2705e-03,  5.5152e-02],\n",
       "           [ 4.8575e-02, -2.8620e-02,  4.0724e-02],\n",
       "           [ 4.4372e-02, -5.5048e-02,  8.2719e-03]],\n",
       " \n",
       "          [[-3.6917e-03, -4.8237e-02,  1.4326e-02],\n",
       "           [ 5.8474e-02,  9.2294e-04,  5.3283e-02],\n",
       "           [ 3.6018e-02,  1.5803e-02, -4.4104e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.2120e-02, -2.1614e-02,  1.7018e-02],\n",
       "           [-4.2496e-02, -5.5788e-02,  2.9173e-02],\n",
       "           [-4.1194e-02,  3.2194e-03,  2.2686e-02]],\n",
       " \n",
       "          [[ 5.4017e-02,  1.5278e-02, -3.9786e-02],\n",
       "           [ 3.6710e-03, -4.5804e-02, -3.8354e-02],\n",
       "           [-2.4702e-02,  3.4668e-02, -4.7339e-02]],\n",
       " \n",
       "          [[ 5.3430e-02,  1.8570e-02, -3.7024e-02],\n",
       "           [-5.7286e-02,  2.4916e-02, -2.3010e-02],\n",
       "           [ 3.4885e-02, -2.9613e-02,  1.6202e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.0582e-02, -2.6968e-02, -2.8093e-02],\n",
       "           [-8.5723e-04, -1.6351e-02, -1.8424e-02],\n",
       "           [ 3.6358e-02, -2.9207e-02,  4.2901e-02]],\n",
       " \n",
       "          [[ 5.2379e-02,  2.7298e-02, -3.8665e-02],\n",
       "           [ 4.7064e-02, -1.9328e-02,  5.7603e-02],\n",
       "           [ 3.4986e-02,  3.6665e-02, -9.3917e-03]],\n",
       " \n",
       "          [[ 3.7847e-02,  5.5604e-02,  1.2676e-02],\n",
       "           [ 5.7904e-02,  4.6458e-02, -1.0816e-02],\n",
       "           [ 1.4825e-02,  3.0120e-02, -2.4013e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.5582e-02,  7.9506e-03, -5.3923e-02],\n",
       "           [ 3.4684e-02,  3.2537e-03, -8.8748e-03],\n",
       "           [ 5.1414e-02,  2.1381e-02, -4.7578e-02]],\n",
       " \n",
       "          [[-1.9648e-02, -5.0517e-02, -1.2699e-02],\n",
       "           [ 2.0551e-02,  3.4886e-02, -1.7081e-02],\n",
       "           [ 4.5170e-02,  4.6150e-02,  2.6860e-02]],\n",
       " \n",
       "          [[-1.7783e-02,  3.7673e-02,  3.8889e-02],\n",
       "           [-4.2494e-02, -3.3087e-02,  4.2578e-02],\n",
       "           [-1.9450e-02, -4.6741e-02, -2.9636e-02]]]]),\n",
       " 'layer2.0.bias': tensor([-0.0029, -0.0226, -0.0220, -0.0451, -0.0162,  0.0195,  0.0535, -0.0280,\n",
       "         -0.0340,  0.0170,  0.0581,  0.0215, -0.0449,  0.0488,  0.0284,  0.0110,\n",
       "         -0.0304, -0.0164, -0.0357, -0.0168,  0.0295,  0.0206, -0.0200,  0.0095,\n",
       "         -0.0089,  0.0315,  0.0465,  0.0486, -0.0454,  0.0323,  0.0181, -0.0093]),\n",
       " 'layer2.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer2.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer3.0.weight': tensor([[[[ 0.0349,  0.0080,  0.0391],\n",
       "           [ 0.0168,  0.0509,  0.0433],\n",
       "           [ 0.0178,  0.0479, -0.0166]],\n",
       " \n",
       "          [[-0.0273, -0.0540, -0.0191],\n",
       "           [-0.0348, -0.0212, -0.0429],\n",
       "           [-0.0271, -0.0277,  0.0539]],\n",
       " \n",
       "          [[ 0.0317, -0.0411, -0.0299],\n",
       "           [ 0.0163, -0.0236,  0.0418],\n",
       "           [ 0.0094, -0.0482, -0.0238]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0558,  0.0193, -0.0203],\n",
       "           [-0.0455, -0.0138,  0.0564],\n",
       "           [ 0.0082, -0.0449, -0.0450]],\n",
       " \n",
       "          [[ 0.0185, -0.0095, -0.0317],\n",
       "           [ 0.0377,  0.0436, -0.0243],\n",
       "           [ 0.0119, -0.0278, -0.0025]],\n",
       " \n",
       "          [[-0.0028,  0.0118,  0.0340],\n",
       "           [-0.0475, -0.0382,  0.0570],\n",
       "           [ 0.0181,  0.0342, -0.0580]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0275, -0.0282,  0.0214],\n",
       "           [ 0.0168, -0.0525,  0.0339],\n",
       "           [ 0.0271, -0.0350,  0.0188]],\n",
       " \n",
       "          [[-0.0379,  0.0073,  0.0297],\n",
       "           [-0.0505,  0.0464, -0.0274],\n",
       "           [-0.0421,  0.0336,  0.0277]],\n",
       " \n",
       "          [[-0.0463,  0.0101, -0.0216],\n",
       "           [ 0.0380, -0.0448,  0.0118],\n",
       "           [-0.0039,  0.0029,  0.0205]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0137, -0.0485,  0.0479],\n",
       "           [ 0.0140,  0.0290,  0.0492],\n",
       "           [-0.0348,  0.0098, -0.0530]],\n",
       " \n",
       "          [[ 0.0022,  0.0261,  0.0222],\n",
       "           [-0.0144, -0.0012,  0.0539],\n",
       "           [-0.0323, -0.0358,  0.0455]],\n",
       " \n",
       "          [[-0.0019, -0.0225,  0.0147],\n",
       "           [-0.0320,  0.0233,  0.0163],\n",
       "           [ 0.0575,  0.0426, -0.0043]]],\n",
       " \n",
       " \n",
       "         [[[-0.0363, -0.0312,  0.0324],\n",
       "           [-0.0358,  0.0405, -0.0376],\n",
       "           [-0.0349,  0.0389, -0.0300]],\n",
       " \n",
       "          [[ 0.0290,  0.0511,  0.0255],\n",
       "           [ 0.0415,  0.0384, -0.0417],\n",
       "           [ 0.0170,  0.0173,  0.0497]],\n",
       " \n",
       "          [[-0.0512,  0.0508,  0.0123],\n",
       "           [ 0.0372, -0.0387, -0.0135],\n",
       "           [ 0.0373,  0.0515,  0.0059]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0423, -0.0471, -0.0543],\n",
       "           [-0.0494,  0.0340,  0.0193],\n",
       "           [ 0.0132, -0.0222, -0.0134]],\n",
       " \n",
       "          [[-0.0555,  0.0462, -0.0468],\n",
       "           [-0.0407,  0.0341, -0.0243],\n",
       "           [ 0.0366, -0.0470, -0.0287]],\n",
       " \n",
       "          [[ 0.0117,  0.0141, -0.0320],\n",
       "           [ 0.0347,  0.0127, -0.0439],\n",
       "           [-0.0045,  0.0420,  0.0280]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0276, -0.0193, -0.0327],\n",
       "           [ 0.0056, -0.0327, -0.0540],\n",
       "           [ 0.0408, -0.0589,  0.0439]],\n",
       " \n",
       "          [[ 0.0170,  0.0479,  0.0354],\n",
       "           [-0.0253,  0.0351,  0.0472],\n",
       "           [-0.0431,  0.0366,  0.0009]],\n",
       " \n",
       "          [[-0.0452,  0.0521, -0.0156],\n",
       "           [ 0.0237,  0.0153,  0.0115],\n",
       "           [ 0.0114,  0.0531, -0.0215]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0174, -0.0583, -0.0320],\n",
       "           [ 0.0349,  0.0220,  0.0481],\n",
       "           [-0.0178,  0.0080,  0.0153]],\n",
       " \n",
       "          [[ 0.0321,  0.0128,  0.0074],\n",
       "           [ 0.0360,  0.0581, -0.0427],\n",
       "           [ 0.0326,  0.0437, -0.0364]],\n",
       " \n",
       "          [[ 0.0378, -0.0583, -0.0260],\n",
       "           [-0.0287,  0.0527, -0.0389],\n",
       "           [ 0.0347, -0.0302, -0.0554]]],\n",
       " \n",
       " \n",
       "         [[[-0.0092, -0.0467, -0.0299],\n",
       "           [ 0.0316, -0.0589, -0.0055],\n",
       "           [ 0.0511, -0.0071, -0.0279]],\n",
       " \n",
       "          [[-0.0223,  0.0226, -0.0080],\n",
       "           [ 0.0587, -0.0140, -0.0529],\n",
       "           [-0.0343,  0.0180,  0.0249]],\n",
       " \n",
       "          [[-0.0064,  0.0322,  0.0150],\n",
       "           [-0.0121,  0.0542, -0.0135],\n",
       "           [-0.0501, -0.0066,  0.0361]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0131, -0.0132,  0.0006],\n",
       "           [-0.0170,  0.0108,  0.0513],\n",
       "           [-0.0477, -0.0503, -0.0247]],\n",
       " \n",
       "          [[ 0.0012,  0.0428,  0.0357],\n",
       "           [ 0.0526,  0.0207, -0.0433],\n",
       "           [ 0.0550,  0.0501,  0.0588]],\n",
       " \n",
       "          [[ 0.0333, -0.0109,  0.0188],\n",
       "           [-0.0043, -0.0551,  0.0034],\n",
       "           [ 0.0480,  0.0101, -0.0003]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0053,  0.0389,  0.0388],\n",
       "           [ 0.0026, -0.0537, -0.0568],\n",
       "           [-0.0342,  0.0285, -0.0239]],\n",
       " \n",
       "          [[ 0.0492,  0.0006,  0.0106],\n",
       "           [-0.0431, -0.0318,  0.0212],\n",
       "           [ 0.0052, -0.0454, -0.0238]],\n",
       " \n",
       "          [[ 0.0561,  0.0425, -0.0006],\n",
       "           [-0.0442,  0.0060, -0.0096],\n",
       "           [-0.0088, -0.0156,  0.0323]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0413, -0.0057, -0.0351],\n",
       "           [ 0.0050,  0.0508, -0.0194],\n",
       "           [-0.0276,  0.0149, -0.0189]],\n",
       " \n",
       "          [[-0.0123, -0.0535,  0.0464],\n",
       "           [-0.0081,  0.0378,  0.0531],\n",
       "           [-0.0053, -0.0570, -0.0249]],\n",
       " \n",
       "          [[ 0.0173, -0.0353,  0.0536],\n",
       "           [ 0.0449, -0.0072, -0.0557],\n",
       "           [-0.0291, -0.0258, -0.0001]]]]),\n",
       " 'layer3.0.bias': tensor([-0.0553,  0.0040,  0.0108, -0.0160,  0.0396,  0.0470,  0.0212,  0.0019,\n",
       "          0.0513, -0.0497,  0.0139, -0.0532,  0.0565, -0.0235,  0.0157,  0.0309,\n",
       "          0.0052,  0.0123, -0.0224, -0.0405,  0.0552,  0.0039,  0.0070, -0.0347,\n",
       "          0.0450,  0.0507, -0.0266,  0.0296,  0.0268,  0.0458,  0.0275, -0.0472,\n",
       "          0.0478, -0.0509,  0.0154, -0.0372,  0.0560, -0.0417, -0.0460,  0.0035,\n",
       "         -0.0077,  0.0466, -0.0062, -0.0025, -0.0086,  0.0558,  0.0206,  0.0366,\n",
       "          0.0067,  0.0200, -0.0214, -0.0477, -0.0559, -0.0190,  0.0371,  0.0582,\n",
       "          0.0312, -0.0585, -0.0531, -0.0584,  0.0278, -0.0551,  0.0183,  0.0443]),\n",
       " 'layer3.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer3.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer4.0.weight': tensor([[[[ 2.5620e-02,  1.1027e-02,  3.8344e-02],\n",
       "           [-5.6369e-04, -1.3636e-02, -1.1476e-02],\n",
       "           [ 2.4599e-02, -1.7833e-02,  1.0314e-02]],\n",
       " \n",
       "          [[-3.6600e-02,  1.6459e-02,  8.5596e-03],\n",
       "           [-2.3940e-02,  3.1190e-02,  1.1611e-03],\n",
       "           [-2.8263e-02, -2.6966e-02, -1.9842e-02]],\n",
       " \n",
       "          [[-2.2325e-02,  1.7213e-02,  1.4972e-02],\n",
       "           [ 1.2437e-03, -1.6358e-02,  2.6994e-02],\n",
       "           [ 6.8585e-03,  4.8376e-04,  2.7526e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0617e-02, -2.6364e-02,  3.6131e-02],\n",
       "           [ 2.8148e-02,  1.4054e-02, -2.4607e-02],\n",
       "           [-6.4064e-03,  3.6277e-02,  6.3002e-03]],\n",
       " \n",
       "          [[-2.6183e-02, -1.6960e-02, -3.2769e-02],\n",
       "           [ 3.3250e-02, -1.0777e-02,  3.2396e-02],\n",
       "           [-8.2837e-03,  3.9580e-02,  2.3819e-02]],\n",
       " \n",
       "          [[ 1.0965e-02, -3.6820e-02, -1.8887e-02],\n",
       "           [ 5.6978e-03, -3.5669e-02, -1.5734e-02],\n",
       "           [-1.7920e-02,  1.7379e-02, -3.0323e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7890e-02,  1.4734e-02,  1.2198e-02],\n",
       "           [-2.2439e-02,  4.1251e-02, -2.5036e-02],\n",
       "           [ 5.7460e-03, -1.1964e-02, -2.5474e-02]],\n",
       " \n",
       "          [[-2.0505e-02,  1.5931e-02,  1.7208e-02],\n",
       "           [-2.7738e-02, -3.5588e-02, -8.7796e-03],\n",
       "           [ 2.6947e-03,  2.5921e-03, -1.3987e-02]],\n",
       " \n",
       "          [[-7.3796e-03, -1.7497e-02,  3.8538e-03],\n",
       "           [ 2.2572e-02, -1.0772e-02,  5.4893e-03],\n",
       "           [ 4.1398e-02, -2.8769e-02, -1.4876e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5627e-02, -2.2806e-03,  1.0660e-02],\n",
       "           [ 3.1863e-03, -3.0281e-02,  3.9491e-02],\n",
       "           [-2.6706e-02, -4.1496e-02, -3.4536e-02]],\n",
       " \n",
       "          [[ 1.2076e-02, -2.2478e-03,  2.5527e-02],\n",
       "           [-5.1937e-03,  7.0800e-04,  2.4908e-02],\n",
       "           [ 3.5183e-02,  2.8290e-03, -1.1281e-02]],\n",
       " \n",
       "          [[ 3.3812e-02,  2.9348e-02,  2.4271e-02],\n",
       "           [ 4.3343e-03,  1.9623e-02,  2.9991e-02],\n",
       "           [ 3.7585e-02,  6.1731e-03, -1.6640e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5880e-02, -6.0504e-03,  2.0034e-03],\n",
       "           [-3.7352e-02, -7.3350e-03,  2.5647e-02],\n",
       "           [ 2.4312e-02, -8.3213e-03,  3.5337e-03]],\n",
       " \n",
       "          [[-3.0441e-02,  6.6977e-03, -1.9300e-02],\n",
       "           [ 3.0446e-02, -7.7699e-03, -5.5637e-03],\n",
       "           [ 1.3507e-02,  2.9579e-02,  3.1732e-02]],\n",
       " \n",
       "          [[-1.2611e-02,  2.5706e-02,  6.1131e-03],\n",
       "           [ 6.8956e-03, -1.2875e-02,  1.7288e-02],\n",
       "           [ 6.3988e-03,  1.7031e-02, -1.8602e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.2298e-03,  3.1480e-02, -2.4839e-02],\n",
       "           [-9.5341e-05, -3.4622e-02,  3.4004e-02],\n",
       "           [-1.9048e-02,  1.2274e-02, -3.6575e-02]],\n",
       " \n",
       "          [[ 2.3614e-02, -1.8650e-02, -2.2995e-02],\n",
       "           [ 1.8063e-02,  3.1919e-02, -3.8414e-02],\n",
       "           [ 3.2621e-02, -2.6842e-02,  2.1469e-02]],\n",
       " \n",
       "          [[ 2.2439e-02,  2.9607e-02, -3.4393e-03],\n",
       "           [ 1.2774e-02, -1.5567e-02,  2.1473e-02],\n",
       "           [-3.5595e-02, -1.9984e-02,  1.7679e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.8253e-03, -3.3776e-02,  4.0900e-02],\n",
       "           [ 2.1382e-02,  2.7088e-02,  4.6202e-04],\n",
       "           [-3.8172e-04,  1.4354e-02, -2.0458e-02]],\n",
       " \n",
       "          [[ 2.8361e-02, -3.9402e-02,  2.3592e-02],\n",
       "           [-1.6914e-02,  3.1797e-02,  1.0471e-02],\n",
       "           [-3.2137e-02,  2.4701e-03, -2.4310e-02]],\n",
       " \n",
       "          [[ 3.4360e-02,  9.9863e-03,  3.2582e-02],\n",
       "           [-3.5713e-02,  2.1561e-02,  2.0948e-02],\n",
       "           [ 2.8734e-02, -2.4535e-02, -1.9657e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8352e-02, -3.0637e-02, -4.1497e-02],\n",
       "           [-2.1351e-02,  1.9204e-02,  6.9097e-03],\n",
       "           [ 9.2071e-03, -2.6410e-02, -2.4193e-03]],\n",
       " \n",
       "          [[ 3.6037e-02,  3.7034e-02,  2.1712e-02],\n",
       "           [-1.5547e-02,  4.0763e-02, -2.4413e-02],\n",
       "           [-3.5063e-02, -6.3464e-03,  1.9633e-02]],\n",
       " \n",
       "          [[-1.1322e-02, -1.5831e-02, -2.7898e-02],\n",
       "           [-1.1176e-02, -4.0802e-02, -1.6075e-03],\n",
       "           [ 7.4114e-03, -1.5146e-02, -2.5475e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.6118e-02,  2.1552e-02, -3.4662e-02],\n",
       "           [-2.2085e-03,  1.5897e-02,  3.3573e-02],\n",
       "           [ 3.4382e-02,  2.0942e-02, -6.2279e-03]],\n",
       " \n",
       "          [[ 2.4146e-02, -3.4124e-02, -3.2239e-02],\n",
       "           [ 2.6915e-02,  1.0536e-02, -3.2622e-02],\n",
       "           [ 2.0656e-02, -1.9801e-02,  4.4186e-03]],\n",
       " \n",
       "          [[-1.3196e-02, -6.5854e-04,  3.5568e-02],\n",
       "           [-4.1158e-02,  1.5582e-02, -3.1423e-02],\n",
       "           [-9.3038e-04,  4.6161e-03, -1.9687e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6987e-03,  7.5396e-03, -7.5504e-03],\n",
       "           [ 9.4232e-03,  2.9016e-02,  2.9479e-02],\n",
       "           [-3.7800e-02,  7.1434e-03, -2.1037e-02]],\n",
       " \n",
       "          [[-1.7767e-02,  7.6964e-03,  6.1694e-03],\n",
       "           [ 2.9679e-02,  1.3413e-02, -7.4646e-04],\n",
       "           [-1.9178e-02, -9.6990e-03, -3.2808e-02]],\n",
       " \n",
       "          [[-3.6097e-02,  2.4256e-02,  3.8199e-02],\n",
       "           [-2.4204e-02, -3.6429e-02, -2.7111e-02],\n",
       "           [ 2.0422e-02,  3.4729e-03,  3.5056e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2510e-02, -1.9212e-02,  2.3803e-02],\n",
       "           [ 1.3745e-02, -2.2359e-02,  2.6260e-02],\n",
       "           [-4.0578e-02,  3.3985e-02,  2.1799e-02]],\n",
       " \n",
       "          [[-6.0673e-03,  3.1644e-02,  3.4686e-03],\n",
       "           [ 3.6875e-02, -4.1006e-02, -6.1496e-03],\n",
       "           [ 7.4729e-03,  1.8152e-03, -1.0912e-02]],\n",
       " \n",
       "          [[-2.6291e-02, -1.4366e-03,  2.9217e-03],\n",
       "           [ 1.3097e-02,  3.0829e-02, -3.4937e-02],\n",
       "           [-3.4530e-02, -3.6971e-02,  1.4080e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6622e-03,  2.5039e-02,  2.8354e-02],\n",
       "           [ 2.3704e-02,  8.1194e-03,  1.8403e-02],\n",
       "           [ 3.3893e-02, -2.9643e-02, -2.5597e-02]],\n",
       " \n",
       "          [[-5.5600e-03,  3.8782e-02,  1.3900e-03],\n",
       "           [-1.6761e-02,  9.2933e-03,  9.7108e-03],\n",
       "           [-2.1357e-03,  3.8266e-02,  3.8584e-02]],\n",
       " \n",
       "          [[ 1.8071e-02,  7.9090e-03,  1.1067e-02],\n",
       "           [ 1.0860e-02,  9.1985e-03,  9.1101e-03],\n",
       "           [ 5.3729e-03, -2.3801e-02, -3.0802e-02]]]]),\n",
       " 'layer4.0.bias': tensor([ 0.0177, -0.0163, -0.0093,  0.0162, -0.0377,  0.0078,  0.0001,  0.0027,\n",
       "         -0.0377,  0.0106, -0.0282,  0.0339, -0.0121, -0.0010, -0.0151, -0.0266,\n",
       "          0.0306,  0.0092, -0.0270,  0.0387,  0.0071,  0.0043,  0.0337, -0.0290,\n",
       "          0.0054, -0.0309, -0.0099,  0.0037,  0.0143,  0.0311, -0.0226, -0.0143,\n",
       "         -0.0285, -0.0150,  0.0323,  0.0416,  0.0100, -0.0162, -0.0373,  0.0130,\n",
       "         -0.0095,  0.0198,  0.0192, -0.0277,  0.0032,  0.0406,  0.0073, -0.0256,\n",
       "         -0.0246,  0.0203,  0.0312, -0.0264, -0.0383, -0.0415, -0.0085, -0.0052,\n",
       "         -0.0147,  0.0275,  0.0078,  0.0238,  0.0250,  0.0253, -0.0249,  0.0367]),\n",
       " 'layer4.1.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'layer4.1.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'layer5.0.weight': tensor([[[[ 4.0029e-02, -1.5555e-02, -1.9442e-02],\n",
       "           [ 2.7807e-02,  1.2606e-03,  2.2996e-02],\n",
       "           [ 1.6510e-02, -1.8767e-02,  1.4049e-02]],\n",
       " \n",
       "          [[-2.0909e-02,  3.2355e-03,  4.8950e-04],\n",
       "           [ 3.5541e-02, -2.6028e-02, -2.1366e-02],\n",
       "           [-1.8651e-02, -1.4314e-02, -1.5306e-04]],\n",
       " \n",
       "          [[-2.3171e-02,  1.9146e-02,  1.5210e-03],\n",
       "           [ 1.9624e-02, -1.5651e-02, -2.6014e-02],\n",
       "           [-3.2673e-02,  1.8227e-02,  3.6811e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4583e-02, -7.9460e-06, -1.4085e-02],\n",
       "           [ 2.8421e-02, -1.1669e-02,  1.9115e-02],\n",
       "           [ 3.0063e-02,  1.8295e-02, -2.4148e-02]],\n",
       " \n",
       "          [[-3.0112e-02,  3.7937e-02,  3.5968e-02],\n",
       "           [ 1.3086e-02, -1.0907e-02,  2.0002e-02],\n",
       "           [-5.9486e-03,  6.4267e-03, -1.3565e-02]],\n",
       " \n",
       "          [[ 3.3119e-02,  2.9293e-02,  4.7366e-03],\n",
       "           [ 1.3828e-02, -8.6379e-04, -3.8102e-02],\n",
       "           [ 2.7153e-02,  3.1091e-02,  1.0126e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.4183e-03, -1.7757e-03, -2.0380e-02],\n",
       "           [-1.5854e-02, -2.6645e-02,  7.1543e-03],\n",
       "           [ 6.6951e-03, -1.8744e-02, -1.2158e-02]],\n",
       " \n",
       "          [[ 1.2498e-02,  2.4377e-02,  2.7904e-02],\n",
       "           [ 3.8156e-02,  3.0734e-02,  8.7722e-03],\n",
       "           [ 2.6730e-02, -3.1139e-02,  3.4744e-02]],\n",
       " \n",
       "          [[ 2.6575e-02,  2.4073e-02, -3.0729e-02],\n",
       "           [ 2.7972e-02, -3.6623e-02,  2.2270e-02],\n",
       "           [-2.7218e-02,  3.9759e-02, -2.6646e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.4700e-03,  2.2825e-03,  3.6883e-02],\n",
       "           [ 2.7217e-02, -3.1232e-02,  3.1608e-02],\n",
       "           [-1.0017e-02,  3.1206e-02, -3.9591e-02]],\n",
       " \n",
       "          [[-2.9666e-02, -4.0470e-02, -6.2156e-03],\n",
       "           [ 3.0331e-02, -3.6313e-04, -1.9975e-02],\n",
       "           [-3.7550e-02,  2.9411e-02, -3.2907e-02]],\n",
       " \n",
       "          [[ 2.4071e-03,  2.2413e-02,  2.5404e-02],\n",
       "           [ 1.3434e-02, -3.0588e-02,  9.5532e-04],\n",
       "           [-3.2427e-02,  1.6529e-02, -1.6419e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.3955e-02,  7.1121e-03,  2.6891e-02],\n",
       "           [ 4.0416e-02, -3.3873e-02, -1.3531e-02],\n",
       "           [ 1.8637e-02,  5.2441e-05,  2.1841e-02]],\n",
       " \n",
       "          [[-1.7873e-02,  3.0563e-02,  1.1849e-02],\n",
       "           [ 9.3570e-03, -1.1101e-02,  8.0893e-03],\n",
       "           [-8.1875e-03, -1.7321e-02, -9.3326e-05]],\n",
       " \n",
       "          [[-2.1851e-02,  4.0022e-02,  8.1340e-03],\n",
       "           [ 1.9282e-02, -2.6939e-02,  1.7700e-02],\n",
       "           [ 7.5512e-03,  3.9676e-02, -3.6485e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.8432e-03,  1.4899e-02,  2.2023e-02],\n",
       "           [-5.1086e-03, -4.1410e-03, -1.7824e-02],\n",
       "           [ 3.6685e-02, -3.0121e-02, -2.4863e-02]],\n",
       " \n",
       "          [[ 7.5307e-03,  2.6082e-02,  2.2635e-02],\n",
       "           [-3.3264e-02, -1.2277e-02, -1.2866e-02],\n",
       "           [ 3.9813e-02, -1.0466e-02, -7.6253e-03]],\n",
       " \n",
       "          [[-3.7760e-02,  7.5000e-03, -5.7763e-03],\n",
       "           [-3.5322e-02,  3.6979e-02,  2.8847e-03],\n",
       "           [ 6.5473e-03,  3.5336e-02, -5.7323e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.4297e-02, -3.6211e-02,  2.7521e-02],\n",
       "           [-9.7694e-03,  1.5891e-02,  1.4592e-02],\n",
       "           [-3.0556e-02,  9.3818e-03,  4.0286e-02]],\n",
       " \n",
       "          [[-2.7050e-02, -1.7057e-02,  2.0408e-02],\n",
       "           [ 2.3277e-02,  3.4720e-02, -2.5510e-02],\n",
       "           [ 3.2969e-02, -3.7801e-02, -2.1019e-02]],\n",
       " \n",
       "          [[ 3.2294e-02, -5.6080e-03,  3.2732e-02],\n",
       "           [ 8.6077e-03,  2.3426e-02, -2.1425e-02],\n",
       "           [-2.0202e-03,  2.7345e-02,  3.4072e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1652e-02,  3.0896e-02, -2.1383e-02],\n",
       "           [ 3.9330e-02, -3.5811e-02,  1.0374e-02],\n",
       "           [ 1.3004e-02,  1.1354e-02, -3.0207e-02]],\n",
       " \n",
       "          [[-1.4926e-02, -2.4606e-02, -2.8183e-02],\n",
       "           [ 2.0890e-03,  3.1961e-02, -2.7149e-02],\n",
       "           [ 3.3376e-02, -4.2753e-03,  1.3732e-02]],\n",
       " \n",
       "          [[-3.1865e-02,  2.2441e-02, -2.7422e-02],\n",
       "           [ 3.6593e-02, -1.8769e-02, -1.5301e-02],\n",
       "           [ 1.6204e-02,  1.2891e-02, -2.4532e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5621e-02, -7.0786e-03, -1.0761e-02],\n",
       "           [-5.0155e-03, -3.1408e-02,  3.0269e-02],\n",
       "           [ 3.1515e-02, -2.1544e-02,  2.6874e-04]],\n",
       " \n",
       "          [[-4.1376e-02, -6.8147e-04, -2.9623e-02],\n",
       "           [-2.8259e-02,  3.9103e-03, -2.5514e-02],\n",
       "           [ 4.5687e-03, -1.8919e-02, -7.3692e-03]],\n",
       " \n",
       "          [[-2.4708e-02, -2.0455e-02, -1.3034e-02],\n",
       "           [ 2.2828e-02,  4.3709e-04,  3.2861e-02],\n",
       "           [ 1.2342e-02,  3.5667e-02, -2.3626e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7968e-02,  2.0814e-02, -1.4589e-02],\n",
       "           [ 3.5259e-02,  3.3609e-02,  1.2301e-02],\n",
       "           [ 7.3563e-03, -1.7608e-02,  2.7465e-02]],\n",
       " \n",
       "          [[ 6.1034e-03, -1.7165e-02, -6.9117e-03],\n",
       "           [ 2.9456e-02,  3.4874e-02,  1.7228e-02],\n",
       "           [ 3.4576e-02,  1.7019e-02, -2.9988e-02]],\n",
       " \n",
       "          [[-3.0170e-02, -2.8234e-02,  3.7775e-02],\n",
       "           [ 3.1383e-02,  3.2691e-02,  3.0495e-02],\n",
       "           [ 3.4685e-03, -1.7589e-02,  2.4322e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7058e-04, -2.9093e-02, -4.0108e-02],\n",
       "           [ 3.2973e-02,  1.0041e-02,  2.1036e-02],\n",
       "           [-2.9385e-02, -6.8148e-03,  3.9885e-02]],\n",
       " \n",
       "          [[ 2.3979e-03, -3.9971e-02, -1.7004e-02],\n",
       "           [-3.3634e-02,  1.1719e-02, -2.8307e-02],\n",
       "           [-3.2483e-02, -1.1167e-02,  1.5263e-02]],\n",
       " \n",
       "          [[ 6.7131e-03,  3.7708e-02,  3.4297e-02],\n",
       "           [ 2.8094e-02,  3.8445e-02,  3.6810e-05],\n",
       "           [ 8.6228e-03,  1.4023e-02,  2.4469e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.1655e-02,  3.6069e-02, -1.6624e-02],\n",
       "           [ 2.2531e-02,  3.7367e-02, -2.7337e-02],\n",
       "           [-5.4987e-03, -3.2980e-03, -2.1241e-02]],\n",
       " \n",
       "          [[-2.5833e-03,  4.0529e-02, -2.8201e-02],\n",
       "           [ 7.9990e-03, -1.9770e-02, -9.0786e-03],\n",
       "           [ 1.9084e-02,  1.7834e-02,  1.1820e-02]],\n",
       " \n",
       "          [[-2.1395e-02, -1.0014e-02,  3.2037e-02],\n",
       "           [ 7.6473e-03,  2.1263e-02,  2.7528e-02],\n",
       "           [ 6.0682e-03,  1.0778e-02,  3.1273e-02]]]]),\n",
       " 'layer5.0.bias': tensor([-0.0339, -0.0223, -0.0282,  0.0156, -0.0012,  0.0039, -0.0381, -0.0168,\n",
       "         -0.0001,  0.0406, -0.0392, -0.0376,  0.0081, -0.0122,  0.0069, -0.0187,\n",
       "         -0.0228,  0.0056,  0.0213,  0.0152, -0.0076,  0.0395,  0.0266,  0.0247,\n",
       "         -0.0403, -0.0306,  0.0379, -0.0167, -0.0330, -0.0408, -0.0215,  0.0353,\n",
       "         -0.0026, -0.0162, -0.0388, -0.0065, -0.0216,  0.0155, -0.0153, -0.0108,\n",
       "         -0.0357, -0.0315, -0.0267, -0.0286, -0.0062, -0.0391,  0.0140, -0.0273,\n",
       "          0.0051,  0.0157, -0.0315, -0.0401,  0.0289, -0.0257, -0.0148,  0.0070,\n",
       "          0.0054,  0.0089, -0.0287, -0.0140, -0.0269,  0.0319, -0.0325, -0.0247]),\n",
       " 'linear.weight': tensor([[ 0.0916,  0.0274,  0.0482, -0.0863,  0.0164, -0.0115, -0.0446,  0.1144,\n",
       "           0.0822,  0.0646,  0.0713,  0.0645,  0.0248,  0.0175,  0.0264,  0.0958,\n",
       "           0.1223,  0.0784, -0.0136,  0.1037,  0.0573,  0.0770, -0.0095, -0.0206,\n",
       "           0.1065,  0.0468,  0.0714,  0.1024,  0.0972, -0.0708, -0.0112,  0.0418,\n",
       "          -0.0384, -0.1069, -0.0260, -0.1035,  0.0921, -0.0480, -0.0806, -0.0412,\n",
       "           0.1044, -0.1037,  0.0918,  0.1132, -0.0616,  0.0739,  0.0543,  0.0419,\n",
       "          -0.1071,  0.0925, -0.0029, -0.0504, -0.1013, -0.1048, -0.1139,  0.0840,\n",
       "           0.0123, -0.0573,  0.0097,  0.1013,  0.0002,  0.0757, -0.1092, -0.0977],\n",
       "         [-0.0976,  0.0218,  0.1236, -0.0156, -0.0988, -0.0866,  0.0803,  0.0230,\n",
       "          -0.0454, -0.0290,  0.1180, -0.1043, -0.1040, -0.0692, -0.0319,  0.0671,\n",
       "           0.0057,  0.0187,  0.1229,  0.0675,  0.0289, -0.0853,  0.0172,  0.0875,\n",
       "          -0.0131, -0.0520, -0.0023, -0.0837, -0.1215,  0.0070,  0.0172, -0.0861,\n",
       "           0.0510,  0.1128,  0.0698, -0.0959,  0.1047, -0.0330,  0.0005,  0.0720,\n",
       "           0.0032, -0.0150, -0.0510, -0.0521,  0.1005,  0.0592, -0.1216, -0.1142,\n",
       "           0.1248,  0.0489, -0.0867, -0.0501, -0.0520,  0.0541, -0.0905,  0.0906,\n",
       "           0.0294,  0.0876,  0.0433, -0.0863,  0.0969, -0.0604, -0.1024, -0.0643],\n",
       "         [ 0.1154, -0.1186, -0.0199, -0.0405, -0.1105,  0.0765,  0.0550, -0.0141,\n",
       "          -0.1237, -0.0296, -0.0304,  0.1103, -0.1205,  0.0008,  0.0556,  0.0408,\n",
       "           0.0326, -0.0969,  0.1037, -0.0864, -0.0293, -0.0055, -0.0150,  0.0192,\n",
       "          -0.0729, -0.0636,  0.0296, -0.0577, -0.0287, -0.0820, -0.0236,  0.0443,\n",
       "          -0.0256, -0.0003, -0.0927, -0.0993,  0.0258,  0.1160, -0.0434, -0.0916,\n",
       "          -0.0447, -0.0580,  0.0066,  0.0233,  0.1130, -0.1072, -0.0153, -0.0757,\n",
       "          -0.1002, -0.0961,  0.0014, -0.0149, -0.1029,  0.1006, -0.0517,  0.0877,\n",
       "          -0.0534, -0.0673,  0.0225,  0.0355,  0.1090, -0.1145,  0.1039, -0.0724],\n",
       "         [ 0.0105, -0.0863,  0.0174,  0.0673, -0.0783, -0.0996,  0.0594, -0.0393,\n",
       "          -0.0898,  0.0047, -0.1083,  0.0007,  0.0800, -0.1056,  0.0060, -0.1029,\n",
       "           0.0600,  0.0489, -0.0016,  0.0796,  0.0368, -0.0254, -0.1187, -0.0487,\n",
       "          -0.0344, -0.0922, -0.0645, -0.0865,  0.0391,  0.0313,  0.0412,  0.1113,\n",
       "          -0.1223, -0.0501, -0.0932, -0.1201,  0.0443,  0.0366, -0.0723,  0.0465,\n",
       "           0.0954,  0.0633,  0.0466, -0.0724, -0.0795, -0.0819, -0.1092,  0.0291,\n",
       "           0.0500,  0.0143, -0.0998, -0.0054,  0.1042,  0.0176, -0.0459,  0.0192,\n",
       "           0.0816, -0.0294, -0.0316, -0.0542,  0.0943, -0.0240,  0.0372, -0.0403],\n",
       "         [-0.0505, -0.0937, -0.1059,  0.0898,  0.1196, -0.1027,  0.0251,  0.0276,\n",
       "          -0.0344,  0.0518, -0.0177,  0.1089,  0.0241,  0.0386, -0.0508,  0.0748,\n",
       "          -0.0992,  0.0156,  0.0612, -0.1040, -0.0413,  0.0628,  0.0228, -0.1098,\n",
       "           0.1152,  0.0852, -0.0362,  0.0163,  0.0398,  0.0036,  0.1198,  0.0906,\n",
       "           0.0250,  0.1074,  0.0016, -0.1161, -0.1173, -0.0486, -0.0867,  0.1088,\n",
       "          -0.0890,  0.0498,  0.0614, -0.1214, -0.0523,  0.0367, -0.0253,  0.0643,\n",
       "          -0.0216,  0.0619,  0.0555,  0.1103, -0.0463, -0.1167, -0.0215, -0.0346,\n",
       "          -0.0006, -0.0089, -0.0418,  0.0205,  0.0769, -0.0936,  0.0747, -0.0514],\n",
       "         [-0.1041, -0.0652, -0.1099, -0.1172, -0.1183,  0.0261, -0.0061, -0.0181,\n",
       "           0.0306,  0.1034,  0.1023, -0.0415, -0.0590,  0.1013, -0.0350, -0.1135,\n",
       "           0.1211,  0.0423,  0.0534, -0.0943,  0.0192, -0.1066,  0.0101, -0.0907,\n",
       "          -0.0641, -0.0925,  0.0244,  0.0263,  0.0090, -0.0468,  0.0813,  0.0006,\n",
       "           0.0742,  0.0435,  0.0780, -0.0913,  0.0158, -0.1105, -0.0535, -0.0402,\n",
       "          -0.0937,  0.0195,  0.0634, -0.0159,  0.1228, -0.0416,  0.0739,  0.0429,\n",
       "           0.0029, -0.0882, -0.0594, -0.0101,  0.0290, -0.0891,  0.0971, -0.0061,\n",
       "          -0.0823, -0.0365,  0.0256, -0.1039,  0.1206,  0.1249,  0.1118, -0.0718]]),\n",
       " 'linear.bias': tensor([ 0.0939, -0.0072, -0.0662,  0.0920, -0.0422,  0.0693])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cda6ca-2600-4980-8650-70de73a18e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c19ccbf5-7109-4406-9df0-37e580288c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of CNN(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f16f7b09-78c9-4093-8968-54580535e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd ={\n",
    "            name: torch.zeros_like(param, requires_grad=False)\n",
    "            for name, param in network.named_parameters()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dcb3064-f071-4872-998e-81745c82fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layer0.0.weight', 'layer0.0.bias', 'layer0.1.weight', 'layer0.1.bias', 'layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer2.0.weight', 'layer2.0.bias', 'layer2.1.weight', 'layer2.1.bias', 'layer3.0.weight', 'layer3.0.bias', 'layer3.1.weight', 'layer3.1.bias', 'layer4.0.weight', 'layer4.0.bias', 'layer4.1.weight', 'layer4.1.bias', 'layer5.0.weight', 'layer5.0.bias', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b55f5187-ea9e-42dc-9dad-f6158273d624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of CNN(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bcd1231-7d65-4664-8598-98d973b58146",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: 23, 3:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b7abd70-7835-4476-b472-475420760140",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = {1:32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab87d681-d311-418b-8457-617e194c5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.update(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8f4a1de-1b43-4c4a-bb49-7ef2441d554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 32, 3: 4}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "764db03d-a1cb-4989-92ba-732f0b0ba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.state_dict().update(current_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1b690-356c-4de3-ad27-dc5133145037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b5e1a-337f-4e7b-9b22-75cd64b3b505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcbaec38-b73f-48fb-bf46-e0ca16b6ac9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m----> 2\u001b[0m net\u001b[38;5;241m.\u001b[39mupdate(\u001b[43msampled_param\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mload_state_dict(net)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_batchnorm()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sampled_param' is not defined"
     ]
    }
   ],
   "source": [
    "net = network.state_dict()\n",
    "net.update(sampled_param)\n",
    "self.network.load_state_dict(net)\n",
    "self._update_batchnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e228735-b6a0-4c4e-80a5-fa50da0d2160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41eaa50-161f-4e0e-bdd7-236b2e7681b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ecf8f4c-a757-4703-83f7-f2f7b06512a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 5, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31625156-5d19-4f81-82ac-a51978657b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = collections.deque()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fb7f41f-dbc0-4938-8e06-95cc38ced94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0ce5be8-0cd8-40b8-b446-4cce6381d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(K):\n",
    "    D.append(_create_weight_copy(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24166383-0684-4e53-a62d-2b87c191a117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4db332c-72b0-4be5-8365-e861a96b7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b5206ff-c719-4b9a-af5e-bda07c04ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_i in D:\n",
    "    dv.append(D_i[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69b2270b-4874-4250-a342-28aa6eadd7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 5, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d2731ef-14e9-411b-aa5c-77a3fbffa1fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718be63c-25eb-4ba2-9e6c-615c9c456180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6644e0b9-6a79-4a70-825d-383b00b9d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceMode(enum.Enum):\n",
    "    \"\"\"\n",
    "    Inference mode switch for your implementation.\n",
    "    `MAP` simply predicts the most likely class using pretrained MAP weights.\n",
    "    `SWAG_DIAGONAL` and `SWAG_FULL` correspond to SWAG-diagonal and the full SWAG method, respectively.\n",
    "    \"\"\"\n",
    "    MAP = 0\n",
    "    SWAG_DIAGONAL = 1\n",
    "    SWAG_FULL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6892e47-141e-4f6e-909a-789dc2600856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf53d3-9bc8-44a3-acbd-fa1565df6e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7629ca91-fe5d-4879-8e45-3d9eff304a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWAGInference(object):\n",
    "    \"\"\"\n",
    "    Your implementation of SWA-Gaussian.\n",
    "    This class is used to run and evaluate your solution.\n",
    "    You must preserve all methods and signatures of this class.\n",
    "    However, you can add new methods if you want.\n",
    "\n",
    "    We provide basic functionality and some helper methods.\n",
    "    You can pass all baselines by only modifying methods marked with TODO.\n",
    "    However, we encourage you to skim other methods in order to gain a better understanding of SWAG.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_xs: torch.Tensor,\n",
    "        model_dir: pathlib.Path,\n",
    "        # TODO(1): change inference_mode to InferenceMode.SWAG_DIAGONAL\n",
    "        # TODO(2): change inference_mode to InferenceMode.SWAG_FULL\n",
    "        inference_mode: InferenceMode = InferenceMode.SWAG_DIAGONAL, # InferenceMode.MAP,\n",
    "        # TODO(2): optionally add/tweak hyperparameters\n",
    "        swag_epochs: int = 30,\n",
    "        swag_learning_rate: float = 0.045,\n",
    "        swag_update_freq: int = 1,\n",
    "        deviation_matrix_max_rank: int = 15,\n",
    "        bma_samples: int = 30,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param train_xs: Training images (for storage only)\n",
    "        :param model_dir: Path to directory containing pretrained MAP weights\n",
    "        :param inference_mode: Control which inference mode (MAP, SWAG-diagonal, full SWAG) to use\n",
    "        :param swag_epochs: Total number of gradient descent epochs for SWAG\n",
    "        :param swag_learning_rate: Learning rate for SWAG gradient descent\n",
    "        :param swag_update_freq: Frequency (in epochs) for updating SWAG statistics during gradient descent\n",
    "        :param deviation_matrix_max_rank: Rank of deviation matrix for full SWAG\n",
    "        :param bma_samples: Number of networks to sample for Bayesian model averaging during prediction\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dir = model_dir\n",
    "        self.inference_mode = inference_mode\n",
    "        self.swag_epochs = swag_epochs\n",
    "        self.swag_learning_rate = swag_learning_rate\n",
    "        self.swag_update_freq = swag_update_freq\n",
    "        self.deviation_matrix_max_rank = deviation_matrix_max_rank\n",
    "        self.bma_samples = bma_samples\n",
    "\n",
    "        # Network used to perform SWAG.\n",
    "        # Note that all operations in this class modify this network IN-PLACE!\n",
    "        self.network = CNN(in_channels=3, out_classes=6)\n",
    "\n",
    "        # Store training dataset to recalculate batch normalization statistics during SWAG inference\n",
    "        self.train_dataset = torch.utils.data.TensorDataset(train_xs)\n",
    "\n",
    "        # SWAG-diagonal\n",
    "        # TODO(1): create attributes for SWAG-diagonal\n",
    "        #  Hint: self._create_weight_copy() creates an all-zero copy of the weights\n",
    "        #  as a dictionary that maps from weight name to values.\n",
    "        #  Hint: you never need to consider the full vector of weights,\n",
    "        #  but can always act on per-layer weights (in the format that _create_weight_copy() returns)\n",
    "        self.w_swa = self._create_weight_copy()\n",
    "        self.w2_swa = self._create_weight_copy()\n",
    "        self.n = 0\n",
    "\n",
    "        # Full SWAG\n",
    "        # TODO(2): create attributes for SWAG-diagonal\n",
    "        #  Hint: check collections.deque\n",
    "\n",
    "        # Calibration, prediction, and other attributes\n",
    "        # TODO(2): create additional attributes, e.g., for calibration\n",
    "        self._prediction_threshold = None  # this is an example, feel free to be creative\n",
    "\n",
    "    def update_swag(self) -> None:\n",
    "        \"\"\"\n",
    "        Update SWAG statistics with the current weights of self.network.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a copy of the current network weights\n",
    "        current_params = {name: param.detach() for name, param in self.network.named_parameters()}\n",
    "\n",
    "        # SWAG-diagonal\n",
    "        for name, param in current_params.items():\n",
    "            # TODO(1): update SWAG-diagonal attributes for weight `name` using `current_params` and `param`\n",
    "            self.w_swa[name] = (self.n * self.w_swa[name] + param)/(self.n + 1)\n",
    "            self.w2_swa[name] = (self.n * self.w2_swa[name] + param*param)/(self.n + 1)\n",
    "            # raise NotImplementedError(\"Update SWAG-diagonal statistics\")\n",
    "\n",
    "        # Full SWAG\n",
    "        if self.inference_mode == InferenceMode.SWAG_FULL:\n",
    "            # TODO(2): update full SWAG attributes for weight `name` using `current_params` and `param`\n",
    "            raise NotImplementedError(\"Update full SWAG statistics\")\n",
    "\n",
    "    def fit_swag(self, loader: torch.utils.data.DataLoader) -> None:\n",
    "        \"\"\"\n",
    "        Fit SWAG on top of the pretrained network self.network.\n",
    "        This method should perform gradient descent with occasional SWAG updates\n",
    "        by calling self.update_swag().\n",
    "        \"\"\"\n",
    "\n",
    "        # We use SGD with momentum and weight decay to perform SWA.\n",
    "        # See the paper on how weight decay corresponds to a type of prior.\n",
    "        # Feel free to play around with optimization hyperparameters.\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.network.parameters(),\n",
    "            lr=self.swag_learning_rate,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=1e-4,\n",
    "        )\n",
    "        loss = torch.nn.CrossEntropyLoss(\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        # TODO(2): Update SWAGScheduler instantiation if you decided to implement a custom schedule.\n",
    "        #  By default, this scheduler just keeps the initial learning rate given to `optimizer`.\n",
    "        lr_scheduler = SWAGScheduler(\n",
    "            optimizer,\n",
    "            epochs=self.swag_epochs,\n",
    "            steps_per_epoch=len(loader),\n",
    "        )\n",
    "\n",
    "        # TODO(1): Perform initialization for SWAG fitting\n",
    "        self.update_swag()\n",
    "        # raise NotImplementedError(\"Initialize SWAG fitting\")\n",
    "\n",
    "        self.network.train()\n",
    "        with tqdm.trange(self.swag_epochs, desc=\"Running gradient descent for SWA\") as pbar:\n",
    "            pbar_dict = {}\n",
    "            for epoch in pbar:\n",
    "                average_loss = 0.0\n",
    "                average_accuracy = 0.0\n",
    "                num_samples_processed = 0\n",
    "                for batch_xs, batch_is_snow, batch_is_cloud, batch_ys in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred_ys = self.network(batch_xs)\n",
    "                    batch_loss = loss(input=pred_ys, target=batch_ys)\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    pbar_dict[\"lr\"] = lr_scheduler.get_last_lr()[0]\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "                    # Calculate cumulative average training loss and accuracy\n",
    "                    average_loss = (batch_xs.size(0) * batch_loss.item() + num_samples_processed * average_loss) / (\n",
    "                        num_samples_processed + batch_xs.size(0)\n",
    "                    )\n",
    "                    average_accuracy = (\n",
    "                        torch.sum(pred_ys.argmax(dim=-1) == batch_ys).item()\n",
    "                        + num_samples_processed * average_accuracy\n",
    "                    ) / (num_samples_processed + batch_xs.size(0))\n",
    "                    num_samples_processed += batch_xs.size(0)\n",
    "                    pbar_dict[\"avg. epoch loss\"] = average_loss\n",
    "                    pbar_dict[\"avg. epoch accuracy\"] = average_accuracy\n",
    "                    pbar.set_postfix(pbar_dict)\n",
    "\n",
    "                # TODO(1): Implement periodic SWAG updates using the attributes defined in __init__\n",
    "                if epoch % self.swag_update_freq == 0:\n",
    "                    self.n = epoch/self.swag_update_freq\n",
    "                    self.update_swag()\n",
    "                # raise NotImplementedError(\"Periodically update SWAG statistics\")\n",
    "\n",
    "    def calibrate(self, validation_data: torch.utils.data.Dataset) -> None:\n",
    "        \"\"\"\n",
    "        Calibrate your predictions using a small validation set.\n",
    "        validation_data contains well-defined and ambiguous samples,\n",
    "        where you can identify the latter by having label -1.\n",
    "        \"\"\"\n",
    "        if self.inference_mode == InferenceMode.MAP:\n",
    "            # In MAP mode, simply predict argmax and do nothing else\n",
    "            self._prediction_threshold = 0.0\n",
    "            return\n",
    "\n",
    "        # TODO(1): pick a prediction threshold, either constant or adaptive.\n",
    "        #  The provided value should suffice to pass the easy baseline.\n",
    "        self._prediction_threshold = 2.0 / 3.0\n",
    "\n",
    "        # TODO(2): perform additional calibration if desired.\n",
    "        #  Feel free to remove or change the prediction threshold.\n",
    "        val_xs, val_is_snow, val_is_cloud, val_ys = validation_data.tensors\n",
    "        assert val_xs.size() == (140, 3, 60, 60)  # N x C x H x W\n",
    "        assert val_ys.size() == (140,)\n",
    "        assert val_is_snow.size() == (140,)\n",
    "        assert val_is_cloud.size() == (140,)\n",
    "\n",
    "    def predict_probabilities_swag(self, loader: torch.utils.data.DataLoader) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform Bayesian model averaging using your SWAG statistics and predict\n",
    "        probabilities for all samples in the loader.\n",
    "        Outputs should be a Nx6 tensor, where N is the number of samples in loader,\n",
    "        and all rows of the output should sum to 1.\n",
    "        That is, output row i column j should be your predicted p(y=j | x_i).\n",
    "        \"\"\"\n",
    "\n",
    "        self.network.eval()\n",
    "\n",
    "        # Perform Bayesian model averaging:\n",
    "        # Instead of sampling self.bma_samples networks (using self.sample_parameters())\n",
    "        # for each datapoint, you can save time by sampling self.bma_samples networks,\n",
    "        # and perform inference with each network on all samples in loader.\n",
    "        per_model_sample_predictions = []\n",
    "        for _ in tqdm.trange(self.bma_samples, desc=\"Performing Bayesian model averaging\"):\n",
    "            # TODO(1): Sample new parameters for self.network from the SWAG approximate posterior\n",
    "            self.sample_parameters()\n",
    "            # raise NotImplementedError(\"Sample network parameters\")\n",
    "\n",
    "            # TODO(1): Perform inference for all samples in `loader` using current model sample,\n",
    "            #  and add the predictions to per_model_sample_predictions\n",
    "            predictions = []\n",
    "            for (batch_xs,) in loader:\n",
    "                predictions.append(self.network(batch_xs))\n",
    "            \n",
    "            predictions = torch.cat(predictions)\n",
    "            \n",
    "            per_model_sample_predictions.append(predictions.unsqueeze(0))\n",
    "            # raise NotImplementedError(\"Perform inference using current model\")\n",
    "\n",
    "        assert len(per_model_sample_predictions) == self.bma_samples\n",
    "        assert all(\n",
    "            isinstance(model_sample_predictions, torch.Tensor)\n",
    "            and model_sample_predictions.dim() == 2  # N x C\n",
    "            and model_sample_predictions.size(1) == 6\n",
    "            for model_sample_predictions in per_model_sample_predictions\n",
    "        )\n",
    "\n",
    "        # TODO(1): Average predictions from different model samples into bma_probabilities\n",
    "        # raise NotImplementedError(\"Aggregate predictions from model samples\")\n",
    "        bma_logits = torch.cat(per_model_sample_predictions, 0)\n",
    "        bma_logits = torch.mean(bma_logits, 0)\n",
    "        bma_probabilities = torch.softmax(bma_logits, dim=-1)\n",
    "\n",
    "        assert bma_probabilities.dim() == 2 and bma_probabilities.size(1) == 6  # N x C\n",
    "        return bma_probabilities\n",
    "\n",
    "    def sample_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        Sample a new network from the approximate SWAG posterior.\n",
    "        For simplicity, this method directly modifies self.network in-place.\n",
    "        Hence, after calling this method, self.network corresponds to a new posterior sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # Instead of acting on a full vector of parameters, all operations can be done on per-layer parameters.\n",
    "        net = self.network.state_dict()\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            # SWAG-diagonal part\n",
    "            z_1 = torch.randn(param.size())\n",
    "            # TODO(1): Sample parameter values for SWAG-diagonal\n",
    "            # raise NotImplementedError(\"Sample parameter for SWAG-diagonal\")\n",
    "            \n",
    "            current_mean = self.w_swa[name]\n",
    "            current_std = torch.sqrt(self.w2_swa[name] - self.w_swa[name]**2)\n",
    "            \n",
    "            assert current_mean.size() == param.size() and current_std.size() == param.size()\n",
    "\n",
    "            # Diagonal part\n",
    "            sampled_param = current_mean + current_std * z_1\n",
    "\n",
    "            # Full SWAG part\n",
    "            if self.inference_mode == InferenceMode.SWAG_FULL:\n",
    "                # TODO(2): Sample parameter values for full SWAG\n",
    "                raise NotImplementedError(\"Sample parameter for full SWAG\")\n",
    "                sampled_param += ...\n",
    "\n",
    "            # Modify weight value in-place; directly changing self.network\n",
    "            param.data = sampled_param\n",
    "\n",
    "            net[name] = sampled_param\n",
    "\n",
    "        # TODO(1): Don't forget to update batch normalization statistics using self._update_batchnorm()\n",
    "        #  in the appropriate place!\n",
    "        self.network.load_state_dict(net)\n",
    "        self._update_batchnorm()\n",
    "\n",
    "        # raise NotImplementedError(\"Update batch normalization statistics for newly sampled network\")\n",
    "\n",
    "    def predict_labels(self, predicted_probabilities: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict labels in {0, 1, 2, 3, 4, 5} or \"don't know\" as -1\n",
    "        based on your model's predicted probabilities.\n",
    "        The parameter predicted_probabilities is an Nx6 tensor containing predicted probabilities\n",
    "        as returned by predict_probabilities(...).\n",
    "        The output should be a N-dimensional long tensor, containing values in {-1, 0, 1, 2, 3, 4, 5}.\n",
    "        \"\"\"\n",
    "\n",
    "        # label_probabilities contains the per-row maximum values in predicted_probabilities,\n",
    "        # max_likelihood_labels the corresponding column index (equivalent to class).\n",
    "        label_probabilities, max_likelihood_labels = torch.max(predicted_probabilities, dim=-1)\n",
    "        num_samples, num_classes = predicted_probabilities.size()\n",
    "        assert label_probabilities.size() == (num_samples,) and max_likelihood_labels.size() == (num_samples,)\n",
    "\n",
    "        # A model without uncertainty awareness might simply predict the most likely label per sample:\n",
    "        # return max_likelihood_labels\n",
    "\n",
    "        # A bit better: use a threshold to decide whether to return a label or \"don't know\" (label -1)\n",
    "        # TODO(2): implement a different decision rule if desired\n",
    "        return torch.where(\n",
    "            label_probabilities >= self._prediction_threshold,\n",
    "            max_likelihood_labels,\n",
    "            torch.ones_like(max_likelihood_labels) * -1,\n",
    "        )\n",
    "\n",
    "    def _create_weight_copy(self) -> typing.Dict[str, torch.Tensor]:\n",
    "        \"\"\"Create an all-zero copy of the network weights as a dictionary that maps name -> weight\"\"\"\n",
    "        return {\n",
    "            name: torch.zeros_like(param, requires_grad=False)\n",
    "            for name, param in self.network.named_parameters()\n",
    "        }\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        loader: torch.utils.data.DataLoader,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Perform full SWAG fitting procedure.\n",
    "        If `PRETRAINED_WEIGHTS_FILE` is `True`, this method skips the MAP inference part,\n",
    "        and uses pretrained weights instead.\n",
    "\n",
    "        Note that MAP inference can take a very long time.\n",
    "        You should hence only perform MAP inference yourself after passing the hard baseline\n",
    "        using the given CNN architecture and pretrained weights.\n",
    "        \"\"\"\n",
    "\n",
    "        # MAP inference to obtain initial weights\n",
    "        PRETRAINED_WEIGHTS_FILE = self.model_dir / \"map_weights.pt\"\n",
    "        if USE_PRETRAINED_INIT:\n",
    "            self.network.load_state_dict(torch.load(PRETRAINED_WEIGHTS_FILE))\n",
    "            print(\"Loaded pretrained MAP weights from\", PRETRAINED_WEIGHTS_FILE)\n",
    "        else:\n",
    "            self.fit_map(loader)\n",
    "\n",
    "        # SWAG\n",
    "        if self.inference_mode in (InferenceMode.SWAG_DIAGONAL, InferenceMode.SWAG_FULL):\n",
    "            self.fit_swag(loader)\n",
    "\n",
    "    def fit_map(self, loader: torch.utils.data.DataLoader) -> None:\n",
    "        \"\"\"\n",
    "        MAP inference procedure to obtain initial weights of self.network.\n",
    "        This is the exact procedure that was used to obtain the pretrained weights we provide.\n",
    "        \"\"\"\n",
    "        map_epochs = 140\n",
    "        initial_lr = 0.01\n",
    "        decayed_lr = 0.0001\n",
    "        decay_start_epoch = 50\n",
    "        decay_factor = decayed_lr / initial_lr\n",
    "\n",
    "        # Create optimizer, loss, and a learning rate scheduler that aids convergence\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.network.parameters(),\n",
    "            lr=initial_lr,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=1e-4,\n",
    "        )\n",
    "        loss = torch.nn.CrossEntropyLoss(\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "            optimizer,\n",
    "            [\n",
    "                torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0),\n",
    "                torch.optim.lr_scheduler.LinearLR(\n",
    "                    optimizer,\n",
    "                    start_factor=1.0,\n",
    "                    end_factor=decay_factor,\n",
    "                    total_iters=(map_epochs - decay_start_epoch) * len(loader),\n",
    "                ),\n",
    "            ],\n",
    "            milestones=[decay_start_epoch * len(loader)],\n",
    "        )\n",
    "\n",
    "        # Put network into training mode\n",
    "        # Batch normalization layers are only updated if the network is in training mode,\n",
    "        # and are replaced by a moving average if the network is in evaluation mode.\n",
    "        self.network.train()\n",
    "        with tqdm.trange(map_epochs, desc=\"Fitting initial MAP weights\") as pbar:\n",
    "            pbar_dict = {}\n",
    "            # Perform the specified number of MAP epochs\n",
    "            for epoch in pbar:\n",
    "                average_loss = 0.0\n",
    "                average_accuracy = 0.0\n",
    "                num_samples_processed = 0\n",
    "                # Iterate over batches of randomly shuffled training data\n",
    "                for batch_xs, _, _, batch_ys in loader:\n",
    "                    # Training step\n",
    "                    optimizer.zero_grad()\n",
    "                    pred_ys = self.network(batch_xs)\n",
    "                    batch_loss = loss(input=pred_ys, target=batch_ys)\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Save learning rate that was used for step, and calculate new one\n",
    "                    pbar_dict[\"lr\"] = lr_scheduler.get_last_lr()[0]\n",
    "                    with warnings.catch_warnings():\n",
    "                        # Suppress annoying warning (that we cannot control) inside PyTorch\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        lr_scheduler.step()\n",
    "\n",
    "                    # Calculate cumulative average training loss and accuracy\n",
    "                    average_loss = (batch_xs.size(0) * batch_loss.item() + num_samples_processed * average_loss) / (\n",
    "                        num_samples_processed + batch_xs.size(0)\n",
    "                    )\n",
    "                    average_accuracy = (\n",
    "                        torch.sum(pred_ys.argmax(dim=-1) == batch_ys).item()\n",
    "                        + num_samples_processed * average_accuracy\n",
    "                    ) / (num_samples_processed + batch_xs.size(0))\n",
    "                    num_samples_processed += batch_xs.size(0)\n",
    "\n",
    "                    pbar_dict[\"avg. epoch loss\"] = average_loss\n",
    "                    pbar_dict[\"avg. epoch accuracy\"] = average_accuracy\n",
    "                    pbar.set_postfix(pbar_dict)\n",
    "\n",
    "    def predict_probabilities(self, xs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict class probabilities for the given images xs.\n",
    "        This method returns an NxC float tensor,\n",
    "        where row i column j corresponds to the probability that y_i is class j.\n",
    "\n",
    "        This method uses different strategies depending on self.inference_mode.\n",
    "        \"\"\"\n",
    "        self.network = self.network.eval()\n",
    "\n",
    "        # Create a loader that we can deterministically iterate many times if necessary\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(xs),\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():  # save memory by not tracking gradients\n",
    "            if self.inference_mode == InferenceMode.MAP:\n",
    "                return self.predict_probabilities_map(loader)\n",
    "            else:\n",
    "                return self.predict_probabilities_swag(loader)\n",
    "\n",
    "    def predict_probabilities_map(self, loader: torch.utils.data.DataLoader) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict probabilities assuming that self.network is a MAP estimate.\n",
    "        This simply performs a forward pass for every batch in `loader`,\n",
    "        concatenates all results, and applies a row-wise softmax.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for (batch_xs,) in loader:\n",
    "            predictions.append(self.network(batch_xs))\n",
    "\n",
    "        predictions = torch.cat(predictions)\n",
    "        return torch.softmax(predictions, dim=-1)\n",
    "\n",
    "    def _update_batchnorm(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset and fit batch normalization statistics using the training dataset self.train_dataset.\n",
    "        We provide this method for you for convenience.\n",
    "        See the SWAG paper for why this is required.\n",
    "\n",
    "        Batch normalization usually uses an exponential moving average, controlled by the `momentum` parameter.\n",
    "        However, we are not training but want the statistics for the full training dataset.\n",
    "        Hence, setting `momentum` to `None` tracks a cumulative average instead.\n",
    "        The following code stores original `momentum` values, sets all to `None`,\n",
    "        and restores the previous hyperparameters after updating batchnorm statistics.\n",
    "        \"\"\"\n",
    "\n",
    "        old_momentum_parameters = dict()\n",
    "        for module in self.network.modules():\n",
    "            # Only need to handle batchnorm modules\n",
    "            if not isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "                continue\n",
    "\n",
    "            # Store old momentum value before removing it\n",
    "            old_momentum_parameters[module] = module.momentum\n",
    "            module.momentum = None\n",
    "\n",
    "            # Reset batch normalization statistics\n",
    "            module.reset_running_stats()\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        self.network.train()\n",
    "        for (batch_xs,) in loader:\n",
    "            self.network(batch_xs)\n",
    "        self.network.eval()\n",
    "\n",
    "        # Restore old `momentum` hyperparameter values\n",
    "        for module, momentum in old_momentum_parameters.items():\n",
    "            module.momentum = momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fe40a-0698-4f1a-a2a4-c4969430200e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccebbaf-47b1-4bf7-b640-8f32b998a491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77b6aa-6f31-4ebc-a756-6ffe1f7752c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0b1d2-6408-4674-9baa-8202dfcb7ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bcfcb-a940-4394-961d-eea5958c81f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d24952e0-a851-4c93-aa19-226404112d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWAGScheduler(torch.optim.lr_scheduler.LRScheduler):\n",
    "    \"\"\"\n",
    "    Custom learning rate scheduler that calculates a different learning rate each gradient descent step.\n",
    "    The default implementation keeps the original learning rate constant, i.e., does nothing.\n",
    "    You can implement a custom schedule inside calculate_lr,\n",
    "    and add+store additional attributes in __init__.\n",
    "    You should not change any other parts of this class.\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_lr(self, current_epoch: float, old_lr: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the learning rate for the epoch given by current_epoch.\n",
    "        current_epoch is the fractional epoch of SWA fitting, starting at 0.\n",
    "        That is, an integer value x indicates the start of epoch (x+1),\n",
    "        and non-integer values x.y correspond to steps in between epochs (x+1) and (x+2).\n",
    "        old_lr is the previous learning rate.\n",
    "\n",
    "        This method should return a single float: the new learning rate.\n",
    "        \"\"\"\n",
    "        # TODO(2): Implement a custom schedule if desired\n",
    "        return old_lr\n",
    "\n",
    "    # TODO(2): Add and store additional arguments if you decide to implement a custom scheduler\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        epochs: int,\n",
    "        steps_per_epoch: int,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        super().__init__(optimizer, last_epoch=-1, verbose=False)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\n",
    "                \"To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\", UserWarning\n",
    "            )\n",
    "        return [\n",
    "            self.calculate_lr(self.last_epoch / self.steps_per_epoch, group[\"lr\"])\n",
    "            for group in self.optimizer.param_groups\n",
    "        ]\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    swag: SWAGInference,\n",
    "    eval_dataset: torch.utils.data.Dataset,\n",
    "    extended_evaluation: bool,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Evaluate your model.\n",
    "    Feel free to change or extend this code.\n",
    "    :param swag: Trained model to evaluate\n",
    "    :param eval_dataset: Validation dataset\n",
    "    :param: extended_evaluation: If True, generates additional plots\n",
    "    :param output_dir: Directory into which extended evaluation plots are saved\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Evaluating model on validation data\")\n",
    "\n",
    "    # We ignore is_snow and is_cloud here, but feel free to use them as well\n",
    "    xs, is_snow, is_cloud, ys = eval_dataset.tensors\n",
    "\n",
    "    # Predict class probabilities on test data,\n",
    "    # most likely classes (according to the max predicted probability),\n",
    "    # and classes as predicted by your SWAG implementation.\n",
    "    pred_prob_all = swag.predict_probabilities(xs)\n",
    "    pred_prob_max, pred_ys_argmax = torch.max(pred_prob_all, dim=-1)\n",
    "    pred_ys = swag.predict_labels(pred_prob_all)\n",
    "\n",
    "    # Create a mask that ignores ambiguous samples (those with class -1)\n",
    "    nonambiguous_mask = ys != -1\n",
    "\n",
    "    # Calculate three kinds of accuracy:\n",
    "    # 1. Overall accuracy, counting \"don't know\" (-1) as its own class\n",
    "    # 2. Accuracy on all samples that have a known label. Predicting -1 on those counts as wrong here.\n",
    "    # 3. Accuracy on all samples that have a known label w.r.t. the class with the highest predicted probability.\n",
    "    accuracy = torch.mean((pred_ys == ys).float()).item()\n",
    "    accuracy_nonambiguous = torch.mean((pred_ys[nonambiguous_mask] == ys[nonambiguous_mask]).float()).item()\n",
    "    accuracy_nonambiguous_argmax = torch.mean(\n",
    "        (pred_ys_argmax[nonambiguous_mask] == ys[nonambiguous_mask]).float()\n",
    "    ).item()\n",
    "    print(f\"Accuracy (raw): {accuracy:.4f}\")\n",
    "    print(f\"Accuracy (non-ambiguous only, your predictions): {accuracy_nonambiguous:.4f}\")\n",
    "    print(f\"Accuracy (non-ambiguous only, predicting most-likely class): {accuracy_nonambiguous_argmax:.4f}\")\n",
    "\n",
    "    # Determine which threshold would yield the smallest cost on the validation data\n",
    "    # Note that this threshold does not necessarily generalize to the test set!\n",
    "    # However, it can help you judge your method's calibration.\n",
    "    thresholds = [0.0] + list(torch.unique(pred_prob_max, sorted=True))\n",
    "    costs = []\n",
    "    for threshold in thresholds:\n",
    "        thresholded_ys = torch.where(pred_prob_max <= threshold, -1 * torch.ones_like(pred_ys), pred_ys)\n",
    "        costs.append(cost_function(thresholded_ys, ys).item())\n",
    "    best_idx = np.argmin(costs)\n",
    "    print(f\"Best cost {costs[best_idx]} at threshold {thresholds[best_idx]}\")\n",
    "    print(\"Note that this threshold does not necessarily generalize to the test set!\")\n",
    "\n",
    "    # Calculate ECE and plot the calibration curve\n",
    "    calibration_data = calc_calibration_curve(pred_prob_all.numpy(), ys.numpy(), num_bins=20)\n",
    "    print(\"Validation ECE:\", calibration_data[\"ece\"])\n",
    "\n",
    "    if extended_evaluation:\n",
    "        print(\"Plotting reliability diagram\")\n",
    "        fig = draw_reliability_diagram(calibration_data)\n",
    "        fig.savefig(output_dir / \"reliability_diagram.pdf\")\n",
    "\n",
    "        sorted_confidence_indices = torch.argsort(pred_prob_max)\n",
    "\n",
    "        # Plot samples your model is most confident about\n",
    "        print(\"Plotting most confident validation set predictions\")\n",
    "        most_confident_indices = sorted_confidence_indices[-10:]\n",
    "        fig, ax = plt.subplots(4, 5, figsize=(13, 11))\n",
    "        for row in range(0, 4, 2):\n",
    "            for col in range(5):\n",
    "                sample_idx = most_confident_indices[5 * row // 2 + col]\n",
    "                ax[row, col].imshow(xs[sample_idx].permute(1, 2, 0).numpy())\n",
    "                ax[row, col].set_axis_off()\n",
    "                ax[row + 1, col].set_title(f\"pred. {pred_ys[sample_idx]}, true {ys[sample_idx]}\")\n",
    "                bar_colors = [\"C0\"] * 6\n",
    "                if ys[sample_idx] >= 0:\n",
    "                    bar_colors[ys[sample_idx]] = \"C1\"\n",
    "                ax[row + 1, col].bar(\n",
    "                    np.arange(6), pred_prob_all[sample_idx].numpy(), tick_label=np.arange(6), color=bar_colors\n",
    "                )\n",
    "        fig.suptitle(\"Most confident predictions\", size=20)\n",
    "        fig.savefig(output_dir / \"examples_most_confident.pdf\")\n",
    "\n",
    "        # Plot samples your model is least confident about\n",
    "        print(\"Plotting least confident validation set predictions\")\n",
    "        least_confident_indices = sorted_confidence_indices[:10]\n",
    "        fig, ax = plt.subplots(4, 5, figsize=(13, 11))\n",
    "        for row in range(0, 4, 2):\n",
    "            for col in range(5):\n",
    "                sample_idx = least_confident_indices[5 * row // 2 + col]\n",
    "                ax[row, col].imshow(xs[sample_idx].permute(1, 2, 0).numpy())\n",
    "                ax[row, col].set_axis_off()\n",
    "                ax[row + 1, col].set_title(f\"pred. {pred_ys[sample_idx]}, true {ys[sample_idx]}\")\n",
    "                bar_colors = [\"C0\"] * 6\n",
    "                if ys[sample_idx] >= 0:\n",
    "                    bar_colors[ys[sample_idx]] = \"C1\"\n",
    "                ax[row + 1, col].bar(\n",
    "                    np.arange(6), pred_prob_all[sample_idx].numpy(), tick_label=np.arange(6), color=bar_colors\n",
    "                )\n",
    "        fig.suptitle(\"Least confident predictions\", size=20)\n",
    "        fig.savefig(output_dir / \"examples_least_confident.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f4cba-589b-4c0b-a57c-95f2f9d1eb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87029b-688f-4484-8c0f-6fc76b975dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4008c64c-b00f-4ae8-8cf0-ebbd7c6752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all randomness\n",
    "setup_seeds()\n",
    "\n",
    "# Build and run the actual solution\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "swag = SWAGInference(\n",
    "    train_xs=dataset_train.tensors[0],\n",
    "    model_dir=model_dir,\n",
    ")\n",
    "# swag.fit(train_loader)\n",
    "swag.calibrate(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900200b6-67c9-437d-90f5-4a56d2ef8e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb8fbd-6d0a-431d-8789-1f8d267b3746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b799281-ff92-42f0-9296-0451a1d40872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f9fc9c133d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05505902-6122-4a0e-9888-f62f0a41ae40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b77476a7-4ede-4b33-934a-c3c02526befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Bayesian model averaging: 100%|█████| 30/30 [03:18<00:00,  6.62s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfork_rng():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEXTENDED_EVALUATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 68\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(swag, eval_dataset, extended_evaluation, output_dir)\u001b[0m\n\u001b[1;32m     63\u001b[0m xs, is_snow, is_cloud, ys \u001b[38;5;241m=\u001b[39m eval_dataset\u001b[38;5;241m.\u001b[39mtensors\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Predict class probabilities on test data,\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# most likely classes (according to the max predicted probability),\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# and classes as predicted by your SWAG implementation.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m pred_prob_all \u001b[38;5;241m=\u001b[39m \u001b[43mswag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m pred_prob_max, pred_ys_argmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pred_prob_all, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     70\u001b[0m pred_ys \u001b[38;5;241m=\u001b[39m swag\u001b[38;5;241m.\u001b[39mpredict_labels(pred_prob_all)\n",
      "Cell \u001b[0;32mIn[80], line 431\u001b[0m, in \u001b[0;36mSWAGInference.predict_probabilities\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_probabilities_map(loader)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_probabilities_swag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[80], line 214\u001b[0m, in \u001b[0;36mSWAGInference.predict_probabilities_swag\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError(\"Perform inference using current model\")\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(per_model_sample_predictions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbma_samples\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(model_sample_predictions, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model_sample_predictions\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# N x C\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model_sample_predictions\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_sample_predictions \u001b[38;5;129;01min\u001b[39;00m per_model_sample_predictions\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# TODO(1): Average predictions from different model samples into bma_probabilities\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# raise NotImplementedError(\"Aggregate predictions from model samples\")\u001b[39;00m\n\u001b[1;32m    223\u001b[0m bma_logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(per_model_sample_predictions, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.random.fork_rng():\n",
    "    evaluate(swag, dataset_val, EXTENDED_EVALUATION, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef281437-ab95-4727-9a83-dd3cc16f665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f9fba5b2400>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969d6db-4ea5-426a-bf09-ea292ffdf0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "558c80f4-59ef-4fed-96e9-3bc99838a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    swag.train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4734fa4-f759-4a6d-85b1-682a525eb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "swag.bma_samples = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2adfb5e5-7848-4676-8a76-746af645807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Bayesian model averaging: 100%|███████| 2/2 [00:29<00:00, 14.80s/it]\n"
     ]
    }
   ],
   "source": [
    "swag.network.eval()\n",
    "\n",
    "# Perform Bayesian model averaging:\n",
    "# Instead of sampling self.bma_samples networks (using self.sample_parameters())\n",
    "# for each datapoint, you can save time by sampling self.bma_samples networks,\n",
    "# and perform inference with each network on all samples in loader.\n",
    "per_model_sample_predictions = []\n",
    "for _ in tqdm.trange(swag.bma_samples, desc=\"Performing Bayesian model averaging\"):\n",
    "    # TODO(1): Sample new parameters for self.network from the SWAG approximate posterior\n",
    "    swag.sample_parameters()\n",
    "    # raise NotImplementedError(\"Sample network parameters\")\n",
    "\n",
    "    # TODO(1): Perform inference for all samples in `loader` using current model sample,\n",
    "    #  and add the predictions to per_model_sample_predictions\n",
    "    predictions = []\n",
    "    for (batch_xs,) in loader:\n",
    "        predictions.append(swag.network(batch_xs))\n",
    "    \n",
    "    predictions = torch.cat(predictions)\n",
    "    \n",
    "    per_model_sample_predictions.append(predictions)\n",
    "    # raise NotImplementedError(\"Perform inference using current model\")\n",
    "\n",
    "assert len(per_model_sample_predictions) == swag.bma_samples\n",
    "assert all(\n",
    "    isinstance(model_sample_predictions, torch.Tensor)\n",
    "    and model_sample_predictions.dim() == 2  # N x C\n",
    "    and model_sample_predictions.size(1) == 6\n",
    "    for model_sample_predictions in per_model_sample_predictions\n",
    ")\n",
    "\n",
    "per_model_sample_predictions = [p.unsqueeze(0) for p in per_model_sample_predictions]\n",
    "\n",
    "# TODO(1): Average predictions from different model samples into bma_probabilities\n",
    "# raise NotImplementedError(\"Aggregate predictions from model samples\")\n",
    "bma_logits = torch.cat(per_model_sample_predictions, 0)\n",
    "bma_logits = torch.mean(bma_logits, 0)\n",
    "bma_probabilities = torch.softmax(bma_logits, dim=-1)\n",
    "\n",
    "assert bma_probabilities.dim() == 2 and bma_probabilities.size(1) == 6  # N x C\n",
    "# return bma_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60130fac-f037-43a1-b79c-b20ddd838060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(per_model_sample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2cb4f863-3ba8-4c92-a1e7-4f1a876d4e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1800, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_model_sample_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1407b9da-558b-4581-b182-dde137b38a18",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(model_sample_predictions, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model_sample_predictions\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# N x C\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model_sample_predictions\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_sample_predictions \u001b[38;5;129;01min\u001b[39;00m per_model_sample_predictions\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert all(\n",
    "    isinstance(model_sample_predictions, torch.Tensor)\n",
    "    and model_sample_predictions.dim() == 2  # N x C\n",
    "    and model_sample_predictions.size(1) == 6\n",
    "    for model_sample_predictions in per_model_sample_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ba9cc1f-0bca-4485-ac04-5ac70e35b4fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_sample_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_sample_predictions\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_sample_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "model_sample_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d5a3d-a7cc-4de6-84a0-ed9fb201e598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f21d3-eca1-4268-8a70-26064171d8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf03f292-3d97-4437-a7ae-96dde269d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1800, 6])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_model_sample_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff8f3a93-161c-4766-b3fc-9118da54a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_logits = torch.cat(per_model_sample_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1cdc757-ec2a-4475-8737-e16aef33c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_logits = torch.mean(bma_logits, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9178544f-cc44-4851-a5fb-1af6351b1740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1800, 6])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7cab3f79-db2a-42e6-ab0a-fa36ed8fbd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1800, 6])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(bma_logits, dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ded066a2-d314-4a44-817e-23094085d8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "        ...,\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(bma_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62f644-344f-40c9-9dae-657b8738d373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57eb3090-5b23-4d84-a53c-0b2430f65469",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bma_probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbma_probabilities\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bma_probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "bma_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa78b54-4f3f-4c6c-9aaa-f66efd09eb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cc4375e-80dd-4a45-9c5e-76a398f4a34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89e7a579-9435-4c4a-8c20-bc470bde2531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29937286-8d31-4605-b33a-7c606065eecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d003005-1850-406f-99e7-89aafd556186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(1): Don't forget to update batch normalization statistics using self._update_batchnorm()\n",
    "#  in the appropriate place!\n",
    "net = swag.network.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "000f4e48-1b46-4da5-af00-78ff3326596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layer0.0.weight', 'layer0.0.bias', 'layer0.1.weight', 'layer0.1.bias', 'layer0.1.running_mean', 'layer0.1.running_var', 'layer0.1.num_batches_tracked', 'layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer1.1.running_mean', 'layer1.1.running_var', 'layer1.1.num_batches_tracked', 'layer2.0.weight', 'layer2.0.bias', 'layer2.1.weight', 'layer2.1.bias', 'layer2.1.running_mean', 'layer2.1.running_var', 'layer2.1.num_batches_tracked', 'layer3.0.weight', 'layer3.0.bias', 'layer3.1.weight', 'layer3.1.bias', 'layer3.1.running_mean', 'layer3.1.running_var', 'layer3.1.num_batches_tracked', 'layer4.0.weight', 'layer4.0.bias', 'layer4.1.weight', 'layer4.1.bias', 'layer4.1.running_mean', 'layer4.1.running_var', 'layer4.1.num_batches_tracked', 'layer5.0.weight', 'layer5.0.bias', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e0268aa-f6dc-4bb4-872c-e75e78a8f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0c4f187-4bed-4b02-9c94-62586119d144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "085441c5-9b04-4909-8a58-80434f5e6a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer0.0.weight',\n",
       "              tensor([[[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.],\n",
       "                        [0., 0., 0., 0., 0.]]]])),\n",
       "             ('layer0.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer0.1.weight',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer0.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer0.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer0.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('layer0.1.num_batches_tracked', tensor(0)),\n",
       "             ('layer1.0.weight',\n",
       "              tensor([[[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]]])),\n",
       "             ('layer1.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer1.1.weight',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer1.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer1.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer1.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('layer1.1.num_batches_tracked', tensor(0)),\n",
       "             ('layer2.0.weight',\n",
       "              tensor([[[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]]])),\n",
       "             ('layer2.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer2.1.weight',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer2.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer2.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer2.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('layer2.1.num_batches_tracked', tensor(0)),\n",
       "             ('layer3.0.weight',\n",
       "              tensor([[[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]]])),\n",
       "             ('layer3.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer3.1.weight',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer3.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer3.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer3.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('layer3.1.num_batches_tracked', tensor(0)),\n",
       "             ('layer4.0.weight',\n",
       "              tensor([[[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]]])),\n",
       "             ('layer4.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer4.1.weight',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer4.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer4.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('layer4.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('layer4.1.num_batches_tracked', tensor(0)),\n",
       "             ('layer5.0.weight',\n",
       "              tensor([[[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]],\n",
       "              \n",
       "              \n",
       "                      [[[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]],\n",
       "              \n",
       "                       [[0., 0., 0.],\n",
       "                        [0., 0., 0.],\n",
       "                        [0., 0., 0.]]]])),\n",
       "             ('layer5.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('linear.weight',\n",
       "              tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       "             ('linear.bias', tensor([0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e553e9b0-202d-4c57-ab86-883db3ffdae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_param\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pai/lib/python3.8/site-packages/torch/_tensor.py:930\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 930\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    932\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    939\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "net.update(sampled_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0d372-6dd1-452f-98ec-1a9de270f04a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5ce9a-52fd-4e07-a0bf-778741a5112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "swag.network.load_state_dict(net)\n",
    "swag._update_batchnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3256c8-6925-4564-8c74-396849721555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5b8e4-dd37-478f-b4e0-ec4ee3142089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d547419-3871-4722-b179-de4a32dc199f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "72ecb99b-f71f-4958-b0b5-f21b7e9e0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c704ef4-8636-46ef-ae42-f7669d88f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4c702ef5-4483-4b31-91dd-4860699a4a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running gradient descent for SWA:   0%|                 | 0/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm.trange(swag.swag_epochs, desc=\"Running gradient descent for SWA\") as pbar:\n",
    "    pbar_dict = {}\n",
    "    for epoch in pbar:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6de22283-c1b5-48f7-a6b3-0684495283c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8aeee07-06da-4f56-bb68-4967578bdbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tqdm.std.tqdm at 0x7f9e4398baf0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f4adc-a10c-4412-8cef-9922fb8b402b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59d78a-4153-4aff-8015-21b827969f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
